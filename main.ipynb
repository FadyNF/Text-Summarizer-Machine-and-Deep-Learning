{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d0b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from utils import prepare_labeled_sentences, prepare_labeled_sentences_spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd3f019",
   "metadata": {},
   "source": [
    "#### Read Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d4506ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BBC Dataset\n",
    "bbc_df = pd.read_csv(\"data/bbc/bbc_dataset.csv\")\n",
    "\n",
    "#IMDB Dataset\n",
    "imdb_df = pd.read_csv(\"data/imdb/imdb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e05b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBC Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>TimeWarner said fourth quarter sales rose 2% t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>The dollar has hit its highest level against t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>Yukos' owner Menatep Group says it will ask Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>Rod Eddington, BA's chief executive, said the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>Pernod has reduced the debt it took on to fund...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  \\\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...   \n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...   \n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...   \n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...   \n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...   \n",
       "\n",
       "                                             Summary  \n",
       "0  TimeWarner said fourth quarter sales rose 2% t...  \n",
       "1  The dollar has hit its highest level against t...  \n",
       "2  Yukos' owner Menatep Group says it will ask Ro...  \n",
       "3  Rod Eddington, BA's chief executive, said the ...  \n",
       "4  Pernod has reduced the debt it took on to fund...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview to confirm structure\n",
    "print(\"BBC Sample:\")\n",
    "display(bbc_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a3b0b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production The filming tech...</td>\n",
       "      <td>A wonderful little production The filming tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was wonderful way to spend time...</td>\n",
       "      <td>I thought it was proof that Woody Allen is sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there a family where little boy Jake...</td>\n",
       "      <td>Basically there a family where little boy Jake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei Love in the Time of Money is vis...</td>\n",
       "      <td>Petter Mattei Love in the Time of Money is vis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  \\\n",
       "0  One of the other reviewers has mentioned that ...   \n",
       "1  A wonderful little production The filming tech...   \n",
       "2  I thought this was wonderful way to spend time...   \n",
       "3  Basically there a family where little boy Jake...   \n",
       "4  Petter Mattei Love in the Time of Money is vis...   \n",
       "\n",
       "                                             Summary  \n",
       "0  One of the other reviewers has mentioned that ...  \n",
       "1  A wonderful little production The filming tech...  \n",
       "2  I thought it was proof that Woody Allen is sti...  \n",
       "3  Basically there a family where little boy Jake...  \n",
       "4  Petter Mattei Love in the Time of Money is vis...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"IMDB Sample:\")\n",
    "display(imdb_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3c1a94",
   "metadata": {},
   "source": [
    "Preprocess BBC Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b005f2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing articles: 100%|██████████| 2225/2225 [08:30<00:00,  4.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process the BBC dataset\n",
    "bbc_labeled_data = prepare_labeled_sentences_spacy(bbc_df)\n",
    "\n",
    "# Convert to DataFrame for modeling\n",
    "bbc_processed_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"article_id\": item[\"article_id\"],\n",
    "            \"article_sentences\": item[\"raw_sentence\"],\n",
    "            \"preprocessed_sentence\": item[\"preprocessed_sentence\"],\n",
    "            \"label\": item[\"label\"],\n",
    "        }\n",
    "        for item in bbc_labeled_data\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3309143b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41677, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6a9ee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary sentences: 16543 out of 41677 (39.69%)\n",
      "\n",
      "Example summary sentences:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_sentences</th>\n",
       "      <th>preprocessed_sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
       "      <td>ad sale boost time warner profit quarterly pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>TimeWarner said fourth quarter sales rose 2% t...</td>\n",
       "      <td>timewarner say fourth quarter sale rise 11.1bn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>It lost 464,000 subscribers in the fourth quar...</td>\n",
       "      <td>lose subscriber fourth quarter profit low prec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                  article_sentences  \\\n",
       "0           0  Ad sales boost Time Warner profit  Quarterly p...   \n",
       "2           0  TimeWarner said fourth quarter sales rose 2% t...   \n",
       "6           0  It lost 464,000 subscribers in the fourth quar...   \n",
       "\n",
       "                               preprocessed_sentence  label  \n",
       "0  ad sale boost time warner profit quarterly pro...      1  \n",
       "2  timewarner say fourth quarter sale rise 11.1bn...      1  \n",
       "6  lose subscriber fourth quarter profit low prec...      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count how many sentences are labeled as summary sentences\n",
    "summary_count = bbc_processed_df['label'].sum()\n",
    "total_count = len(bbc_processed_df)\n",
    "print(f\"Summary sentences: {summary_count} out of {total_count} ({summary_count/total_count:.2%})\")\n",
    "\n",
    "# Show some examples of sentences included in summaries\n",
    "print(\"\\nExample summary sentences:\")\n",
    "display(bbc_processed_df[bbc_processed_df['label'] == 1].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65bf0a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_sentences</th>\n",
       "      <th>preprocessed_sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
       "      <td>ad sale boost time warner profit quarterly pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>The firm, which is now one of the biggest inve...</td>\n",
       "      <td>firm one big investor google benefit sale inte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>TimeWarner said fourth quarter sales rose 2% t...</td>\n",
       "      <td>timewarner say fourth quarter sale rise 11.1bn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Its profits were buoyed by one-off gains which...</td>\n",
       "      <td>profit buoy gain offset profit dip warner bros...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Time Warner said on Friday that it now owns 8%...</td>\n",
       "      <td>time warner say friday google</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>But its own internet business, AOL, had has mi...</td>\n",
       "      <td>internet business aol mix fortune</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>It lost 464,000 subscribers in the fourth quar...</td>\n",
       "      <td>lose subscriber fourth quarter profit low prec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>However, the company said AOL's underlying pro...</td>\n",
       "      <td>however company say aol underlying profit exce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>It hopes to increase subscribers by offering t...</td>\n",
       "      <td>hop increase subscriber offer online service f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>TimeWarner also has to restate 2000 and 2003 r...</td>\n",
       "      <td>timewarner also restate result follow probe u ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>Time Warner's fourth quarter profits were slig...</td>\n",
       "      <td>time warner fourth quarter profit slightly goo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>But its film division saw profits slump 27% to...</td>\n",
       "      <td>film division saw profit slump help flop alexa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>For the full-year, TimeWarner posted a profit ...</td>\n",
       "      <td>timewarner post profit 3.36bn performance reve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Our financial performance was strong, meeting...</td>\n",
       "      <td>financial performance strong meeting exceed ob...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>For 2005, TimeWarner is projecting operating e...</td>\n",
       "      <td>timewarner project operate earnings growth aro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>TimeWarner is to restate its accounts as part ...</td>\n",
       "      <td>timewarner restate account part effort resolve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>It has already offered to pay $300m to settle ...</td>\n",
       "      <td>already offer pay settle charge deal review sec</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>The company said it was unable to estimate the...</td>\n",
       "      <td>company say unable estimate amount need set as...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>It will now book the sale of its stake in AOL ...</td>\n",
       "      <td>book sale stake aol europe loss value stake</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>dollar gain greenspan speech</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>The dollar has hit its highest level against t...</td>\n",
       "      <td>dollar hit high level euro almost three month ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>And Alan Greenspan highlighted the US governme...</td>\n",
       "      <td>alan greenspan highlight u government willingn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>In late trading in New York, the dollar reache...</td>\n",
       "      <td>late trading new york dollar reach 1.2871 euro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>Market concerns about the deficit has hit the ...</td>\n",
       "      <td>market concern deficit hit greenback recent month</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>On Friday, Federal Reserve chairman Mr Greensp...</td>\n",
       "      <td>friday federal reserve chairman mr greenspan s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>\"I think the chairman's taking a much more san...</td>\n",
       "      <td>think chairman take much sanguine view current...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>\"He's taking a longer-term view, laying out a ...</td>\n",
       "      <td>take view lay set condition current account de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>Worries about the deficit concerns about China...</td>\n",
       "      <td>worry deficit concern china however remain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>China's currency remains pegged to the dollar ...</td>\n",
       "      <td>china currency remain peg dollar u currency sh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>But calls for a shift in Beijing's policy have...</td>\n",
       "      <td>call shift beijing policy fall deaf ear despit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>The G7 meeting is thought unlikely to produce ...</td>\n",
       "      <td>meeting think unlikely produce meaningful move...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>In the meantime, the US Federal Reserve's deci...</td>\n",
       "      <td>meantime u federal reserve decision february b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>The half-point window, some believe, could be ...</td>\n",
       "      <td>window believe could enough keep u asset look ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>The recent falls have partly been the result o...</td>\n",
       "      <td>recent fall partly result big budget deficit w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>The White House will announce its budget on Mo...</td>\n",
       "      <td>white house announce budget monday many commen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>Yukos unit buyer faces loan claim  The owners ...</td>\n",
       "      <td>yukos unit buyer face loan claim owner embattl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>State-owned Rosneft bought the Yugansk unit fo...</td>\n",
       "      <td>rosneft buy yugansk unit 9.3bn sale force russ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>Yukos' owner Menatep Group says it will ask Ro...</td>\n",
       "      <td>yukos owner menatep group say ask rosneft repa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>Rosneft already faces a similar $540m repaymen...</td>\n",
       "      <td>rosneft already face similar repayment demand ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>Legal experts said Rosneft's purchase of Yugan...</td>\n",
       "      <td>legal expert say rosneft purchase yugansk woul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>\"The pledged assets are with Rosneft, so it wi...</td>\n",
       "      <td>pledge asset rosneft pay real money creditor a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>Menatep Group's managing director Tim Osborne ...</td>\n",
       "      <td>menatep group manage director tim osborne tell...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>Rosneft officials were unavailable for comment.</td>\n",
       "      <td>rosneft official unavailable comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2</td>\n",
       "      <td>But the company has said it intends to take ac...</td>\n",
       "      <td>company say intend take action menatep recover...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>Yukos had filed for bankruptcy protection in a...</td>\n",
       "      <td>yukos file bankruptcy protection u court attem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>The sale went ahead in December and Yugansk wa...</td>\n",
       "      <td>sale go ahead december yugansk sell shell comp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2</td>\n",
       "      <td>Yukos claims its downfall was punishment for t...</td>\n",
       "      <td>yukos claim downfall punishment political ambi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3</td>\n",
       "      <td>High fuel prices hit BA's profits  British Air...</td>\n",
       "      <td>high fuel price hit ba profit british airway b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3</td>\n",
       "      <td>Reporting its results for the three months to ...</td>\n",
       "      <td>report result three month december airline mak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>Rod Eddington, BA's chief executive, said the ...</td>\n",
       "      <td>rod eddington ba chief executive say result re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3</td>\n",
       "      <td>BA's profits were still better than market exp...</td>\n",
       "      <td>ba profit still good market expectation expect...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>3</td>\n",
       "      <td>To help offset the increased price of aviation...</td>\n",
       "      <td>help offset increased price aviation fuel ba l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3</td>\n",
       "      <td>In October, it increased this from Â£6 to Â£10...</td>\n",
       "      <td>october increase flight surcharge raise â£2.50...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3</td>\n",
       "      <td>Yet aviation analyst Mike Powell of Dresdner K...</td>\n",
       "      <td>yet aviation analyst mike powell dresdner klei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>3</td>\n",
       "      <td>Looking ahead to its full year results to Marc...</td>\n",
       "      <td>look ahead full year result march ba warn yiel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>3</td>\n",
       "      <td>However, it said sales would be better than pr...</td>\n",
       "      <td>however say sale would good previously forecast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3</td>\n",
       "      <td>\"For the year to March 2005, the total revenue...</td>\n",
       "      <td>year march total revenue outlook slightly good...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3</td>\n",
       "      <td>BA had previously forecast a 2% to 3% rise in ...</td>\n",
       "      <td>ba previously forecast rise revenue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3</td>\n",
       "      <td>It also reported on Friday that passenger numb...</td>\n",
       "      <td>also report friday passenger number rise 8.1 j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>3</td>\n",
       "      <td>Aviation analyst Nick Van den Brul of BNP Pari...</td>\n",
       "      <td>aviation analyst nick van den brul bnp paribas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id                                  article_sentences  \\\n",
       "0            0  Ad sales boost Time Warner profit  Quarterly p...   \n",
       "1            0  The firm, which is now one of the biggest inve...   \n",
       "2            0  TimeWarner said fourth quarter sales rose 2% t...   \n",
       "3            0  Its profits were buoyed by one-off gains which...   \n",
       "4            0  Time Warner said on Friday that it now owns 8%...   \n",
       "5            0  But its own internet business, AOL, had has mi...   \n",
       "6            0  It lost 464,000 subscribers in the fourth quar...   \n",
       "7            0  However, the company said AOL's underlying pro...   \n",
       "8            0  It hopes to increase subscribers by offering t...   \n",
       "9            0  TimeWarner also has to restate 2000 and 2003 r...   \n",
       "10           0  Time Warner's fourth quarter profits were slig...   \n",
       "11           0  But its film division saw profits slump 27% to...   \n",
       "12           0  For the full-year, TimeWarner posted a profit ...   \n",
       "13           0  \"Our financial performance was strong, meeting...   \n",
       "14           0  For 2005, TimeWarner is projecting operating e...   \n",
       "15           0  TimeWarner is to restate its accounts as part ...   \n",
       "16           0  It has already offered to pay $300m to settle ...   \n",
       "17           0  The company said it was unable to estimate the...   \n",
       "18           0  It will now book the sale of its stake in AOL ...   \n",
       "19           1                   Dollar gains on Greenspan speech   \n",
       "20           1  The dollar has hit its highest level against t...   \n",
       "21           1  And Alan Greenspan highlighted the US governme...   \n",
       "22           1  In late trading in New York, the dollar reache...   \n",
       "23           1  Market concerns about the deficit has hit the ...   \n",
       "24           1  On Friday, Federal Reserve chairman Mr Greensp...   \n",
       "25           1  \"I think the chairman's taking a much more san...   \n",
       "26           1  \"He's taking a longer-term view, laying out a ...   \n",
       "27           1  Worries about the deficit concerns about China...   \n",
       "28           1  China's currency remains pegged to the dollar ...   \n",
       "29           1  But calls for a shift in Beijing's policy have...   \n",
       "30           1  The G7 meeting is thought unlikely to produce ...   \n",
       "31           1  In the meantime, the US Federal Reserve's deci...   \n",
       "32           1  The half-point window, some believe, could be ...   \n",
       "33           1  The recent falls have partly been the result o...   \n",
       "34           1  The White House will announce its budget on Mo...   \n",
       "35           2  Yukos unit buyer faces loan claim  The owners ...   \n",
       "36           2  State-owned Rosneft bought the Yugansk unit fo...   \n",
       "37           2  Yukos' owner Menatep Group says it will ask Ro...   \n",
       "38           2  Rosneft already faces a similar $540m repaymen...   \n",
       "39           2  Legal experts said Rosneft's purchase of Yugan...   \n",
       "40           2  \"The pledged assets are with Rosneft, so it wi...   \n",
       "41           2  Menatep Group's managing director Tim Osborne ...   \n",
       "42           2    Rosneft officials were unavailable for comment.   \n",
       "43           2  But the company has said it intends to take ac...   \n",
       "44           2  Yukos had filed for bankruptcy protection in a...   \n",
       "45           2  The sale went ahead in December and Yugansk wa...   \n",
       "46           2  Yukos claims its downfall was punishment for t...   \n",
       "47           3  High fuel prices hit BA's profits  British Air...   \n",
       "48           3  Reporting its results for the three months to ...   \n",
       "49           3  Rod Eddington, BA's chief executive, said the ...   \n",
       "50           3  BA's profits were still better than market exp...   \n",
       "51           3  To help offset the increased price of aviation...   \n",
       "52           3  In October, it increased this from Â£6 to Â£10...   \n",
       "53           3  Yet aviation analyst Mike Powell of Dresdner K...   \n",
       "54           3  Looking ahead to its full year results to Marc...   \n",
       "55           3  However, it said sales would be better than pr...   \n",
       "56           3  \"For the year to March 2005, the total revenue...   \n",
       "57           3  BA had previously forecast a 2% to 3% rise in ...   \n",
       "58           3  It also reported on Friday that passenger numb...   \n",
       "59           3  Aviation analyst Nick Van den Brul of BNP Pari...   \n",
       "\n",
       "                                preprocessed_sentence  label  \n",
       "0   ad sale boost time warner profit quarterly pro...      1  \n",
       "1   firm one big investor google benefit sale inte...      0  \n",
       "2   timewarner say fourth quarter sale rise 11.1bn...      1  \n",
       "3   profit buoy gain offset profit dip warner bros...      0  \n",
       "4                       time warner say friday google      0  \n",
       "5                   internet business aol mix fortune      0  \n",
       "6   lose subscriber fourth quarter profit low prec...      1  \n",
       "7   however company say aol underlying profit exce...      1  \n",
       "8   hop increase subscriber offer online service f...      0  \n",
       "9   timewarner also restate result follow probe u ...      0  \n",
       "10  time warner fourth quarter profit slightly goo...      1  \n",
       "11  film division saw profit slump help flop alexa...      0  \n",
       "12  timewarner post profit 3.36bn performance reve...      1  \n",
       "13  financial performance strong meeting exceed ob...      0  \n",
       "14  timewarner project operate earnings growth aro...      1  \n",
       "15  timewarner restate account part effort resolve...      0  \n",
       "16    already offer pay settle charge deal review sec      0  \n",
       "17  company say unable estimate amount need set as...      0  \n",
       "18        book sale stake aol europe loss value stake      0  \n",
       "19                       dollar gain greenspan speech      0  \n",
       "20  dollar hit high level euro almost three month ...      1  \n",
       "21  alan greenspan highlight u government willingn...      0  \n",
       "22  late trading new york dollar reach 1.2871 euro...      0  \n",
       "23  market concern deficit hit greenback recent month      1  \n",
       "24  friday federal reserve chairman mr greenspan s...      0  \n",
       "25  think chairman take much sanguine view current...      1  \n",
       "26  take view lay set condition current account de...      1  \n",
       "27         worry deficit concern china however remain      0  \n",
       "28  china currency remain peg dollar u currency sh...      1  \n",
       "29  call shift beijing policy fall deaf ear despit...      0  \n",
       "30  meeting think unlikely produce meaningful move...      0  \n",
       "31  meantime u federal reserve decision february b...      0  \n",
       "32  window believe could enough keep u asset look ...      0  \n",
       "33  recent fall partly result big budget deficit w...      1  \n",
       "34  white house announce budget monday many commen...      0  \n",
       "35  yukos unit buyer face loan claim owner embattl...      0  \n",
       "36  rosneft buy yugansk unit 9.3bn sale force russ...      1  \n",
       "37  yukos owner menatep group say ask rosneft repa...      1  \n",
       "38  rosneft already face similar repayment demand ...      0  \n",
       "39  legal expert say rosneft purchase yugansk woul...      0  \n",
       "40  pledge asset rosneft pay real money creditor a...      1  \n",
       "41  menatep group manage director tim osborne tell...      0  \n",
       "42               rosneft official unavailable comment      0  \n",
       "43  company say intend take action menatep recover...      1  \n",
       "44  yukos file bankruptcy protection u court attem...      0  \n",
       "45  sale go ahead december yugansk sell shell comp...      1  \n",
       "46  yukos claim downfall punishment political ambi...      0  \n",
       "47  high fuel price hit ba profit british airway b...      0  \n",
       "48  report result three month december airline mak...      0  \n",
       "49  rod eddington ba chief executive say result re...      1  \n",
       "50  ba profit still good market expectation expect...      1  \n",
       "51  help offset increased price aviation fuel ba l...      1  \n",
       "52  october increase flight surcharge raise â£2.50...      0  \n",
       "53  yet aviation analyst mike powell dresdner klei...      1  \n",
       "54  look ahead full year result march ba warn yiel...      1  \n",
       "55    however say sale would good previously forecast      0  \n",
       "56  year march total revenue outlook slightly good...      1  \n",
       "57                ba previously forecast rise revenue      1  \n",
       "58  also report friday passenger number rise 8.1 j...      0  \n",
       "59  aviation analyst nick van den brul bnp paribas...      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_processed_df.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa7f591",
   "metadata": {},
   "source": [
    "Preprocessed IMDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ac0d9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing articles:   0%|          | 3/4000 [00:00<07:10,  9.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing articles: 100%|██████████| 4000/4000 [08:26<00:00,  7.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process the BBC dataset\n",
    "imdb_labeled_df = prepare_labeled_sentences_spacy(imdb_df[:4000])\n",
    "\n",
    "# Convert to DataFrame for modeling\n",
    "imdb_processed_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"article_id\": item[\"article_id\"],\n",
    "            \"article_sentences\": item[\"raw_sentence\"],\n",
    "            \"preprocessed_sentence\": item[\"preprocessed_sentence\"],\n",
    "            \"label\": item[\"label\"],\n",
    "        }\n",
    "        for item in imdb_labeled_df\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a67dd484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13024, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64901be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary sentences: 2934 out of 13024 (22.53%)\n",
      "\n",
      "Example summary sentences:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_sentences</th>\n",
       "      <th>preprocessed_sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A wonderful little production The filming tech...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>Basically there a family where little boy Jake...</td>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>Petter Mattei Love in the Time of Money is vis...</td>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id                                  article_sentences  \\\n",
       "2            1  A wonderful little production The filming tech...   \n",
       "9            3  Basically there a family where little boy Jake...   \n",
       "11           4  Petter Mattei Love in the Time of Money is vis...   \n",
       "\n",
       "                                preprocessed_sentence  label  \n",
       "2   wonderful little production filming technique ...      1  \n",
       "9   basically family little boy jake think zombie ...      1  \n",
       "11  petter mattei love time money visually stunnin...      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count how many sentences are labeled as summary sentences\n",
    "summary_count = imdb_processed_df['label'].sum()\n",
    "total_count = len(imdb_processed_df)\n",
    "print(f\"Summary sentences: {summary_count} out of {total_count} ({summary_count/total_count:.2%})\")\n",
    "\n",
    "# Show some examples of sentences included in summaries\n",
    "print(\"\\nExample summary sentences:\")\n",
    "display(imdb_processed_df[imdb_processed_df['label'] == 1].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a84aae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A wonderful little production The filming technique is very unassuming very old time BBC fashion and gives comforting and sometimes discomforting sense of realism to the entire piece The actors are extremely well chosen Michael Sheen not only has got all the polari\n"
     ]
    }
   ],
   "source": [
    "print(imdb_processed_df[\"article_sentences\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e1a68bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_sentences</th>\n",
       "      <th>preprocessed_sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>one reviewer mention watch oz episode hook rig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>This show pulls no punches with regards to dru...</td>\n",
       "      <td>show pull punch regard drug sex violence hardc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A wonderful little production The filming tech...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>but he has all the voices down pat too You can...</td>\n",
       "      <td>voice pat truly see seamless edit guide refere...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>but it is terrificly written and performed pie...</td>\n",
       "      <td>terrificly write perform piece masterful produ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>The realism really comes home with the little ...</td>\n",
       "      <td>realism really come home little thing fantasy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>I thought this was wonderful way to spend time...</td>\n",
       "      <td>think wonderful way spend time hot summer week...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>The plot is simplistic but the dialogue is wit...</td>\n",
       "      <td>plot simplistic dialogue witty character likab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>While some may be disappointed when they reali...</td>\n",
       "      <td>may disappoint realize match point risk addict...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>Basically there a family where little boy Jake...</td>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>And then we have Jake with his closet which to...</td>\n",
       "      <td>jake closet totally ruin film expect see booge...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>Petter Mattei Love in the Time of Money is vis...</td>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>This is movie that seems to be telling us what...</td>\n",
       "      <td>movie seem tell u money power success people d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>Kane Michael Imperioli Adrian Grenier and the ...</td>\n",
       "      <td>kane michael imperioli adrian grenier rest tal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>We wish Mr Mattei good luck and await anxiousl...</td>\n",
       "      <td>wish mr mattei good luck await anxiously next ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>Probably my all time favorite movie story of s...</td>\n",
       "      <td>probably time favorite movie story selflessnes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>The kids are as grandma says more like dressed...</td>\n",
       "      <td>kid grandma say like dress midget child make f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>I sure would like to see resurrection of up da...</td>\n",
       "      <td>sure would like see resurrection dated seahunt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>Oh by the way thank you for an outlet like thi...</td>\n",
       "      <td>oh way thank outlet like view many viewpoint t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>So any ole way believe ve got what wanna say W...</td>\n",
       "      <td>ole way believe get wan na say would nice read...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7</td>\n",
       "      <td>This show was an amazing fresh innovative idea...</td>\n",
       "      <td>show amazing fresh innovative idea first air f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>encourage positive comment film look forward w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9</td>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>like original gut wrench laughter like movie y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
       "      <td>phil alien one quirky film humour base around ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>At first it was very odd and pretty funny but ...</td>\n",
       "      <td>first odd pretty funny movie progress find jok...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>anymore</td>\n",
       "      <td>anymore</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10</td>\n",
       "      <td>Its low budget film thats never problem in its...</td>\n",
       "      <td>low budget film thats never problem pretty int...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11</td>\n",
       "      <td>I saw this movie when was about when it came o...</td>\n",
       "      <td>saw movie come recall scary scene big bird eat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11</td>\n",
       "      <td>The horror As young kid going to these cheesy ...</td>\n",
       "      <td>horror young kid go cheesy film saturday after...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12</td>\n",
       "      <td>So im not big fan of Boll work but then again ...</td>\n",
       "      <td>im big fan boll work many enjoy movie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12</td>\n",
       "      <td>Postal maybe im the only one Boll apparently b...</td>\n",
       "      <td>postal maybe im one boll apparently buy right ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12</td>\n",
       "      <td>So the tale goes like this Jack Carver played ...</td>\n",
       "      <td>tale go like jack carver play til schweiger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12</td>\n",
       "      <td>yes Carver is German all hail the bratwurst ea...</td>\n",
       "      <td>yes carver german hail bratwurst eat dude howe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12</td>\n",
       "      <td>but we only saw carver in first person perspec...</td>\n",
       "      <td>saw carver first person perspective</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>12</td>\n",
       "      <td>so we don really know what he looked like when...</td>\n",
       "      <td>really know look like kick however storyline f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>12</td>\n",
       "      <td>We see the evil mad scientist Dr Krieger playe...</td>\n",
       "      <td>see evil mad scientist dr krieger play udo kie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>13</td>\n",
       "      <td>The cast played Shakespeare Shakespeare lost a...</td>\n",
       "      <td>cast play shakespeare shakespeare lose appreci...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>14</td>\n",
       "      <td>This fantastic movie of three prisoners who be...</td>\n",
       "      <td>fantastic movie three prisoner become famous o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>14</td>\n",
       "      <td>but this roll is not bad Another good thing ab...</td>\n",
       "      <td>roll bad another good thing movie soundtrack m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>15</td>\n",
       "      <td>Kind of drawn in by the erotic scenes only to ...</td>\n",
       "      <td>kind drawn erotic scene realize one amateurish...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>15</td>\n",
       "      <td>What was with the bisexual relationship out of...</td>\n",
       "      <td>bisexual relationship nowhere heterosexual enc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>15</td>\n",
       "      <td>And what was with that absurd dance with every...</td>\n",
       "      <td>absurd dance everybody play stereotyped role g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>16</td>\n",
       "      <td>Some films just simply should not be remade Th...</td>\n",
       "      <td>film simply remake one bad film fail capture f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>16</td>\n",
       "      <td>But you will enjoy the friction of terror in t...</td>\n",
       "      <td>enjoy friction terror old version much</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>17</td>\n",
       "      <td>This movie made it into one of my top most awf...</td>\n",
       "      <td>movie make one top awful movie horrible contin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>17</td>\n",
       "      <td>The ghost scene at the end was stolen from the...</td>\n",
       "      <td>ghost scene end steal final scene old star war...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>17</td>\n",
       "      <td>hello</td>\n",
       "      <td>hello</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>17</td>\n",
       "      <td>And the whole machine vs humans theme WAS the ...</td>\n",
       "      <td>whole machine v human theme matrix terminator ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>18</td>\n",
       "      <td>I remember this film it was the first film had...</td>\n",
       "      <td>remember film first film watch cinema picture ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>19</td>\n",
       "      <td>An awful film It must have been up against som...</td>\n",
       "      <td>awful film must real stinker nominate golden g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>19</td>\n",
       "      <td>They ve taken the story of the first famous fe...</td>\n",
       "      <td>take story first famous female renaissance pai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>19</td>\n",
       "      <td>My complaint is not that they ve taken liberti...</td>\n",
       "      <td>complaint take liberty fact story good would p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>19</td>\n",
       "      <td>But it simply bizarre by all accounts the true...</td>\n",
       "      <td>simply bizarre account true story artist would...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>19</td>\n",
       "      <td>so why did they come up with this dishwater du...</td>\n",
       "      <td>come dishwater dull script suppose enough nake...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>20</td>\n",
       "      <td>After the success of Die Hard and it sequels i...</td>\n",
       "      <td>success die hard sequels surprise really glut ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>20</td>\n",
       "      <td>However if you an forget all the nonsense it a...</td>\n",
       "      <td>however forget nonsense actually lovable unden...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>20</td>\n",
       "      <td>And whilst he surely can be it really does loo...</td>\n",
       "      <td>whilst surely really look like ralph waite fra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>20</td>\n",
       "      <td>yes you can help enjoy that bit Hal needed goo...</td>\n",
       "      <td>yes help enjoy bit hal need good kicking</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>20</td>\n",
       "      <td>So forget your better judgement who cares if t...</td>\n",
       "      <td>forget good judgement care could never happen ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>20</td>\n",
       "      <td>And if you re looking for Qaulen he the one we...</td>\n",
       "      <td>look qaulen one wear helicopter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id                                  article_sentences  \\\n",
       "0            0  One of the other reviewers has mentioned that ...   \n",
       "1            0  This show pulls no punches with regards to dru...   \n",
       "2            1  A wonderful little production The filming tech...   \n",
       "3            1  but he has all the voices down pat too You can...   \n",
       "4            1  but it is terrificly written and performed pie...   \n",
       "5            1  The realism really comes home with the little ...   \n",
       "6            2  I thought this was wonderful way to spend time...   \n",
       "7            2  The plot is simplistic but the dialogue is wit...   \n",
       "8            2  While some may be disappointed when they reali...   \n",
       "9            3  Basically there a family where little boy Jake...   \n",
       "10           3  And then we have Jake with his closet which to...   \n",
       "11           4  Petter Mattei Love in the Time of Money is vis...   \n",
       "12           4  This is movie that seems to be telling us what...   \n",
       "13           4  Kane Michael Imperioli Adrian Grenier and the ...   \n",
       "14           4  We wish Mr Mattei good luck and await anxiousl...   \n",
       "15           5  Probably my all time favorite movie story of s...   \n",
       "16           5  The kids are as grandma says more like dressed...   \n",
       "17           6  I sure would like to see resurrection of up da...   \n",
       "18           6  Oh by the way thank you for an outlet like thi...   \n",
       "19           6  So any ole way believe ve got what wanna say W...   \n",
       "20           7  This show was an amazing fresh innovative idea...   \n",
       "21           8  Encouraged by the positive comments about this...   \n",
       "22           9  If you like original gut wrenching laughter yo...   \n",
       "23          10  Phil the Alien is one of those quirky films wh...   \n",
       "24          10  At first it was very odd and pretty funny but ...   \n",
       "25          10                                            anymore   \n",
       "26          10  Its low budget film thats never problem in its...   \n",
       "27          11  I saw this movie when was about when it came o...   \n",
       "28          11  The horror As young kid going to these cheesy ...   \n",
       "29          12  So im not big fan of Boll work but then again ...   \n",
       "30          12  Postal maybe im the only one Boll apparently b...   \n",
       "31          12  So the tale goes like this Jack Carver played ...   \n",
       "32          12  yes Carver is German all hail the bratwurst ea...   \n",
       "33          12  but we only saw carver in first person perspec...   \n",
       "34          12  so we don really know what he looked like when...   \n",
       "35          12  We see the evil mad scientist Dr Krieger playe...   \n",
       "36          13  The cast played Shakespeare Shakespeare lost a...   \n",
       "37          14  This fantastic movie of three prisoners who be...   \n",
       "38          14  but this roll is not bad Another good thing ab...   \n",
       "39          15  Kind of drawn in by the erotic scenes only to ...   \n",
       "40          15  What was with the bisexual relationship out of...   \n",
       "41          15  And what was with that absurd dance with every...   \n",
       "42          16  Some films just simply should not be remade Th...   \n",
       "43          16  But you will enjoy the friction of terror in t...   \n",
       "44          17  This movie made it into one of my top most awf...   \n",
       "45          17  The ghost scene at the end was stolen from the...   \n",
       "46          17                                              hello   \n",
       "47          17  And the whole machine vs humans theme WAS the ...   \n",
       "48          18  I remember this film it was the first film had...   \n",
       "49          19  An awful film It must have been up against som...   \n",
       "50          19  They ve taken the story of the first famous fe...   \n",
       "51          19  My complaint is not that they ve taken liberti...   \n",
       "52          19  But it simply bizarre by all accounts the true...   \n",
       "53          19  so why did they come up with this dishwater du...   \n",
       "54          20  After the success of Die Hard and it sequels i...   \n",
       "55          20  However if you an forget all the nonsense it a...   \n",
       "56          20  And whilst he surely can be it really does loo...   \n",
       "57          20  yes you can help enjoy that bit Hal needed goo...   \n",
       "58          20  So forget your better judgement who cares if t...   \n",
       "59          20  And if you re looking for Qaulen he the one we...   \n",
       "\n",
       "                                preprocessed_sentence  label  \n",
       "0   one reviewer mention watch oz episode hook rig...      0  \n",
       "1   show pull punch regard drug sex violence hardc...      0  \n",
       "2   wonderful little production filming technique ...      1  \n",
       "3   voice pat truly see seamless edit guide refere...      0  \n",
       "4   terrificly write perform piece masterful produ...      0  \n",
       "5   realism really come home little thing fantasy ...      0  \n",
       "6   think wonderful way spend time hot summer week...      0  \n",
       "7   plot simplistic dialogue witty character likab...      0  \n",
       "8   may disappoint realize match point risk addict...      0  \n",
       "9   basically family little boy jake think zombie ...      1  \n",
       "10  jake closet totally ruin film expect see booge...      0  \n",
       "11  petter mattei love time money visually stunnin...      1  \n",
       "12  movie seem tell u money power success people d...      0  \n",
       "13  kane michael imperioli adrian grenier rest tal...      1  \n",
       "14  wish mr mattei good luck await anxiously next ...      0  \n",
       "15  probably time favorite movie story selflessnes...      1  \n",
       "16  kid grandma say like dress midget child make f...      0  \n",
       "17  sure would like see resurrection dated seahunt...      1  \n",
       "18  oh way thank outlet like view many viewpoint t...      0  \n",
       "19  ole way believe get wan na say would nice read...      0  \n",
       "20  show amazing fresh innovative idea first air f...      0  \n",
       "21  encourage positive comment film look forward w...      0  \n",
       "22  like original gut wrench laughter like movie y...      1  \n",
       "23  phil alien one quirky film humour base around ...      1  \n",
       "24  first odd pretty funny movie progress find jok...      1  \n",
       "25                                            anymore      0  \n",
       "26  low budget film thats never problem pretty int...      0  \n",
       "27  saw movie come recall scary scene big bird eat...      1  \n",
       "28  horror young kid go cheesy film saturday after...      0  \n",
       "29              im big fan boll work many enjoy movie      0  \n",
       "30  postal maybe im one boll apparently buy right ...      0  \n",
       "31        tale go like jack carver play til schweiger      0  \n",
       "32  yes carver german hail bratwurst eat dude howe...      0  \n",
       "33                saw carver first person perspective      0  \n",
       "34  really know look like kick however storyline f...      0  \n",
       "35  see evil mad scientist dr krieger play udo kie...      0  \n",
       "36  cast play shakespeare shakespeare lose appreci...      0  \n",
       "37  fantastic movie three prisoner become famous o...      1  \n",
       "38  roll bad another good thing movie soundtrack m...      1  \n",
       "39  kind drawn erotic scene realize one amateurish...      0  \n",
       "40  bisexual relationship nowhere heterosexual enc...      0  \n",
       "41  absurd dance everybody play stereotyped role g...      0  \n",
       "42  film simply remake one bad film fail capture f...      0  \n",
       "43             enjoy friction terror old version much      0  \n",
       "44  movie make one top awful movie horrible contin...      0  \n",
       "45  ghost scene end steal final scene old star war...      0  \n",
       "46                                              hello      0  \n",
       "47  whole machine v human theme matrix terminator ...      0  \n",
       "48  remember film first film watch cinema picture ...      0  \n",
       "49  awful film must real stinker nominate golden g...      1  \n",
       "50  take story first famous female renaissance pai...      1  \n",
       "51  complaint take liberty fact story good would p...      0  \n",
       "52  simply bizarre account true story artist would...      0  \n",
       "53  come dishwater dull script suppose enough nake...      0  \n",
       "54  success die hard sequels surprise really glut ...      0  \n",
       "55  however forget nonsense actually lovable unden...      0  \n",
       "56  whilst surely really look like ralph waite fra...      0  \n",
       "57           yes help enjoy bit hal need good kicking      0  \n",
       "58  forget good judgement care could never happen ...      0  \n",
       "59                    look qaulen one wear helicopter      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_processed_df.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36012aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def balance_dataset(df):\n",
    "    df_majority = df[df.label == 0]\n",
    "    df_minority = df[df.label == 1]\n",
    "\n",
    "    df_minority_upsampled = resample(\n",
    "        df_minority, replace=True, n_samples=len(df_majority), random_state=42\n",
    "    )\n",
    "\n",
    "    return pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "\n",
    "# Balance both datasets\n",
    "bbc_balanced = balance_dataset(bbc_processed_df)\n",
    "imdb_balanced = balance_dataset(imdb_processed_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49d1bfc",
   "metadata": {},
   "source": [
    "#### Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ee6068",
   "metadata": {},
   "source": [
    "kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145708c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'tfidf__ngram_range': (1, 1), 'tfidf__min_df': 3, 'tfidf__max_features': 3000, 'clf__weights': 'distance', 'clf__n_neighbors': 7, 'clf__metric': 'cosine'}\n",
      "Best score: 0.7530351372268077\n",
      "BBC Dataset Evaluation (KNN):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.74      0.79      5043\n",
      "           1       0.77      0.86      0.81      5011\n",
      "\n",
      "    accuracy                           0.80     10054\n",
      "   macro avg       0.80      0.80      0.80     10054\n",
      "weighted avg       0.80      0.80      0.80     10054\n",
      "\n",
      "\n",
      "Article ID: 0\n",
      "Reference Summary: TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. For the full-year, Time...\n",
      "Generated Summary: TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. ...\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.7966101694915254, 'p': 1.0, 'f': 0.8867924478942684}, 'rouge-2': {'r': 0.7534246575342466, 'p': 0.9821428571428571, 'f': 0.8527131733814074}, 'rouge-l': {'r': 0.7966101694915254, 'p': 1.0, 'f': 0.8867924478942684}}\n",
      "\n",
      "Article ID: 1\n",
      "Reference Summary: \"I think the chairman's taking a much more sanguine view on the current account deficit than he's taken for some time,\" said Robert Sinche, head of currency strategy at Bank of America in New York. \"I...\n",
      "Generated Summary: \"I think the chairman's taking a much more sanguine view on the current account deficit than he's taken for some time,\" said Robert Sinche, head of currency strategy at Bank of America in New York. \"I...\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.5463917525773195, 'p': 1.0, 'f': 0.706666662096889}, 'rouge-2': {'r': 0.44360902255639095, 'p': 1.0, 'f': 0.6145833290760634}, 'rouge-l': {'r': 0.5463917525773195, 'p': 1.0, 'f': 0.706666662096889}}\n",
      "\n",
      "Article ID: 2\n",
      "Reference Summary: State-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part settle a $27.5bn tax claim against Yukos. But the company has said it intends to take action against Menatep t...\n",
      "Generated Summary: State-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part settle a $27.5bn tax claim against Yukos. But the company has said it intends to take action against Menatep t...\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.5128205128205128, 'p': 1.0, 'f': 0.6779660972134445}, 'rouge-2': {'r': 0.4666666666666667, 'p': 1.0, 'f': 0.6363636320247934}, 'rouge-l': {'r': 0.5128205128205128, 'p': 1.0, 'f': 0.6779660972134445}}\n",
      "\n",
      "Article ID: 3\n",
      "Reference Summary: BA had previously forecast a 2% to 3% rise in full-year revenue. \"It is quite good on the revenue side and it shows the impact of fuel surcharges and a positive cargo development, however, operating m...\n",
      "Generated Summary: BA had previously forecast a 2% to 3% rise in full-year revenue. \"It is quite good on the revenue side and it shows the impact of fuel surcharges and a positive cargo development, however, operating m...\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.43410852713178294, 'p': 1.0, 'f': 0.6054054011839299}, 'rouge-2': {'r': 0.3471502590673575, 'p': 1.0, 'f': 0.5153846115588758}, 'rouge-l': {'r': 0.43410852713178294, 'p': 1.0, 'f': 0.6054054011839299}}\n",
      "\n",
      "Article ID: 4\n",
      "Reference Summary: In terms of market value, Pernod - at 7.5bn euros ($9.7bn) - is about 9% smaller than Allied Domecq, which has a capitalisation of Â£5.7bn ($10.7bn; 8.2bn euros). Pernod said it was seeking acquisitio...\n",
      "Generated Summary: In terms of market value, Pernod - at 7.5bn euros ($9.7bn) - is about 9% smaller than Allied Domecq, which has a capitalisation of Â£5.7bn ($10.7bn; 8.2bn euros). Pernod said it was seeking acquisitio...\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.8, 'p': 1.0, 'f': 0.8888888839506174}, 'rouge-2': {'r': 0.7142857142857143, 'p': 1.0, 'f': 0.8333333284722222}, 'rouge-l': {'r': 0.8, 'p': 1.0, 'f': 0.8888888839506174}}\n"
     ]
    }
   ],
   "source": [
    "from ML_models.knn import KNNExtractiveSummarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare data\n",
    "X = bbc_balanced[\"preprocessed_sentence\"]\n",
    "y = bbc_balanced[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize and tune model\n",
    "knn_bbc = KNNExtractiveSummarizer()\n",
    "\n",
    "# Fine-tune the model on the training set\n",
    "knn_bbc.tune(X_train, y_train, n_iter=10, scoring=\"f1\")  # You can increase n_iter\n",
    "\n",
    "# Evaluate\n",
    "print(\"BBC Dataset Evaluation (KNN):\")\n",
    "knn_bbc.evaluate(X_test, y_test)\n",
    "\n",
    "# Generate summaries for a few articles\n",
    "sample_article_ids = bbc_balanced[\"article_id\"].unique()[:5]\n",
    "\n",
    "for article_id in sample_article_ids:\n",
    "    article_df = bbc_balanced[bbc_balanced[\"article_id\"] == article_id]\n",
    "    reference_summary = \" \".join(\n",
    "        article_df[article_df[\"label\"] == 1][\"article_sentences\"]\n",
    "    )\n",
    "    generated_summary = knn_bbc.summarize(\n",
    "        article_df[\"article_sentences\"].tolist(),\n",
    "        article_df[\"preprocessed_sentence\"].tolist(),\n",
    "    )\n",
    "\n",
    "    print(f\"\\nArticle ID: {article_id}\")\n",
    "    print(\"Reference Summary:\", reference_summary[:200] + \"...\")\n",
    "    print(\"Generated Summary:\", generated_summary[:200] + \"...\")\n",
    "\n",
    "    rouge_scores = knn_bbc.compute_rouge(generated_summary, reference_summary)\n",
    "    if rouge_scores is not None:\n",
    "        print(\"ROUGE Scores:\", rouge_scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aa701b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'tfidf__ngram_range': (1, 1), 'tfidf__min_df': 1, 'tfidf__max_features': 5000, 'clf__weights': 'distance', 'clf__n_neighbors': 7, 'clf__metric': 'euclidean'}\n",
      "Best score: 0.8969881150466228\n",
      "IMDB Dataset Evaluation (KNN):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      2013\n",
      "           1       0.94      0.92      0.93      2023\n",
      "\n",
      "    accuracy                           0.93      4036\n",
      "   macro avg       0.93      0.93      0.93      4036\n",
      "weighted avg       0.93      0.93      0.93      4036\n",
      "\n",
      "\n",
      "Article ID: 0\n",
      "Reference Summary: ...\n",
      "Generated Summary: One of the other reviewers has mentioned that after watching just Oz episode you ll be hooked They are right as this is exactly what happened with me The first thing that struck me about Oz was its br...\n",
      "Error computing ROUGE: Reference is empty.\n",
      "\n",
      "Article ID: 1\n",
      "Reference Summary: A wonderful little production The filming technique is very unassuming very old time BBC fashion and gives comforting and sometimes discomforting sense of realism to the entire piece The actors are ex...\n",
      "Generated Summary: but it is terrificly written and performed piece masterful production about one of the great master of comedy and his life A wonderful little production The filming technique is very unassuming very o...\n",
      "ROUGE Scores: {'rouge-1': {'r': 1.0, 'p': 0.75, 'f': 0.8571428522448981}, 'rouge-2': {'r': 1.0, 'p': 0.6666666666666666, 'f': 0.7999999952000001}, 'rouge-l': {'r': 1.0, 'p': 0.75, 'f': 0.8571428522448981}}\n",
      "\n",
      "Article ID: 2\n",
      "Reference Summary: ...\n",
      "Generated Summary: The plot is simplistic but the dialogue is witty and the characters are likable even the well bread suspected serial killer...\n",
      "Error computing ROUGE: Reference is empty.\n",
      "\n",
      "Article ID: 3\n",
      "Reference Summary: Basically there a family where little boy Jake thinks there a zombie in his closet his parents are fighting all the time This movie is slower than soap opera and suddenly Jake decides to become Rambo ...\n",
      "Generated Summary: Basically there a family where little boy Jake thinks there a zombie in his closet his parents are fighting all the time This movie is slower than soap opera and suddenly Jake decides to become Rambo ...\n",
      "ROUGE Scores: {'rouge-1': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-2': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-l': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}}\n",
      "\n",
      "Article ID: 4\n",
      "Reference Summary: Kane Michael Imperioli Adrian Grenier and the rest of the talented cast make these characters come alive Petter Mattei Love in the Time of Money is visually stunning film to watch Mr Mattei offers us ...\n",
      "Generated Summary: Petter Mattei Love in the Time of Money is visually stunning film to watch Mr Mattei offers us vivid portrait about human relations Petter Mattei Love in the Time of Money is visually stunning film to...\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.6111111111111112, 'p': 1.0, 'f': 0.7586206849464924}, 'rouge-2': {'r': 0.575, 'p': 1.0, 'f': 0.7301587255228017}, 'rouge-l': {'r': 0.6111111111111112, 'p': 1.0, 'f': 0.7586206849464924}}\n"
     ]
    }
   ],
   "source": [
    "from ML_models.knn import KNNExtractiveSummarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare data\n",
    "X = imdb_balanced[\"preprocessed_sentence\"]\n",
    "y = imdb_balanced[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize and tune model\n",
    "knn_bbc = KNNExtractiveSummarizer()\n",
    "\n",
    "# Fine-tune the model on the training set\n",
    "knn_bbc.tune(X_train, y_train, n_iter=10, scoring=\"f1\")  # You can increase n_iter\n",
    "\n",
    "# Evaluate\n",
    "print(\"IMDB Dataset Evaluation (KNN):\")\n",
    "knn_bbc.evaluate(X_test, y_test)\n",
    "\n",
    "# Generate summaries for a few articles\n",
    "sample_article_ids = imdb_balanced[\"article_id\"].unique()[:5]\n",
    "\n",
    "for article_id in sample_article_ids:\n",
    "    article_df = imdb_balanced[imdb_balanced[\"article_id\"] == article_id]\n",
    "    reference_summary = \" \".join(\n",
    "        article_df[article_df[\"label\"] == 1][\"article_sentences\"]\n",
    "    )\n",
    "    generated_summary = knn_bbc.summarize(\n",
    "        article_df[\"article_sentences\"].tolist(),\n",
    "        article_df[\"preprocessed_sentence\"].tolist(),\n",
    "    )\n",
    "\n",
    "    print(f\"\\nArticle ID: {article_id}\")\n",
    "    print(\"Reference Summary:\", reference_summary[:200] + \"...\")\n",
    "    print(\"Generated Summary:\", generated_summary[:200] + \"...\")\n",
    "\n",
    "    rouge_scores = knn_bbc.compute_rouge(generated_summary, reference_summary)\n",
    "    if rouge_scores is not None:\n",
    "        print(\"ROUGE Scores:\", rouge_scores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c925098",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55b135f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<<<<<<< local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best params: {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 3, 'tfidf__max_features': 5000, 'clf__max_iter': 1500, 'clf__C': 1}\n",
      "Best score: 0.5626295285604364\n",
      "BBC Dataset Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.66      0.69      5062\n",
      "           1       0.54      0.62      0.58      3274\n",
      "\n",
      "    accuracy                           0.65      8336\n",
      "   macro avg       0.64      0.64      0.64      8336\n",
      "weighted avg       0.66      0.65      0.65      8336\n",
      "\n",
      "\n",
      "Article ID: 0\n",
      "Reference Summary: TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. For the full-year, Time...\n",
      "Generated Summary: The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn ...\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.6101694915254238, 'p': 0.7058823529411765, 'f': 0.654545449571901}, 'rouge-2': {'r': 0.4794520547945205, 'p': 0.5932203389830508, 'f': 0.5303030253592746}, 'rouge-l': {'r': 0.6101694915254238, 'p': 0.7058823529411765, 'f': 0.654545449571901}}\n",
      "\n",
      "Article ID: 1\n",
      "Reference Summary: The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise. Market concerns about the deficit has hit the...\n",
      "Generated Summary: The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise. On Friday, Federal Reserve chairman Mr Greens...\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.2909090909090909, 'p': 0.47761194029850745, 'f': 0.36158191619904884}, 'rouge-2': {'r': 0.19480519480519481, 'p': 0.35294117647058826, 'f': 0.2510460205213495}, 'rouge-l': {'r': 0.2818181818181818, 'p': 0.4626865671641791, 'f': 0.35028248117080024}}\n",
      "\n",
      "Article ID: 2\n",
      "Reference Summary: State-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part settle a $27.5bn tax claim against Yukos. Yukos' owner Menatep Group says it will ask Rosneft to repay a loan ...\n",
      "Generated Summary: Yukos unit buyer faces loan claim  The owners of embattled Russian oil giant Yukos are to ask the buyer of its former production unit to pay back a $900m (Â£479m) loan. Yukos' owner Menatep Group says...\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.375, 'p': 0.6111111111111112, 'f': 0.4647887276810157}, 'rouge-2': {'r': 0.1693548387096774, 'p': 0.2916666666666667, 'f': 0.21428570963765106}, 'rouge-l': {'r': 0.3409090909090909, 'p': 0.5555555555555556, 'f': 0.42253520655425514}}\n"
     ]
    }
   ],
   "source": [
    "from ML_models.logistic_reg import LogisticRegressionSummarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = bbc_balanced[\"preprocessed_sentence\"]\n",
    "y = bbc_balanced[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "lr_bbc = LogisticRegressionSummarizer()\n",
    "\n",
    "# Fine-tune the model on the training set\n",
    "lr_bbc.tune(\n",
    "    X_train, y_train, n_iter=10, scoring=\"f1\"\n",
    ")  # You can increase n_iter if desired\n",
    "\n",
    "print(\"BBC Dataset Evaluation:\")\n",
    "lr_bbc.evaluate(X_test, y_test)\n",
    "\n",
    "sample_article_ids = bbc_balanced[\"article_id\"].unique()[:3]\n",
    "\n",
    "for article_id in sample_article_ids:\n",
    "    article_df = bbc_balanced[bbc_balanced[\"article_id\"] == article_id]\n",
    "    reference_summary = \" \".join(\n",
    "        article_df[article_df[\"label\"] == 1][\"article_sentences\"]\n",
    "    )\n",
    "    generated_summary = lr_bbc.summarize(\n",
    "        article_df[\"article_sentences\"].tolist(),\n",
    "        article_df[\"preprocessed_sentence\"].tolist(),\n",
    "    )\n",
    "\n",
    "    print(f\"\\nArticle ID: {article_id}\")\n",
    "    print(\"Reference Summary:\", reference_summary[:200] + \"...\")\n",
    "    print(\"Generated Summary:\", generated_summary[:200] + \"...\")\n",
    "\n",
    "    rouge_scores = lr_bbc.compute_rouge(generated_summary, reference_summary)\n",
    "    if rouge_scores is not None:\n",
    "        print(\"ROUGE Scores:\", rouge_scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63f7063f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<<<<<<< local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best params: {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 2, 'tfidf__max_features': 3000, 'clf__max_iter': 500, 'clf__C': 0.1}\n",
      "Best score: 0.40721609299234146\n",
      "IMDB Dataset Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76      2021\n",
      "           1       0.35      0.57      0.43       584\n",
      "\n",
      "    accuracy                           0.80      4036\n",
      "   macro avg       0.80      0.80      0.80      4036\n",
      "weighted avg       0.80      0.80      0.80      4036\n",
      "\n",
      "\n",
      "Article ID: 0\n",
      "Reference Summary: ...\n",
      "Generated Summary: One of the other reviewers has mentioned that after watching just Oz episode you ll be hooked They are right as this is exactly what happened with me The first thing that struck me about Oz was its br...\n",
      "Error computing ROUGE: Reference is empty.\n",
      "\n",
      "Article ID: 1\n",
      "Reference Summary: A wonderful little production The filming technique is very unassuming very old time BBC fashion and gives comforting and sometimes discomforting sense of realism to the entire piece The actors are ex...\n",
      "Generated Summary: A wonderful little production The filming technique is very unassuming very old time BBC fashion and gives comforting and sometimes discomforting sense of realism to the entire piece The actors are ex...\n",
      "ROUGE Scores: {'rouge-1': {'r': 1.0, 'p': 0.5492957746478874, 'f': 0.7090909045140497}, 'rouge-2': {'r': 1.0, 'p': 0.45161290322580644, 'f': 0.6222222179358025}, 'rouge-l': {'r': 1.0, 'p': 0.5492957746478874, 'f': 0.7090909045140497}}\n",
      "\n",
      "Article ID: 2\n",
      "Reference Summary: ...\n",
      "Generated Summary: I thought this was wonderful way to spend time on too hot summer weekend sitting in the air conditioned theater and watching light hearted comedy The plot is simplistic but the dialogue is witty and t...\n",
      "Error computing ROUGE: Reference is empty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>>>>> remote\n"
     ]
    }
   ],
   "source": [
    "from ML_models.logistic_reg import LogisticRegressionSummarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = imdb_balanced[\"preprocessed_sentence\"]\n",
    "y = imdb_balanced[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "lr_imdb = LogisticRegressionSummarizer()\n",
    "\n",
    "# Fine-tune the model on the training set\n",
    "lr_imdb.tune(X_train, y_train, n_iter=10, scoring=\"f1\")\n",
    "\n",
    "print(\"IMDB Dataset Evaluation:\")\n",
    "lr_imdb.evaluate(X_test, y_test)\n",
    "\n",
    "sample_article_ids = imdb_balanced[\"article_id\"].unique()[:3]\n",
    "\n",
    "for article_id in sample_article_ids:\n",
    "    article_df = imdb_balanced[imdb_balanced[\"article_id\"] == article_id]\n",
    "    article_sents = article_df[\"article_sentences\"].tolist()\n",
    "    preprocessed_sents = article_df[\"preprocessed_sentence\"].tolist()\n",
    "\n",
    "    if not preprocessed_sents or not article_sents:\n",
    "        print(f\"\\nArticle ID: {article_id}\")\n",
    "        print(\"Empty input. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    reference_summary = \" \".join(\n",
    "        article_df[article_df[\"label\"] == 1][\"article_sentences\"]\n",
    "    )\n",
    "    generated_summary = lr_imdb.summarize(article_sents, preprocessed_sents)\n",
    "\n",
    "    print(f\"\\nArticle ID: {article_id}\")\n",
    "    print(\"Reference Summary:\", reference_summary[:200] + \"...\")\n",
    "    print(\"Generated Summary:\", generated_summary[:200] + \"...\")\n",
    "\n",
    "    rouge_scores = lr_imdb.compute_rouge(generated_summary, reference_summary)\n",
    "    if rouge_scores is not None:\n",
    "        print(\"ROUGE Scores:\", rouge_scores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39d614e",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829982a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Fady\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running on BBC Dataset ===\n",
      "Train Accuracy: 0.8802\n",
      "Test Accuracy: 0.8588\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.92     12218\n",
      "           1       0.06      0.47      0.10       208\n",
      "\n",
      "    accuracy                           0.86     12426\n",
      "   macro avg       0.52      0.67      0.51     12426\n",
      "weighted avg       0.97      0.86      0.91     12426\n",
      "\n",
      "\n",
      "ROUGE Scores:\n",
      "rouge-1: 0.3920\n",
      "rouge-2: 0.2834\n",
      "rouge-l: 0.3817\n",
      "\n",
      "--- Article 1665 ---\n",
      "Predicted: Campaign groups including Friends of the Earth, the World Development Movement, and War on Want said UK government policy on free trade was a major barrier to fighting poverty.\n",
      "Reference: Mr Brown welcomed news that the Bill Gates Foundation and Norway are joining up to put an extra Â£0.53bn ($1bn ) into the Global Alliance for Vaccines and Immunisation (Gavi).UK Chancellor Gordon Brown has offered Â£960m ($1.8bn) over 15 years to an international scheme aiming to boost vaccination and immunisation schemes.If Gavi could increase its funding for immunisation by an extra Â£4bn ($7.4bn) over 10 years, then an extra five million lives could have been saved by 2015 and five million thereafter, Mr Brown argued.\"As long as Mr Blair and Mr Brown continue to push free trade and privatisation on developing countries, more and more people will be pushed deeper into poverty, not lifted out of it.\"Britain, France, Gavi and the Gates Foundation have drawn up proposals to apply the principles of the International Finance Facility (IFF) to the area of immunisation.Campaign groups including Friends of the Earth, the World Development Movement, and War on Want said UK government policy on free trade was a major barrier to fighting poverty.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 1348 ---\n",
      "Predicted: Injury sidelines Philippoussis\n",
      "\n",
      "Mark Philippoussis withdrew from the Sydney International tennis tournament as expected on Sunday after suffering a groin injury during the Hopman Cup.\n",
      "Reference: Defending women's champion Justine Henin-Hardenne is also out of the Sydney event because of a knee injury.Number one men's seed Lleyton Hewitt begins his quest for a fourth Sydney title on Tuesday when he plays Karol Beck.Lindsay Davenport, top seed in the women's draw, has been handed a first-round bye and plays France's Dechy in the second round on Tuesday.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 433 ---\n",
      "Predicted: \"We will submit a budget that fits the times,\" Mr Bush said. \"As well, we've got to deal with the long-term deficit issues.\"\n",
      "Reference: Mr Bush, however, has said the best way to halt the dollar's slide is to deal with the US deficit.US president George W Bush has pledged to introduce a \"tough\" federal budget next February in a bid to halve the country's deficit in five years.\"We will submit a budget that fits the times,\" Mr Bush said.The US budget and its trade deficit are both deep in the red, helping to push the dollar to lows against the euro and fuelling fears about the economy.Mr Bush indicated there would be \"strict discipline\" on non-defence spending in the budget.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 1436 ---\n",
      "Predicted: About 50,000 children live with foster families in the UK and carers have said they need more money to make ends meet. Ms Hodge said: \"Foster carers must not be out of pocket when meeting the costs of caring for a looked after child - a crucial role in society. \"We need to make sure that arrangements for paying foster carers are as fair and transparent as possible. \"Our proposal for a national minimum rate shows we are serious about creating a better deal for foster carers and about encouraging more people to come forward and consider fostering as a worthwhile and rewarding opportunity.\"\n",
      "Reference: About 50,000 children live with foster families in the UK and carers have said they need more money to make ends meet.\"And with a shortage of over 8,000 foster carers in England, it's not a sustainable situation to expect carers to fund foster care from their own pockets.\"\"We need to make sure that arrangements for paying foster carers are as fair and transparent as possible.Foster carers are to be guaranteed a minimum allowance to help cover their costs, the government has announced.\"But ADSS fully supports proper remuneration for valued foster carers and looks forward to working with ministers, local government and the fostering organisations themselves in order to make sure a sensible and practicable policy emerges.\"Ms Hodge said: \"Foster carers must not be out of pocket when meeting the costs of caring for a looked after child - a crucial role in society.\"Our proposal for a national minimum rate shows we are serious about creating a better deal for foster carers and about encouraging more people to come forward and consider fostering as a worthwhile and rewarding opportunity.\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 1375 ---\n",
      "Predicted: Butler said of her success: \"I felt great throughout the race and hope this is a good beginning for a marvellous 2005 season for me.\"\n",
      "Reference: Gelete Burka then crowned a great day for Ethiopia by claiming victory in the women's race.Elsewhere, Abebe Dinkessa of Ethiopia won the Brussels IAAF cross-country race on Sunday, completing the 10,500m course in 33.22.The Scot, who led GB to World Cross Country bronze earlier this year, moved away from the field with Ines Monteiro halfway into the 6.6km race.Butler said of her success: \"I felt great throughout the race and hope this is a good beginning for a marvellous 2005 season for me.\"\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ML_models.decisionTreeClassifierModel import DecisionTreeClassifierModel\n",
    "bbc_model = DecisionTreeClassifierModel(\"BBC\", bbc_processed_df)\n",
    "bbc_model.run()\n",
    "bbc_model.show_predictions(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d91c558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running on IMDB Dataset ===\n",
      "Train Accuracy: 0.9771\n",
      "Test Accuracy: 0.9684\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     11650\n",
      "           1       0.05      0.34      0.08        50\n",
      "\n",
      "    accuracy                           0.97     11700\n",
      "   macro avg       0.52      0.66      0.53     11700\n",
      "weighted avg       0.99      0.97      0.98     11700\n",
      "\n",
      "\n",
      "ROUGE Scores:\n",
      "rouge-1: 0.5617\n",
      "rouge-2: 0.4881\n",
      "rouge-l: 0.5612\n",
      "\n",
      "--- Article 13209 ---\n",
      "Predicted: Two old men sitting on park bench don really have problem with this scene Only problem is that it not scene it the entire movieYup movies don get anymore low concept than this They also don get anymore boring than this either but there worse to come because these two old men are chalk and cheese One is Nat Moyer who is Yiddish communist while the other is Midge Carter former golden gloves champion who also black Let me see now Jew and black man sitting on park bench getting along fine Well guess it possible though unlikely but if this film has such an inoffensive scenario why play up to the Jewish stereotype Why make them loud tribilistic rabble rousers who take hebrew oaths Slightly ironic that the Jews seen at the start of the movie are exactly the type of Jews seen in Nazi propaganda films in the sStereotypes aside moi dearz the problem with M NOT RAPPAPORT is that it written for an entirely different meduim than cinema it based on stage play and it shows Walter Matthau sleepwalks through his role as Nat while this commentator almost slept through the whole movie\n",
      "Reference: Two old men sitting on park bench don't really have problem with this scene. Only problem is that it not scene it the entire movie. Walter Matthau sleepwalks through his role as Nat while this commentator almost slept through the whole movie.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 6634 ---\n",
      "Predicted: Dark Harbor is moody little excursion into murky emotional waters that run extremely deep It basically character piece featuring finely layered performance by the always great Rickman with Polly Walker and Norman Reedus also excellent forming the other two sides of this strange triangle perfect late night cable film with surprise ending to boot\n",
      "Reference: Dark Harbor is moody little excursion into murky emotional waters that run extremely deep. It basically character piece featuring finely layered performance by the always great Rickman. Polly Walker and Norman Reedus also excellent forming the other two sides of this strange triangle.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 37454 ---\n",
      "Predicted: After long period in the space looking for the remains of planet Krypton Superman Brandon Routh returns to Earth He misses Lois Lane Kate Bosworth who got married and has son with Richard White James Marsden Meanwhile Lex Luthor Kevin Spacey plots an evil plan using crystals he stole from the Fortress of Solitude to create new land and submerge the USA After so many delightful movies of Superman with the unforgettable Christopher Reeve or TV shows like Lois and Clark and Teri Hatcher or Smallville great expectation was created for the return of Superman in this Bryan Singer version Unfortunately the awful story is too long and boring with many unnecessary parts lack of emotion and overrated in IMDb In addition the romance between Lois Lane and Superman is something shamefully ridiculous The twenty two years old actress Kate Bosworth is wrongly miscast playing the role of mature reporter and experienced mother of five years old boy Brandon Routh is two years younger than Tom Welling who plays teenager Clark Kent in Smallville The character of Parker Posey Kitty Kowalski is actually silly caricature Last but not the least and in spite of being terrific Lex Luthor Kevin Spacey is forty five years old therefore older and older than the rest of the lead cast The corny conclusion looks like soap opera and is terrible My vote is four Title Brazil Superman Returns\n",
      "Reference: After long period in the space looking for the remains of planet Krypton Superman Brandon Routh returns to Earth He misses Lois Lane Kate Bosworth who got married and has son with Richard White James Marsden Meanwhile Lex Luthor Kevin Spacey plots an evil plan using crystals he stole from the Fortress of Solitude to create new land and submerge the USA.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 8308 ---\n",
      "Predicted: There were lot of things going against this movie for me before watched it First was typical high school senior in Shakespeare class didn really even like much less understood half of Shakespeare would be no more than UNINTELLIGIBLE without me pouring ALL my concentration into his almost encrypted plays encrypted with his extremely difficult to understand language and then still wouldn get most of it Second it was hours long never thought that could be good thing Well let me tell you something This movie was so masterful so beautiful actually understood all the language as it was being performed Now the script was followed to the letter in this movie the same script that was incomprehensible to me in Shakespeare class And here was my mind opening and me understanding it was doubting myself while watching the movie almost But lo and behold when performed and only then Shakespeare comes to life So this version of Hamlet showed me that Shakespeare is indeed master who wrote great stories When saw it on the big screen especially in the high budget major motion picture style with beautiful cinematography and photography and acted amazingly by Brannagh and cast somehow understood what was going on What was being said The language is awesome and passionate It allows for more raw emotion when words can describe something maybe Shakespeare words can still hold to this day that Fist of The North Star animated english dub is the greatest movie ever made No movie provides more sheer entertainment But for movie to come close to dethroning Fist from that position which Hamlet did it came close is truly amazing awe inspiring It wasn a movie It was an event Even more amazing it made me appreciate shakespeare Wow Powerful Powerful is the word One of the rare TRULY powerful movies out there This gets hundred trillion stars out of infinity stars Yes yes By the way all you kids out there in Shakespeare class forget it You re wasting you re time You have to see the plays performed Only then will justice be done to them\n",
      "Reference: There were lot of things going against this movie for me before watched it. This movie was so masterful so beautiful actually understood all the language as it was being performed. The script was followed to the letter in this movie the same script that was incomprehensible to me in Shakespeare class.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 12120 ---\n",
      "Predicted: I sorry but even TJ Hooker Adrian Zmed couldn save this sequel went through half the movie thinking that this was spoof of the original Then came that wild and wacky motorcycle scene notice that this is the only movie that Patricia Birch directs and sadly realized they were trying to be serious did get kick out of the fact that the opposing gang having lost their wheels due to their gambling habits in the original Grease were forced to use motorcycles in the second movie Being shamed by that putz character Carrington d hate to see what they would resort to later maybe Mopeds also never bought the hackneyed theme hunky Australian boy can fit into Outsiders dominated school ergo goes for tough guy with stupid biker helmet look It was Disney story gone horribly awry So it looks like you CAN ruin good thing by placing bubble gum smacking Michelle Pfeiffer in musical The only thing took away from this movie was an idea of how many points out of ten to give it\n",
      "Reference: I sorry but even TJ Hooker Adrian Zmed couldn't save this sequel. It was Disney story gone horribly awry. So it looks like you CAN ruin good thing by placing bubble gum smacking Michelle Pfeiffer in musical.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ML_models.decisionTreeClassifierModel import DecisionTreeClassifierModel\n",
    "bbc_model = DecisionTreeClassifierModel(\"imdb\", imdb_processed_df)\n",
    "bbc_model.run()\n",
    "bbc_model.show_predictions(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2502619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML_models.decision_tree import DecisionTreeSummarizer\n",
    "\n",
    "bbc_summarizer = DecisionTreeSummarizer(\"BBC\", bbc_df)\n",
    "bbc_summarizer.run()\n",
    "bbc_summarizer.show_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317e7064",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_summarizer = DecisionTreeSummarizer(\"IMDB\", imdb_df)\n",
    "bbc_summarizer.run()\n",
    "bbc_summarizer.show_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa1b59",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0d669517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running classification on BBC Dataset ===\n",
      "\n",
      "Train Accuracy: 0.6780\n",
      "Test Accuracy: 0.6516\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.66      7557\n",
      "           1       0.66      0.63      0.64      7524\n",
      "\n",
      "    accuracy                           0.65     15081\n",
      "   macro avg       0.65      0.65      0.65     15081\n",
      "weighted avg       0.65      0.65      0.65     15081\n",
      "\n",
      "\n",
      "=== Article-wise Summary Evaluation ===\n",
      "\n",
      "Article ID: 0\n",
      "Reference Summary: Musicians to tackle US red tape  Musicians' groups are to tackle US visa regulations which are blamed for hindering British acts' chances of succeeding across the Atlantic. A singer hoping to perform in the US can expect to pay $1,300 (Â£680) simply for obtaining a visa. Nigel McCune from the Musicians' Union said British musicians are \"disadvantaged\" compared to their US counterparts. \"The US is the world's biggest music market, which means something has to be done about the creaky bureaucracy,\" says Mr McCune. \"The current situation is preventing British acts from maintaining momentum and developing in the US,\" he added. The Musicians' Union stance is being endorsed by the Music Managers' Forum (MMF), who say British artists face \"an uphill struggle\" to succeed in the US, thanks to the tough visa requirements, which are also seen as impractical. A US Embassy spokesman said: \"We are aware that entertainers require visas for time-specific visas and are doing everything we can to process those applications speedily.\"\n",
      "Generated Summary: Musicians to tackle US red tape  Musicians' groups are to tackle US visa regulations which are blamed for hindering British acts' chances of succeeding across the Atlantic. Nigel McCune from the Musicians' Union said British musicians are \"disadvantaged\" compared to their US counterparts. \"If you make a mistake on your form, you risk a five-year ban and thus the ability to further your career,\" says Mr McCune. \"The US is the world's biggest music market, which means something has to be done about the creaky bureaucracy,\" says Mr McCune. The Musicians' Union stance is being endorsed by the Music Managers' Forum (MMF), who say British artists face \"an uphill struggle\" to succeed in the US, thanks to the tough visa requirements, which are also seen as impractical. The MMF's general secretary James Seller said: \"Imagine if you were an orchestra from the Orkneys? \"It's still very important, but there are other markets like Europe, India and China,\" added Mr Seller. A Department for Media, Culture and Sport spokeswoman said: \"We're aware that people are experiencing problems, and are working with the US embassy and record industry to see what we can do about it.\" A US Embassy spokesman said: \"We are aware that entertainers require visas for time-specific visas and are doing everything we can to process those applications speedily.\"\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.8448, 'p': 0.6405, 'f': 0.7286}, 'rouge-2': {'r': 0.7736, 'p': 0.5829, 'f': 0.6649}, 'rouge-l': {'r': 0.8362, 'p': 0.634, 'f': 0.7212}}\n",
      "\n",
      "Article ID: 1\n",
      "Reference Summary: U2's desire to be number one  U2, who have won three prestigious Grammy Awards for their hit Vertigo, are stubbornly clinging to their status as one of the biggest bands in the world. They also have to want it. They have to want to be the biggest band ever and not stop wanting it. Their new album, How To Dismantle An Atomic Bomb, comes 28 years after the schoolfriends got together in Dublin and 17 years after The Joshua Tree cemented their place on the all-time rock A-list. Vertigo, the first single from the new album, went straight into the UK singles chart at number one, knocking Eminem off the top spot and giving them their 26th top 10 hit. \"The challenge is to be bigger and bolder and better - to make records the whole world will listen to,\" Bono recently said. We don't want to be thought of as a veteran band.\" The band have done \"everything in their considerable powers\" to ensure they remain the biggest band in the world, according to Q magazine editor Paul Rees. They are, perhaps, alone as the only rock band that has got better with age.\" The stadium-filling, anthemic sound was U2's aim from the start, and their third album, War, saw them make the breakthrough on both sides of the Atlantic, going to number one in the UK and 12 in the US. Songs like Sunday Bloody Sunday and New Year's Day brought success and an image as a political and spiritual band - which Bono rejected as a cliche. In 1987, The Joshua Tree broke sales records and saw the band reach the height of their powers with hits including Where the Streets Have No Name, I Still Haven't Found What I'm Looking For and With Or Without You. The end of the decade marked a crucial point for the band - they had reached the top but still yearned for new challenges and achievements. These came in the form of explorations of different branches of rock and forays into electronic dance music, plus wildly extravagant stage shows, while still trying to retain their mass appeal. Before the release of How To Dismantle An Atomic Bomb, they had sold 125 million albums around the world. But they still want more.\n",
      "Generated Summary: U2's desire to be number one  U2, who have won three prestigious Grammy Awards for their hit Vertigo, are stubbornly clinging to their status as one of the biggest bands in the world. The music must be inspired and appeal across generations and be distinctive, if not always groundbreaking. Their new album, How To Dismantle An Atomic Bomb, comes 28 years after the schoolfriends got together in Dublin and 17 years after The Joshua Tree cemented their place on the all-time rock A-list. Vertigo, the first single from the new album, went straight into the UK singles chart at number one, knocking Eminem off the top spot and giving them their 26th top 10 hit. \"The challenge is to be bigger and bolder and better - to make records the whole world will listen to,\" Bono recently said. The band have done \"everything in their considerable powers\" to ensure they remain the biggest band in the world, according to Q magazine editor Paul Rees. The other key ingredient was the fact they were highly organised, Mr Rees said. Songs like Sunday Bloody Sunday and New Year's Day brought success and an image as a political and spiritual band - which Bono rejected as a cliche. In 1987, The Joshua Tree broke sales records and saw the band reach the height of their powers with hits including Where the Streets Have No Name, I Still Haven't Found What I'm Looking For and With Or Without You. Those songs took the band's epic, atmospheric sound to a simple, powerful and popular pinnacle. The end of the decade marked a crucial point for the band - they had reached the top but still yearned for new challenges and achievements. These came in the form of explorations of different branches of rock and forays into electronic dance music, plus wildly extravagant stage shows, while still trying to retain their mass appeal. The Achtung Baby album in 1991 was followed by Zooropa, Pop and their corresponding stadium tours, which featured giant olives, flying cars, live phone calls to the White House and Bono's transformation into alter-egos The Fly and MacPhisto.\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.821, 'p': 0.7801, 'f': 0.8}, 'rouge-2': {'r': 0.7349, 'p': 0.7478, 'f': 0.7413}, 'rouge-l': {'r': 0.8166, 'p': 0.7759, 'f': 0.7957}}\n",
      "\n",
      "Article ID: 2\n",
      "Reference Summary: Rocker Doherty in on-stage fight  Rock singer Pete Doherty has been involved in a fight with his band's guitarist at their biggest gig to date. Babyshambles played for 5,000 fans at London's Brixton Academy on Tuesday. The former Libertines singer traded blows with guitarist Patrick Walden. On Monday Doherty faced blackmail and robbery charges in court, which he denies. He is out on Â£50,000 bail and the judge agreed to extend his 2200 GMT curfew deadline by two hours so he could play the Brixton gig. Babyshambles, which he formed after his acrimonious departure from the Libertines, played a warm-up show at The Garage, north London, on Monday. On Tuesday, Doherty and his three bandmates were introduced to the crowd by Mick Jones, the former Clash guitarist who produced the Libertines' second album. Doherty, 25, had to be home by midnight to observe the curfew, which is one of the conditions of his bail.\n",
      "Generated Summary: Rocker Doherty in on-stage fight  Rock singer Pete Doherty has been involved in a fight with his band's guitarist at their biggest gig to date. But the group had to stop during the next song to persuade fans not to push forward and allow security guards to pull people out of the crush. Doherty appealed to fans to calm down, saying: \"There's a few people getting hurt down the front, you've got to move back.\" The music resumed minutes later but after several more songs, the singer appeared to accidentally disconnect Walden's guitar, leading the pair to trade kicks and punches.\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.283, 'p': 0.3797, 'f': 0.3243}, 'rouge-2': {'r': 0.1711, 'p': 0.2574, 'f': 0.2055}, 'rouge-l': {'r': 0.2736, 'p': 0.3671, 'f': 0.3135}}\n"
     ]
    }
   ],
   "source": [
    "from ML_models.randomforest import RandomForestClassifierModel\n",
    "model_bbc_rf = RandomForestClassifierModel(\"BBC\", bbc_processed_df)\n",
    "model_bbc_rf.run()\n",
    "model_bbc_rf.show_predictions(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c670cdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running classification on imdb Dataset ===\n",
      "\n",
      "Train Accuracy: 0.7743\n",
      "Test Accuracy: 0.7241\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.67      0.71      3037\n",
      "           1       0.70      0.78      0.74      3017\n",
      "\n",
      "    accuracy                           0.72      6054\n",
      "   macro avg       0.73      0.72      0.72      6054\n",
      "weighted avg       0.73      0.72      0.72      6054\n",
      "\n",
      "\n",
      "=== Article-wise Summary Evaluation ===\n",
      "\n",
      "Article ID: 0\n",
      "Reference Summary: ...\n",
      "Generated Summary: One of the other reviewers has mentioned that after watching just Oz episode you ll be hooked They are right as this is exactly what happened with me The first thing that struck me about Oz was its brutality and unflinching scenes of violence which set in right from the word GO Trust me this is not show for the faint hearted or timid\n",
      "Error computing ROUGE: Reference or generated summary is empty.\n",
      "\n",
      "Article ID: 1\n",
      "Reference Summary: A wonderful little production The filming technique is very unassuming very old time BBC fashion and gives comforting and sometimes discomforting sense of realism to the entire piece The actors are extremely well chosen Michael Sheen not only has got all the polari\n",
      "Generated Summary: A wonderful little production The filming technique is very unassuming very old time BBC fashion and gives comforting and sometimes discomforting sense of realism to the entire piece The actors are extremely well chosen Michael Sheen not only has got all the polari but he has all the voices down pat too You can truly see the seamless editing guided by the references to Williams diary entries not only is it well worth the watching\n",
      "ROUGE Scores: {'rouge-1': {'r': 1.0, 'p': 0.65, 'f': 0.7879}, 'rouge-2': {'r': 1.0, 'p': 0.5833, 'f': 0.7368}, 'rouge-l': {'r': 1.0, 'p': 0.65, 'f': 0.7879}}\n",
      "\n",
      "Article ID: 2\n",
      "Reference Summary: ...\n",
      "Generated Summary: I thought this was wonderful way to spend time on too hot summer weekend sitting in the air conditioned theater and watching light hearted comedy The plot is simplistic but the dialogue is witty and the characters are likable even the well bread suspected serial killer\n",
      "Error computing ROUGE: Reference or generated summary is empty.\n"
     ]
    }
   ],
   "source": [
    "from ML_models.randomforest import RandomForestClassifierModel\n",
    "model_bbc_rf = RandomForestClassifierModel(\"imdb\", imdb_processed_df)\n",
    "model_bbc_rf.run()\n",
    "model_bbc_rf.show_predictions(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e97a3c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Fady\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running on BBC Dataset ===\n",
      "Train Accuracy: 0.9407\n",
      "Test Accuracy: 0.9315\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96     12226\n",
      "           1       0.07      0.27      0.11       200\n",
      "\n",
      "    accuracy                           0.93     12426\n",
      "   macro avg       0.53      0.60      0.54     12426\n",
      "weighted avg       0.97      0.93      0.95     12426\n",
      "\n",
      "\n",
      "ROUGE Scores:\n",
      "rouge-1: 0.3028\n",
      "rouge-2: 0.2067\n",
      "rouge-l: 0.2960\n",
      "\n",
      "--- Article 1665 ---\n",
      "Predicted: \"Things have been building up over the past few years and I think this is the year for Ireland,\" he told BBC Sport. A lot of things are in our favour with England and France at home.\" \"For Ireland to win it we need to stay relatively injury free, and fortunately we are one of the few teams that have done that so far,\" Wood added. \"It is going to be tough and we need to take all the luck and opportunities that come our way.\"\n",
      "Reference: \"So many of the major England players have either retired in the last year or are injured that I think it will be very hard for them down in Cardiff,\" Wood added.Former captain Keith Wood believes Ireland can win only their second Grand Slam - and first since 1948 - in this year's RBS Six Nations Championship.After claiming their first Triple Crown for 19 years last season, Wood tips his former team-mates to go one better.\"For Ireland to win it we need to stay relatively injury free, and fortunately we are one of the few teams that have done that so far,\" Wood added.\"Wales have had four brilliant games in the last year or so and lost all four, so the time is right for them now to beat one of the major teams.\"Ireland's last game of the tournament is against Wales in Cardiff - a fixture they have not lost since 1983.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 1348 ---\n",
      "Predicted: USADA chief executive officer Terry Madden said the action taken against Collins was further proof of that.\n",
      "Reference: Sprinter Michelle Collins has received an eight-year ban for doping offences after a hearing at the North American Court of Arbitration for Sport (CAS).\"The USADA has proved, beyond a reasonable doubt, that Collins took EPO, the testosterone/epitestosterone cream and THG,\" said a CAS statement.Collins' ban is a result of her connection to the federal inquiry into the Balco doping scandal.USADA chief executive officer Terry Madden said the action taken against Collins was further proof of that.The USADA has built its cases on verbal evidence given to the federal investigation into Balco rather than test results.So far a total of 13 athletes have been sanctioned for violations involving drugs associated with the Balco doping scandal.The US Anti-Doping Agency (USADA) decided to press charges against Collins in the summer.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 433 ---\n",
      "Predicted: Cairn Energy in Indian gas find\n",
      "\n",
      "Shares in Cairn Energy rose 3.8% to 1,088 pence on Tuesday after the UK firm announced a fresh gas discovery in northern India.\n",
      "Reference: The firm, which last year made a number of other new finds in the Rajasthan area, said the latest discovery could lead to large gas volumes.Cairn has also been granted approval to extend its Rajasthan exploration area.A spokesman said the company's decision to carry out further investigations at the new find showed that it believed there was significant gas.Cairn's string of finds in Rajasthan last year saw it elevated to the FTSE 100 index of the UK's leading listed companies.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 1436 ---\n",
      "Predicted: England's defensive crisis grows\n",
      "\n",
      "England's defensive worries have deepened following the withdrawal of Tottenham's Ledley King from the squad to face Holland.\n",
      "Reference: But now he has pulled out with a bruised knee and is likely to be replaced by Carragher, alongside Brown.The 25-year-old was only called into the squad on Sunday night as cover following the enforced withdrawal of Upson, who has a hamstring injury.Injured Rio Ferdinand and Sol Campbell were both left out of the squad, and Matthew Upson has already pulled out.Eriksson has still not decided whether to call up any further back-up, having already summoned Phil Neville after Bridge pulled out with a foot injury.Wes Brown and Jamie Carragher are likely to be the makeshift partnership.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 1375 ---\n",
      "Predicted: Brizzel to run AAA's in Sheffield\n",
      "\n",
      "Ballymena sprinter Paul Brizzel will be among eight of Ireland's European Indoor hopefuls competing in this weekend's AAA's Championships.\n",
      "Reference: Corkman Mark Carroll confirmed in midweek that he would join Cragg in the European Championships.In-form James McIlroy will hope to confirm his place in the British team for Madrid by winning the 800m title.US-based Alistair Cragg and Mark Carroll are the only Irish athletes selected so far for the Europeans who will not run in Sheffield.Ballymena sprinter Paul Brizzel will be among eight of Ireland's European Indoor hopefuls competing in this weekend's AAA's Championships.Brizzel will defend his 200m title in the British trials.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ML_models.random_forest import RandomForestSummarizer\n",
    "\n",
    "bbc_summarizer = RandomForestSummarizer(\"BBC\", bbc_df)\n",
    "bbc_summarizer.run()\n",
    "bbc_summarizer.show_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23de144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running on IMDB Dataset ===\n",
      "Train Accuracy: 0.9968\n",
      "Test Accuracy: 0.9924\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     11650\n",
      "           1       0.15      0.16      0.15        50\n",
      "\n",
      "    accuracy                           0.99     11700\n",
      "   macro avg       0.57      0.58      0.57     11700\n",
      "weighted avg       0.99      0.99      0.99     11700\n",
      "\n",
      "\n",
      "ROUGE Scores:\n",
      "rouge-1: 0.5617\n",
      "rouge-2: 0.4881\n",
      "rouge-l: 0.5612\n",
      "\n",
      "--- Article 13209 ---\n",
      "Predicted: Two old men sitting on park bench don really have problem with this scene Only problem is that it not scene it the entire movieYup movies don get anymore low concept than this They also don get anymore boring than this either but there worse to come because these two old men are chalk and cheese One is Nat Moyer who is Yiddish communist while the other is Midge Carter former golden gloves champion who also black Let me see now Jew and black man sitting on park bench getting along fine Well guess it possible though unlikely but if this film has such an inoffensive scenario why play up to the Jewish stereotype Why make them loud tribilistic rabble rousers who take hebrew oaths Slightly ironic that the Jews seen at the start of the movie are exactly the type of Jews seen in Nazi propaganda films in the sStereotypes aside moi dearz the problem with M NOT RAPPAPORT is that it written for an entirely different meduim than cinema it based on stage play and it shows Walter Matthau sleepwalks through his role as Nat while this commentator almost slept through the whole movie\n",
      "Reference: Two old men sitting on park bench don't really have problem with this scene. Only problem is that it not scene it the entire movie. Walter Matthau sleepwalks through his role as Nat while this commentator almost slept through the whole movie.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 6634 ---\n",
      "Predicted: Dark Harbor is moody little excursion into murky emotional waters that run extremely deep It basically character piece featuring finely layered performance by the always great Rickman with Polly Walker and Norman Reedus also excellent forming the other two sides of this strange triangle perfect late night cable film with surprise ending to boot\n",
      "Reference: Dark Harbor is moody little excursion into murky emotional waters that run extremely deep. It basically character piece featuring finely layered performance by the always great Rickman. Polly Walker and Norman Reedus also excellent forming the other two sides of this strange triangle.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 37454 ---\n",
      "Predicted: After long period in the space looking for the remains of planet Krypton Superman Brandon Routh returns to Earth He misses Lois Lane Kate Bosworth who got married and has son with Richard White James Marsden Meanwhile Lex Luthor Kevin Spacey plots an evil plan using crystals he stole from the Fortress of Solitude to create new land and submerge the USA After so many delightful movies of Superman with the unforgettable Christopher Reeve or TV shows like Lois and Clark and Teri Hatcher or Smallville great expectation was created for the return of Superman in this Bryan Singer version Unfortunately the awful story is too long and boring with many unnecessary parts lack of emotion and overrated in IMDb In addition the romance between Lois Lane and Superman is something shamefully ridiculous The twenty two years old actress Kate Bosworth is wrongly miscast playing the role of mature reporter and experienced mother of five years old boy Brandon Routh is two years younger than Tom Welling who plays teenager Clark Kent in Smallville The character of Parker Posey Kitty Kowalski is actually silly caricature Last but not the least and in spite of being terrific Lex Luthor Kevin Spacey is forty five years old therefore older and older than the rest of the lead cast The corny conclusion looks like soap opera and is terrible My vote is four Title Brazil Superman Returns\n",
      "Reference: After long period in the space looking for the remains of planet Krypton Superman Brandon Routh returns to Earth He misses Lois Lane Kate Bosworth who got married and has son with Richard White James Marsden Meanwhile Lex Luthor Kevin Spacey plots an evil plan using crystals he stole from the Fortress of Solitude to create new land and submerge the USA.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 8308 ---\n",
      "Predicted: There were lot of things going against this movie for me before watched it First was typical high school senior in Shakespeare class didn really even like much less understood half of Shakespeare would be no more than UNINTELLIGIBLE without me pouring ALL my concentration into his almost encrypted plays encrypted with his extremely difficult to understand language and then still wouldn get most of it Second it was hours long never thought that could be good thing Well let me tell you something This movie was so masterful so beautiful actually understood all the language as it was being performed Now the script was followed to the letter in this movie the same script that was incomprehensible to me in Shakespeare class And here was my mind opening and me understanding it was doubting myself while watching the movie almost But lo and behold when performed and only then Shakespeare comes to life So this version of Hamlet showed me that Shakespeare is indeed master who wrote great stories When saw it on the big screen especially in the high budget major motion picture style with beautiful cinematography and photography and acted amazingly by Brannagh and cast somehow understood what was going on What was being said The language is awesome and passionate It allows for more raw emotion when words can describe something maybe Shakespeare words can still hold to this day that Fist of The North Star animated english dub is the greatest movie ever made No movie provides more sheer entertainment But for movie to come close to dethroning Fist from that position which Hamlet did it came close is truly amazing awe inspiring It wasn a movie It was an event Even more amazing it made me appreciate shakespeare Wow Powerful Powerful is the word One of the rare TRULY powerful movies out there This gets hundred trillion stars out of infinity stars Yes yes By the way all you kids out there in Shakespeare class forget it You re wasting you re time You have to see the plays performed Only then will justice be done to them\n",
      "Reference: There were lot of things going against this movie for me before watched it. This movie was so masterful so beautiful actually understood all the language as it was being performed. The script was followed to the letter in this movie the same script that was incomprehensible to me in Shakespeare class.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 12120 ---\n",
      "Predicted: I sorry but even TJ Hooker Adrian Zmed couldn save this sequel went through half the movie thinking that this was spoof of the original Then came that wild and wacky motorcycle scene notice that this is the only movie that Patricia Birch directs and sadly realized they were trying to be serious did get kick out of the fact that the opposing gang having lost their wheels due to their gambling habits in the original Grease were forced to use motorcycles in the second movie Being shamed by that putz character Carrington d hate to see what they would resort to later maybe Mopeds also never bought the hackneyed theme hunky Australian boy can fit into Outsiders dominated school ergo goes for tough guy with stupid biker helmet look It was Disney story gone horribly awry So it looks like you CAN ruin good thing by placing bubble gum smacking Michelle Pfeiffer in musical The only thing took away from this movie was an idea of how many points out of ten to give it\n",
      "Reference: I sorry but even TJ Hooker Adrian Zmed couldn't save this sequel. It was Disney story gone horribly awry. So it looks like you CAN ruin good thing by placing bubble gum smacking Michelle Pfeiffer in musical.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ML_models.random_forest import RandomForestSummarizer\n",
    "\n",
    "bbc_summarizer = RandomForestSummarizer(\"IMDB\", imdb_df)\n",
    "bbc_summarizer.run()\n",
    "bbc_summarizer.show_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2801c4",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea16ccce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running classification on BBC Dataset ===\n",
      "\n",
      "Train Accuracy: 0.7293\n",
      "Test Accuracy: 0.6651\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.87      0.76      5027\n",
      "           1       0.64      0.36      0.46      3309\n",
      "\n",
      "    accuracy                           0.67      8336\n",
      "   macro avg       0.66      0.61      0.61      8336\n",
      "weighted avg       0.66      0.67      0.64      8336\n",
      "\n",
      "\n",
      "=== Article-wise Summary Evaluation ===\n",
      "\n",
      "Article ID: 1385\n",
      "Reference Summary: Martinez sees off Vinci challenge  Veteran Spaniard Conchita Martinez came from a set down to beat Italian Roberta Vinci at the Qatar Open in Doha. Slovakian Daniela Hantuchova beat Bulgarian Magdaleena Maleeva 4-6 6-4 6-3 to set up a second round clash with Russian Elena Bovina. The veteran Martinez found herself in trouble early on against Vinci with the Italian clinching the set thanks to breaks in the third and 11th games.\n",
      "Generated Summary: The veteran Martinez found herself in trouble early on against Vinci with the Italian clinching the set thanks to breaks in the third and 11th games. In the day's other matches, Japan's Ai Sugiyama defeated Australian Samantha Stosur 6-2 6-3 while Australian Nicole Pratt beat Tunisian Selima Sfar 7-5 6-2 and will next face compatriot Alicia Molik.\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.45454545454545453, 'p': 0.5, 'f': 0.47619047120181407}, 'rouge-2': {'r': 0.352112676056338, 'p': 0.44642857142857145, 'f': 0.393700782471325}, 'rouge-l': {'r': 0.43636363636363634, 'p': 0.48, 'f': 0.4571428521541951}}\n",
      "\n",
      "Article ID: 311\n",
      "Reference Summary: Dance music not dead says Fatboy  DJ Norman Cook - aka Fatboy Slim - has said that dance music is not dead, but has admitted it is currently going through a \"fallow patch\". The commercial failure of the latest albums by Britain's two biggest dance acts - Fatboy Slim's Palookaville and The Prodigy's Always Outnumbered Never Outgunned - has been coupled with the closure of many \"superclubs,\" and the folding of three dance music magazines. These developments lead some to suggest that dance was finished as a popular music genre. Cook acknowledged that much change in the dance world in the four years since his last album, Halfway Between The Gutter And The Stars, but he stressed this did not mean the dance scene was permanently over. \"Every week when I was making the album, I was reading articles about the demise of dance music - and obviously that affects you somewhat,\" he told BBC World Service's The Ticket programme. \"So I think, consciously or subconsciously, reading every week that dance music was dead I would think 'right, scrub that track then'.\" \"With a crowd that big, if the weather's nice, the atmosphere before I even go is so good that about halfway through the first record I think 'I've got them',\" Cook said. In particular, he said he had struggled to cope with tabloid intrusion during the temporary break-up of his marriage to Radio One presenter Zoe Ball, after she was linked with DJ Dan Peppe. \"The tabloid thing has been difficult at times,\" Cook said. He said that he had been \"determined\" that what had happened with Ball did not affect the album. \"At first I was doing deliberately jolly tunes so that people wouldn't think I was depressed,\" he explained. \"I said to Zoe, 'I did this track called My Masochistic Baby Went And Left Me, do you mind if it's on the album?'\" he recalled.\n",
      "Generated Summary: Dance music not dead says Fatboy  DJ Norman Cook - aka Fatboy Slim - has said that dance music is not dead, but has admitted it is currently going through a \"fallow patch\". The commercial failure of the latest albums by Britain's two biggest dance acts - Fatboy Slim's Palookaville and The Prodigy's Always Outnumbered Never Outgunned - has been coupled with the closure of many \"superclubs,\" and the folding of three dance music magazines. Last month the Brit Awards announced they would no longer be awarding a Best Dance Act prize, with the Brits committee announcing that \"dance music is no longer where it's happening in music.\" In particular, he said he had struggled to cope with tabloid intrusion during the temporary break-up of his marriage to Radio One presenter Zoe Ball, after she was linked with DJ Dan Peppe.\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.4271356783919598, 'p': 0.8173076923076923, 'f': 0.5610561011020707}, 'rouge-2': {'r': 0.3432343234323432, 'p': 0.7647058823529411, 'f': 0.4738040959513495}, 'rouge-l': {'r': 0.41708542713567837, 'p': 0.7980769230769231, 'f': 0.5478547809700575}}\n",
      "\n",
      "Article ID: 1972\n",
      "Reference Summary: The real danger is not what happens to your data as it crosses the net, argues analyst Bill Thompson. The Financial Services Authority has warned banks and other financial institutions that members of criminal gangs may be applying for jobs which give them access to confidential customer data. The fear is not that they will steal money from our bank accounts but that they will instead steal something far more valuable in our digital society - our identities. Armed with the personal details that a bank holds, plus a fake letter or two, it is apparently easy to get a loan, open a bank account with an overdraft or get a credit card in someone else's name. But, however careful you may be, if the organisations you trust with your personal data, bank accounts and credit cards are not able to look after their databases properly then you are in trouble. And as we all become aware of the danger of identity theft and look more carefully for unexpected transactions on our statements, banks should have good enough records and logs to trace the people who might have accessed the account details. Fortunately there are now ways to keep bank systems more secure from the sort of data theft that involves taking a portable hard drive or flash memory card into the office, plugging it into a USB slot and sucking down customer files. In fact I do not know of a single case where an e-mail containing payment details has led to card fraud. And just last week the online bank Cahoot admitted that its customer account details could be read by anyone who could guess a login name. Whether it is external hackers breaking in because of poor system security or internal staff abusing the access they get as part of their job, the issue is the same: how do we make sure that our personal data is not abused? After all, I bank with Cahoot but it would be so much hassle to move my accounts that I did not even consider it when I heard about their security problems. I doubt many others have closed their accounts, especially when there is little guarantee that other banks are not going to make the same sort of mistake in future. The two options would seem to be more stringent data protection law, so that companies really feel the pressure to improve their internal processes, or a wave of civil lawsuits against financial institutions with sloppy practices whose customers suffer from identity theft.\n",
      "Generated Summary: The two options would seem to be more stringent data protection law, so that companies really feel the pressure to improve their internal processes, or a wave of civil lawsuits against financial institutions with sloppy practices whose customers suffer from identity theft.\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.1659919028340081, 'p': 1.0, 'f': 0.2847222197803338}, 'rouge-2': {'r': 0.1, 'p': 1.0, 'f': 0.18181818016528928}, 'rouge-l': {'r': 0.1659919028340081, 'p': 1.0, 'f': 0.2847222197803338}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ML_models.xgboost import XGBoostClassifierModel\n",
    "\n",
    "# ✅ Use the actual DataFrame variable, not a string\n",
    "# Assuming bbc_processed_df was defined earlier\n",
    "df = bbc_processed_df\n",
    "\n",
    "# Run the model\n",
    "model = XGBoostClassifierModel(dataset_name=\"BBC\", df=df)\n",
    "model.run()\n",
    "model.show_predictions(n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b2c80b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running classification on imdb Dataset ===\n",
      "\n",
      "Train Accuracy: 0.8545\n",
      "Test Accuracy: 0.775\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87      2018\n",
      "           1       0.50      0.11      0.18       587\n",
      "\n",
      "    accuracy                           0.78      2605\n",
      "   macro avg       0.65      0.54      0.53      2605\n",
      "weighted avg       0.72      0.78      0.71      2605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ML_models.xgboost import XGBoostClassifierModel\n",
    "\n",
    "df = imdb_processed_df  # Your preprocessed DataFrame with 'text' and 'label' columns\n",
    "\n",
    "model = XGBoostClassifierModel(dataset_name=\"imdb\", df=df)\n",
    "model.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4f1578",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aafc69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== BBC Dataset Results =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.55      0.67      5043\n",
      "           1       0.67      0.91      0.77      5011\n",
      "\n",
      "    accuracy                           0.73     10054\n",
      "   macro avg       0.77      0.73      0.72     10054\n",
      "weighted avg       0.77      0.73      0.72     10054\n",
      "\n",
      "\n",
      "===== IMDB Dataset Results =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.75      0.83      2013\n",
      "           1       0.79      0.95      0.86      2023\n",
      "\n",
      "    accuracy                           0.85      4036\n",
      "   macro avg       0.86      0.85      0.85      4036\n",
      "weighted avg       0.86      0.85      0.85      4036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def train_and_evaluate(df, dataset_name=\"\"):\n",
    "    X = df[\"preprocessed_sentence\"]\n",
    "    y = df[\"label\"]\n",
    "\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\")\n",
    "    X_vec = vectorizer.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_vec, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f\"\\n===== {dataset_name} Dataset Results =====\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Train on BBC\n",
    "train_and_evaluate(bbc_balanced, dataset_name=\"BBC\")\n",
    "\n",
    "# Train on IMDB\n",
    "train_and_evaluate(imdb_balanced, dataset_name=\"IMDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18e9d8b",
   "metadata": {},
   "source": [
    "#### Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09d5c0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Fady\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Fady\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Training model...\n",
      "Epoch 1 - Val Accuracy: 0.9931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fady\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Fady\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Fady\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9931    1.0000    0.9965      7722\n",
      "           1     0.0000    0.0000    0.0000        54\n",
      "\n",
      "    accuracy                         0.9931      7776\n",
      "   macro avg     0.4965    0.5000    0.4983      7776\n",
      "weighted avg     0.9862    0.9931    0.9896      7776\n",
      "\n",
      "Epoch 2 - Val Accuracy: 0.9931\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9931    1.0000    0.9965      7722\n",
      "           1     0.0000    0.0000    0.0000        54\n",
      "\n",
      "    accuracy                         0.9931      7776\n",
      "   macro avg     0.4965    0.5000    0.4983      7776\n",
      "weighted avg     0.9862    0.9931    0.9896      7776\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fady\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Fady\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Fady\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Val Accuracy: 0.9931\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9931    1.0000    0.9965      7722\n",
      "           1     0.0000    0.0000    0.0000        54\n",
      "\n",
      "    accuracy                         0.9931      7776\n",
      "   macro avg     0.4965    0.5000    0.4983      7776\n",
      "weighted avg     0.9862    0.9931    0.9896      7776\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fady\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Fady\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Fady\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Val Accuracy: 0.9931\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9931    1.0000    0.9965      7722\n",
      "           1     0.0000    0.0000    0.0000        54\n",
      "\n",
      "    accuracy                         0.9931      7776\n",
      "   macro avg     0.4965    0.5000    0.4983      7776\n",
      "weighted avg     0.9862    0.9931    0.9896      7776\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fady\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Fady\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Fady\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Val Accuracy: 0.9931\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9931    1.0000    0.9965      7722\n",
      "           1     0.0000    0.0000    0.0000        54\n",
      "\n",
      "    accuracy                         0.9931      7776\n",
      "   macro avg     0.4965    0.5000    0.4983      7776\n",
      "weighted avg     0.9862    0.9931    0.9896      7776\n",
      "\n",
      "\n",
      "Sample Evaluation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fady\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Fady\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Fady\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Article:\n",
      "Ad sales boost Time Warner profit\n",
      "\n",
      "Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.\n",
      "\n",
      "The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and high...\n",
      "\n",
      "✂️ Predicted Summary:\n",
      "Ad sales boost Time Warner profit  Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn.\n",
      "\n",
      "✅ ROUGE:\n",
      "{'rouge1': Score(precision=0.9722222222222222, recall=0.45751633986928103, fmeasure=0.6222222222222222), 'rouge2': Score(precision=0.9014084507042254, recall=0.42105263157894735, fmeasure=0.5739910313901344), 'rougeL': Score(precision=0.6111111111111112, recall=0.2875816993464052, fmeasure=0.3911111111111111)}\n",
      "\n",
      "📄 Article:\n",
      "Dollar gains on Greenspan speech\n",
      "\n",
      "The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.\n",
      "\n",
      "And Alan Greenspan highlighted the US government's willingness to curb spending and rising household savings a...\n",
      "\n",
      "✂️ Predicted Summary:\n",
      "The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise. In late trading in New York, the dollar reached $1.2871 against the euro, from $1.2974 on Thursday. The White House will announce its budget on Monday, and many commentators believe the deficit will remain at close to half a trillion dollars.\n",
      "\n",
      "✅ ROUGE:\n",
      "{'rouge1': Score(precision=0.6338028169014085, recall=0.2647058823529412, fmeasure=0.37344398340248963), 'rouge2': Score(precision=0.45714285714285713, recall=0.1893491124260355, fmeasure=0.26778242677824265), 'rougeL': Score(precision=0.5352112676056338, recall=0.2235294117647059, fmeasure=0.3153526970954357)}\n",
      "\n",
      "📄 Article:\n",
      "Yukos unit buyer faces loan claim\n",
      "\n",
      "The owners of embattled Russian oil giant Yukos are to ask the buyer of its former production unit to pay back a $900m (Â£479m) loan.\n",
      "\n",
      "State-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part settle a $27.5bn tax claim against Yukos...\n",
      "\n",
      "✂️ Predicted Summary:\n",
      "Yukos unit buyer faces loan claim  The owners of embattled Russian oil giant Yukos are to ask the buyer of its former production unit to pay back a $900m (Â£479m) loan. State-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part settle a $27.5bn tax claim against Yukos. Yukos' owner Menatep Group says it will ask Rosneft to repay a loan that Yugansk had secured on its assets.\n",
      "\n",
      "✅ ROUGE:\n",
      "{'rouge1': Score(precision=0.7272727272727273, recall=0.4307692307692308, fmeasure=0.5410628019323672), 'rouge2': Score(precision=0.5921052631578947, recall=0.3488372093023256, fmeasure=0.43902439024390244), 'rougeL': Score(precision=0.4935064935064935, recall=0.2923076923076923, fmeasure=0.36714975845410625)}\n"
     ]
    }
   ],
   "source": [
    "from DL_models.vanilla_transformer import run_pipeline\n",
    "\n",
    "model = run_pipeline(bbc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830f84fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65c34c2e",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef86af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from DL_models.cnn import CNNExtractiveSummarizer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Prepare data\n",
    "# X = bbc_processed_df[\"preprocessed_sentence\"]\n",
    "# y = bbc_processed_df[\"label\"]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize model\n",
    "# cnn_bbc = CNNExtractiveSummarizer()\n",
    "\n",
    "# # Train/tune the model\n",
    "# cnn_bbc.tune(X_train, y_train, X_val_raw=X_test, y_val=y_test, epochs=30)\n",
    "\n",
    "# # Evaluate\n",
    "# print(\"BBC Dataset Evaluation (CNN):\")\n",
    "# cnn_bbc.evaluate(X_test, y_test)\n",
    "\n",
    "# # Generate summaries for a few articles\n",
    "# sample_article_ids = bbc_processed_df[\"article_id\"].unique()[:5]\n",
    "\n",
    "# for article_id in sample_article_ids:\n",
    "#     article_df = bbc_processed_df[bbc_processed_df[\"article_id\"] == article_id]\n",
    "#     reference_summary = \" \".join(\n",
    "#         article_df[article_df[\"label\"] == 1][\"article_sentences\"]\n",
    "#     )\n",
    "#     generated_summary = cnn_bbc.summarize(\n",
    "#         article_df[\"article_sentences\"].tolist(),\n",
    "#         article_df[\"preprocessed_sentence\"].tolist()\n",
    "#     )\n",
    "\n",
    "#     print(f\"\\nArticle ID: {article_id}\")\n",
    "#     print(\"Reference Summary:\", reference_summary[:200] + \"...\")\n",
    "#     print(\"Generated Summary:\", generated_summary[:200] + \"...\")\n",
    "\n",
    "#     rouge_scores = cnn_bbc.compute_rouge(generated_summary, reference_summary)\n",
    "#     if rouge_scores is not None:\n",
    "#         print(\"ROUGE Scores:\", rouge_scores[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c088b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from DL_models.cnn import CNNExtractiveSummarizer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Prepare data\n",
    "# X = imdb_processed_df[\"preprocessed_sentence\"]\n",
    "# y = imdb_processed_df[\"label\"]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize model\n",
    "# cnn_bbc = CNNExtractiveSummarizer()\n",
    "\n",
    "# # Train/tune the model\n",
    "# cnn_bbc.tune(X_train, y_train, X_val_raw=X_test, y_val=y_test, epochs=30)\n",
    "\n",
    "# # Evaluate\n",
    "# print(\"IMDB Dataset Evaluation (CNN):\")\n",
    "# cnn_bbc.evaluate(X_test, y_test)\n",
    "\n",
    "# # Generate summaries for a few articles\n",
    "# sample_article_ids = imdb_processed_df[\"article_id\"].unique()[:5]\n",
    "\n",
    "# for article_id in sample_article_ids:\n",
    "#     article_df = imdb_processed_df[imdb_processed_df[\"article_id\"] == article_id]\n",
    "#     reference_summary = \" \".join(\n",
    "#         article_df[article_df[\"label\"] == 1][\"article_sentences\"]\n",
    "#     )\n",
    "#     generated_summary = cnn_bbc.summarize(\n",
    "#         article_df[\"article_sentences\"].tolist(),\n",
    "#         article_df[\"preprocessed_sentence\"].tolist()\n",
    "#     )\n",
    "\n",
    "#     print(f\"\\nArticle ID: {article_id}\")\n",
    "#     print(\"Reference Summary:\", reference_summary[:200] + \"...\")\n",
    "#     print(\"Generated Summary:\", generated_summary[:200] + \"...\")\n",
    "\n",
    "#     rouge_scores = cnn_bbc.compute_rouge(generated_summary, reference_summary)\n",
    "#     if rouge_scores is not None:\n",
    "#         print(\"ROUGE Scores:\", rouge_scores[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b33e981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training on BBC ===\n",
      "Epoch 1 Loss: 1.0872\n",
      "Epoch 2 Loss: 1.0021\n",
      "Epoch 3 Loss: 0.8830\n",
      "Epoch 4 Loss: 0.6982\n",
      "Epoch 5 Loss: 0.4818\n",
      "Training completed in 281.33s\n",
      "Best Threshold: 0.25, F1: 0.6022\n",
      "\n",
      "ROUGE Scores:\n",
      "rouge-1: 0.3566\n",
      "rouge-2: 0.2505\n",
      "rouge-l: 0.3027\n",
      "\n",
      "--- Article ID: 1217 ---\n",
      "Predicted Summary:\n",
      " lord drayson whose company powderject win pound contract provide smallpox vaccine government september terror attack give party day christmas\n",
      "Reference Summary:\n",
      " party build poll war chests labour party receive donation final quarter new figure show significant donation come retire millionaire businessman philanthropist sir christopher ondaatje give party sum refrigerator magnate william haughey obe give also donation top conservative scottish business group focus scotland institute international research world large independent conference company also among gift tory donation total bearwood corporate service liberal democrat large donor joseph rowntree reform trust ltd company promote political reform constitutional change give sum registered political party require set quarter donation headquarters local constituency party receive\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article ID: 945 ---\n",
      "Predicted Summary:\n",
      " say fine would levy employer licence would remove mr mcconnell add near nine per cent rise tax revenue new york bar restaurant ireland one point three per cent volume sale fall decline ban main point plan comprehensive ban smoking enclose public place scotland scottish green party health spokeswoman eleanor scott say pleased scotland would follow success story new york ireland\n",
      "Reference Summary:\n",
      " tell scottish parliament wednesday comprehensive ban smoke public place would introduce spring mr mcconnell say country health rate lamentable least smoking say fine would levy employer licence would remove earlier scottish executive consider range option agree unanimously introduce ban smoke public place statement parliament mr mcconnell say licensed trade would ask join expert committee prior ban come force health argument far outweigh linger public disquiet complete ban claim licensed trade job would lose tell msps clear scotland must hold back poor public health single big contribution devolve government make reduce toll preventable death cause smoke mr mcconnell claim evidence smoke ban help smoker either give quicker smoke less scottish conservative party leader david mcletchie question would exempt ban scottish green party health spokeswoman eleanor scott say pleased scotland would follow success story new york ireland\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article ID: 572 ---\n",
      "Predicted Summary:\n",
      " film direct jeunet receive best actress picture director nomination\n",
      "Reference Summary:\n",
      " tautou film top cesar prize nod french film long engagement receive nomination france cesar film award despite recent ruling french enough cesar organiser modify rule allow film compete film direct jeunet receive best actress picture director nomination last november court judge film american compete french film festival ruling mean movie film france used french actor technician eligible compete french prize film best film category include police drama quai de orfevres arnaud desplechin king queen abdellatif kechiche france number one film chorus\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article ID: 695 ---\n",
      "Predicted Summary:\n",
      " add pair bring real warmth saturday night end felt enough format show\n",
      "Reference Summary:\n",
      " johnny denise lose passport johnny vaughan denise van outen saturday night entertainment show passport paradise return screen bbc say bbc spokeswoman say graham norton strictly dance fever would priority much card next year concentrate moment strictly come dancing phenomenally well say\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article ID: 1975 ---\n",
      "Predicted Summary:\n",
      " still want drink merry long day winter draw good pub guide offer service give location address near recommend pub\n",
      "Reference Summary:\n",
      " new year texting break record mobile phone essential recent new year festivity party mood auld lang syne number text message send anything go midnight december midnight january text message send uk wish happy new year friend family via text message become staple ingredient year large party case new year eve party texting useful unable speak hear noisy background say restaurant use text message tell customer special offer promotion anyone need bit january cheer party season use service set jongleur comedy club text joke day\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from DL_models.bilstm_attention import BiLSTMSummarizer\n",
    "\n",
    "bilstmn = BiLSTMSummarizer(\"BBC\", bbc_processed_df)\n",
    "bilstmn.train()\n",
    "bilstmn.evaluate()\n",
    "bilstmn.show_samples(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dee05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training on IMDB ===\n",
      "Epoch 1 Loss: 0.9286\n",
      "Epoch 2 Loss: 0.8791\n",
      "Epoch 3 Loss: 0.8417\n",
      "Epoch 4 Loss: 0.8230\n",
      "Epoch 5 Loss: 0.7406\n",
      "Training completed in 88.23s\n",
      "Best Threshold: 0.40, F1: 0.4321\n",
      "\n",
      "ROUGE Scores:\n",
      "rouge-1: 0.4443\n",
      "rouge-2: 0.3931\n",
      "rouge-l: 0.4315\n",
      "\n",
      "--- Article ID: 3460 ---\n",
      "Predicted Summary:\n",
      " hit rock bottom right begin bad act jumbled sequence event mean sure freddy movie suppose dreamlike creepy one like train wreck poor sequence event awful plot setup feel like come terrible headache like get scar freddy annoyance see many time one nothing different lot time want take awful one liner get tv screen\n",
      "Reference Summary:\n",
      " hit rock bottom right begin bad act jumbled sequence event mean sure freddy movie suppose dreamlike creepy one like train wreck poor sequence event awful plot setup feel like come terrible headache like get scar directing totally fail none suspense well craft horror previous sequel find even death scene mostly crass moronic death food especially except one cool scene craft like comic book battle movie get point storyline lame lame lame lame\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article ID: 1213 ---\n",
      "Predicted Summary:\n",
      " high school student take health class year topic drug learn harm cause person talk still believe know drug really mess person anyway teacher want u watch naturally groan start sleep like rest class actually enjoy movie totally real sugar coat character amazing believable even plot outstandingly realistic believable like movie mainly get point effect drug take abuser consequence person deal everyone reassure nothing bad happen well let get serious anything happen small town even best friend like sam chris movie show person really learn lot watch pretty effective\n",
      "Reference Summary:\n",
      " \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article ID: 885 ---\n",
      "Predicted Summary:\n",
      " one bad movie ever see comedy funny also badly make top direction full unnecessary split screen effect two hero fantasy language annoy confuse quite lot touch others genitals time bad nonsense cheap attempt give movie appeal refer german history show sensitive aspect hero find climax show erkan stefan cure mentally ill woman joyful lifestyle expect anything good director michael bully herbig also make two funny tv show funny western movie nearly funny sf comedy movie\n",
      "Reference Summary:\n",
      " \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article ID: 2761 ---\n",
      "Predicted Summary:\n",
      " want daft little horror film hark back style eighty woodland flick might find enjoyment\n",
      "Reference Summary:\n",
      " film actually work fairly original idea never see nymph throw heaven horror movie\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article ID: 768 ---\n",
      "Predicted Summary:\n",
      " teacher show u movie first grade see since watch trailer though look like first grade movie think horrify movie could barely watch\n",
      "Reference Summary:\n",
      " teacher show u movie first grade see since watch trailer though look like first grade movie think horrify movie could barely watch\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "bilstm = BiLSTMSummarizer(\"IMDB\", imdb_processed_df)\n",
    "bilstm.train()\n",
    "bilstm.evaluate()\n",
    "bilstm.show_samples(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1ba7ef",
   "metadata": {},
   "source": [
    "FeedForward Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bc676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ===== Cell 1: Imports =====\n",
    "# from DL_models.FNN import (FeedForwardNet, extract_features, prepare_dataloaders,\n",
    "#                            compute_class_weight, train_model)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c821c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ===== Cell 2: Data Preparation =====\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# X_train_df, X_val_df, y_train, y_val = train_test_split(\n",
    "#     bbc_processed_df[['preprocessed_sentence']],\n",
    "#     bbc_processed_df['label'].values,\n",
    "#     test_size=0.2,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# X_train, X_val, vectorizer = extract_features(X_train_df, X_val_df)\n",
    "\n",
    "# train_loader, val_loader = prepare_dataloaders(X_train, y_train, X_val, y_val, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1adffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ===== Cell 3: Model Initialization =====\n",
    "# input_size = X_train.shape[1]\n",
    "# model = FeedForwardNet(input_size)\n",
    "# pos_weight = compute_class_weight(y_train).to(device)\n",
    "# criterion = torch.nn.BCELoss(pos_weight)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77061a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ===== Cell 4: Training =====\n",
    "# train_model(model, train_loader, val_loader, criterion, optimizer, device=device, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405290ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rouge_score import rouge_scorer\n",
    "# import numpy as np\n",
    "\n",
    "# # ===== Cell 6: ROUGE Evaluation =====\n",
    "# def evaluate_rouge(df, model, vectorizer, top_k=3):\n",
    "#     scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "#     scores = []\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for article_id in df['article_id'].unique():\n",
    "#             article_df = df[df['article_id'] == article_id]\n",
    "#             X = vectorizer.transform(article_df['preprocessed_sentence']).toarray()\n",
    "#             preds = model(torch.tensor(X, dtype=torch.float32)).numpy()\n",
    "\n",
    "#             top_indices = preds.argsort()[-top_k:][::-1]\n",
    "#             predicted_summary = \" \".join(article_df.iloc[top_indices][\"article_sentences\"])\n",
    "#             reference_summary = imdb_df.loc[article_id][\"Summary\"]\n",
    "\n",
    "#             score = scorer.score(reference_summary, predicted_summary)\n",
    "#             scores.append(score)\n",
    "\n",
    "#     return scores\n",
    "\n",
    "# rouge_scores = evaluate_rouge(bbc_processed_df, model, vectorizer)\n",
    "\n",
    "# avg_rouge1 = np.mean([s[\"rouge1\"].fmeasure for s in rouge_scores])\n",
    "# avg_rouge2 = np.mean([s[\"rouge2\"].fmeasure for s in rouge_scores])\n",
    "# avg_rougeL = np.mean([s[\"rougeL\"].fmeasure for s in rouge_scores])\n",
    "\n",
    "# print(f\"Average ROUGE-1: {avg_rouge1:.4f}\")\n",
    "# print(f\"Average ROUGE-2: {avg_rouge2:.4f}\")\n",
    "# print(f\"Average ROUGE-L: {avg_rougeL:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ca856e",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b595aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\fady\\appdata\\roaming\\python\\python312\\site-packages (from rouge) (1.16.0)\n",
      "Requirement already satisfied: rouge_score in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rouge_score) (2.2.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rouge_score) (2.1.3)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\fady\\appdata\\roaming\\python\\python312\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk->rouge_score) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk->rouge_score) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\fady\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk->rouge_score) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Fady\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,142,336</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m30\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │     \u001b[38;5;34m4,142,336\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,191,809</span> (15.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,191,809\u001b[0m (15.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,191,809</span> (15.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,191,809\u001b[0m (15.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6207 - loss: 0.6479\n",
      "Epoch 1: val_loss improved from inf to 0.61103, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 82ms/step - accuracy: 0.6209 - loss: 0.6477 - val_accuracy: 0.6716 - val_loss: 0.6110 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7358 - loss: 0.5395\n",
      "Epoch 2: val_loss did not improve from 0.61103\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.7358 - loss: 0.5395 - val_accuracy: 0.6587 - val_loss: 0.6332 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.8141 - loss: 0.4359\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.61103\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.8139 - loss: 0.4361 - val_accuracy: 0.6517 - val_loss: 0.6659 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.8610 - loss: 0.3611\n",
      "Epoch 4: val_loss did not improve from 0.61103\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.8609 - loss: 0.3612 - val_accuracy: 0.6378 - val_loss: 0.8631 - learning_rate: 5.0000e-04\n",
      "Epoch 4: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "--- Example Article ---\n",
      "Ad sales boost Time Warner profit\n",
      "\n",
      "Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.\n",
      "\n",
      "The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\n",
      "\n",
      "Time  ...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step\n",
      "\n",
      "--- Extracted Summary ---\n",
      "Ad sales boost Time Warner profit\n",
      "\n",
      "Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier. The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales.\n",
      "\n",
      "--- ROUGE Scores BBC ---\n",
      "rouge1: Precision: 0.7358, Recall: 0.2549, F1: 0.3786\n",
      "rouge2: Precision: 0.4423, Recall: 0.1513, F1: 0.2255\n",
      "rougeL: Precision: 0.5849, Recall: 0.2026, F1: 0.3010\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def compute_rouge_scores(pred_summary, reference_summary):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference_summary, pred_summary)\n",
    "    return scores\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, TimeDistributed, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# === Load your data ===\n",
    "\n",
    "texts = bbc_df[\"Article\"]\n",
    "summaries = ['starttoken ' + s + ' endtoken' for s in bbc_df[\"Summary\"]]\n",
    "\n",
    "# === Tokenizer setup ===\n",
    "text_tokenizer = Tokenizer(num_words=5000, oov_token='UNK')\n",
    "text_tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# === Parameters ===\n",
    "max_sent_len = 30\n",
    "max_sents = 5\n",
    "\n",
    "# === Preprocess articles ===\n",
    "def preprocess_articles(texts):\n",
    "    all_articles = []\n",
    "    for article in texts:\n",
    "        sents = sent_tokenize(article)[:max_sents]\n",
    "        tokenized = text_tokenizer.texts_to_sequences(sents)\n",
    "        padded = pad_sequences(tokenized, maxlen=max_sent_len, padding='post')\n",
    "        padded = np.pad(padded, ((0, max_sents - len(padded)), (0, 0)), mode='constant')\n",
    "        all_articles.append(padded)\n",
    "    return np.array(all_articles)\n",
    "\n",
    "X = preprocess_articles(texts)\n",
    "\n",
    "# # === Generate labels for extractive summary ===\n",
    "def label_sentences(texts, summaries, top_n=3):\n",
    "    labels = []\n",
    "    for article, summary in zip(texts, summaries):\n",
    "        sents = sent_tokenize(article)[:max_sents]\n",
    "        summary_text = summary.replace(\"starttoken \", \"\").replace(\" endtoken\", \"\")\n",
    "        \n",
    "        if not sents:\n",
    "            labels.append(np.zeros(max_sents))\n",
    "            continue\n",
    "\n",
    "        # Compute TF-IDF similarity\n",
    "        tfidf = TfidfVectorizer().fit(sents + [summary_text])\n",
    "        sent_vecs = tfidf.transform(sents)\n",
    "        summary_vec = tfidf.transform([summary_text])\n",
    "        sims = cosine_similarity(summary_vec, sent_vecs).flatten()\n",
    "\n",
    "        # Get top-N most similar sentence indices\n",
    "        top_indices = sims.argsort()[-top_n:]\n",
    "        label = np.zeros(len(sents))\n",
    "        label[top_indices] = 1\n",
    "\n",
    "        # Pad to max_sents\n",
    "        padded_label = np.pad(label, (0, max_sents - len(label)), 'constant')\n",
    "        labels.append(padded_label)\n",
    "        \n",
    "    return np.array(labels)\n",
    "\n",
    "\n",
    "y = label_sentences(texts, summaries, top_n=3)\n",
    "\n",
    "# === Train-test split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# === Model Definition ===\n",
    "input_layer = Input(shape=(max_sents, max_sent_len))\n",
    "embedding_layer = TimeDistributed(Embedding(input_dim=len(text_tokenizer.word_index)+1, output_dim=128))(input_layer)\n",
    "lstm_layer = TimeDistributed(LSTM(64))(embedding_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(lstm_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# === Callbacks ===\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-5, verbose=1)\n",
    "checkpoint = ModelCheckpoint('best_extractive_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "# === Train ===\n",
    "model.fit(\n",
    "    X_train,\n",
    "    np.expand_dims(y_train, -1),\n",
    "    validation_split=0.1,\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# === Inference ===\n",
    "\n",
    "def extract_summary(article):\n",
    "    sents = sent_tokenize(article)[:max_sents]\n",
    "    tokenized = text_tokenizer.texts_to_sequences(sents)\n",
    "    padded = pad_sequences(tokenized, maxlen=max_sent_len, padding='post')\n",
    "    padded = np.pad(padded, ((0, max_sents - len(padded)), (0, 0)), mode='constant')\n",
    "    \n",
    "    prediction = model.predict(np.expand_dims(padded, 0))[0].flatten()\n",
    "    \n",
    "    # === Dynamic threshold based on mean score\n",
    "    threshold = prediction.mean()\n",
    "    \n",
    "    summary = [s for i, s in enumerate(sents) if prediction[i] > threshold]\n",
    "    # Fallback if no sentence is selected\n",
    "    if not summary:\n",
    "        top_idx = prediction.argmax()\n",
    "        summary = [sents[top_idx]]\n",
    "    \n",
    "    return ' '.join(summary)\n",
    "\n",
    "# === Example Prediction + Evaluation ===\n",
    "example_idx = 0\n",
    "article = texts.iloc[example_idx]\n",
    "reference_summary = bbc_df[\"Summary\"].iloc[example_idx].replace(\"starttoken \", \"\").replace(\" endtoken\", \"\")\n",
    "\n",
    "print(\"\\n--- Example Article ---\")\n",
    "print(article[:500], \"...\")\n",
    "\n",
    "# Predict summary\n",
    "pred_summary = extract_summary(article)\n",
    "print(\"\\n--- Extracted Summary ---\")\n",
    "print(pred_summary)\n",
    "\n",
    "# Compute ROUGE\n",
    "rouge_scores = compute_rouge_scores(pred_summary, reference_summary)\n",
    "print(\"\\n--- ROUGE Scores BBC ---\")\n",
    "for key, value in rouge_scores.items():\n",
    "    print(f\"{key}: Precision: {value.precision:.4f}, Recall: {value.recall:.4f}, F1: {value.fmeasure:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e42c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\fady\\appdata\\roaming\\python\\python312\\site-packages (from rouge) (1.16.0)\n",
      "Requirement already satisfied: rouge_score in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rouge_score) (2.2.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rouge_score) (2.1.3)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\fady\\appdata\\roaming\\python\\python312\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk->rouge_score) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk->rouge_score) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\fady\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk->rouge_score) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Fady\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,236,200</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m30\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m100\u001b[0m)     │     \u001b[38;5;34m3,236,200\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m42,240\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,278,505</span> (12.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,278,505\u001b[0m (12.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,305</span> (165.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m42,305\u001b[0m (165.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,236,200</span> (12.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,236,200\u001b[0m (12.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9857 - loss: 0.0331\n",
      "Epoch 1: val_loss improved from inf to 0.00001, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 59ms/step - accuracy: 0.9857 - loss: 0.0331 - val_accuracy: 1.0000 - val_loss: 1.0450e-05 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.0317e-05\n",
      "Epoch 2: val_loss improved from 0.00001 to 0.00000, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.0315e-05 - val_accuracy: 1.0000 - val_loss: 2.3533e-06 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1974/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 2.6681e-06\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 3: val_loss improved from 0.00000 to 0.00000, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 2.6675e-06 - val_accuracy: 1.0000 - val_loss: 7.4317e-07 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 1.0023e-06\n",
      "Epoch 4: val_loss improved from 0.00000 to 0.00000, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 1.0023e-06 - val_accuracy: 1.0000 - val_loss: 3.8727e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 5.1363e-07\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 5: val_loss improved from 0.00000 to 0.00000, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 5.1358e-07 - val_accuracy: 1.0000 - val_loss: 1.7012e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 2.4595e-07\n",
      "Epoch 6: val_loss improved from 0.00000 to 0.00000, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 2.4593e-07 - val_accuracy: 1.0000 - val_loss: 9.8545e-08 - learning_rate: 2.5000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 1.3991e-07\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 7: val_loss improved from 0.00000 to 0.00000, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 1.3990e-07 - val_accuracy: 1.0000 - val_loss: 4.7582e-08 - learning_rate: 2.5000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 7.3384e-08\n",
      "Epoch 8: val_loss improved from 0.00000 to 0.00000, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 7.3380e-08 - val_accuracy: 1.0000 - val_loss: 2.9140e-08 - learning_rate: 1.2500e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 4.4152e-08\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 9: val_loss improved from 0.00000 to 0.00000, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 4.4149e-08 - val_accuracy: 1.0000 - val_loss: 1.5255e-08 - learning_rate: 1.2500e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 2.5486e-08\n",
      "Epoch 10: val_loss improved from 0.00000 to 0.00000, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 2.5485e-08 - val_accuracy: 1.0000 - val_loss: 1.0603e-08 - learning_rate: 6.2500e-05\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "\n",
      "--- IMDB Sample Article ---\n",
      "One of the other reviewers has mentioned that after watching just Oz episode you ll be hooked They are right as this is exactly what happened with me The first thing that struck me about Oz was its brutality and unflinching scenes of violence which set in right from the word GO Trust me this is not show for the faint hearted or timid This show pulls no punches with regards to drugs sex or violence Its is hardcore in the classic use of the word It is called OZ as that is the nickname given to the ...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\n",
      "--- Extracted Summary ---\n",
      "One of the other reviewers has mentioned that after watching just Oz episode you ll be hooked They are right as this is exactly what happened with me The first thing that struck me about Oz was its brutality and unflinching scenes of violence which set in right from the word GO Trust me this is not show for the faint hearted or timid This show pulls no punches with regards to drugs sex or violence Its is hardcore in the classic use of the word It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary It focuses mainly on Emerald City an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda Em City is home to many Aryans Muslims gangstas Latinos Christians Italians Irish and more so scuffles death stares dodgy dealings and shady agreements are never far away would say the main appeal of the show is due to the fact that it goes where other shows wouldn dare Forget pretty pictures painted for mainstream audiences forget charm forget romance OZ doesn mess around The first episode ever saw struck me as so nasty it was surreal couldn say was ready for it but as watched more developed taste for Oz and got accustomed to the high levels of graphic violence Not just violence but injustice crooked guards who ll be sold out for nickel inmates who ll kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience Watching Oz you may become comfortable with what is uncomfortable viewing thats if you can get in touch with your darker side\n",
      "\n",
      "--- ROUGE Scores ---\n",
      "rouge1: Precision: 0.1860, Recall: 1.0000, F1: 0.3137\n",
      "rouge2: Precision: 0.1800, Recall: 0.9818, F1: 0.3042\n",
      "rougeL: Precision: 0.1860, Recall: 1.0000, F1: 0.3137\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# !pip install rouge\n",
    "# !pip install rouge_score\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def compute_rouge_scores(pred_summary, reference_summary):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference_summary, pred_summary)\n",
    "    return scores\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, TimeDistributed, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "nltk.download('punkt')\n",
    "# === Tokenizer setup ===\n",
    "text_tokenizer = Tokenizer(num_words=5000, oov_token='UNK')\n",
    "text_tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# === Parameters ===\n",
    "max_sent_len = 30\n",
    "max_sents = 5\n",
    "\n",
    "# === Preprocess articles ===\n",
    "def preprocess_articles(texts):\n",
    "    all_articles = []\n",
    "    for article in texts:\n",
    "        sents = sent_tokenize(article)[:max_sents]\n",
    "        tokenized = text_tokenizer.texts_to_sequences(sents)\n",
    "        padded = pad_sequences(tokenized, maxlen=max_sent_len, padding='post')\n",
    "        padded = np.pad(padded, ((0, max_sents - len(padded)), (0, 0)), mode='constant')\n",
    "        all_articles.append(padded)\n",
    "    return np.array(all_articles)\n",
    "\n",
    "\n",
    "\n",
    "# # === Generate labels for extractive summary ===\n",
    "def label_sentences(texts, summaries, top_n=3):\n",
    "    labels = []\n",
    "    for article, summary in zip(texts, summaries):\n",
    "        sents = sent_tokenize(article)[:max_sents]\n",
    "        summary_text = summary.replace(\"starttoken \", \"\").replace(\" endtoken\", \"\")\n",
    "        \n",
    "        if not sents:\n",
    "            labels.append(np.zeros(max_sents))\n",
    "            continue\n",
    "\n",
    "        # Compute TF-IDF similarity\n",
    "        tfidf = TfidfVectorizer().fit(sents + [summary_text])\n",
    "        sent_vecs = tfidf.transform(sents)\n",
    "        summary_vec = tfidf.transform([summary_text])\n",
    "        sims = cosine_similarity(summary_vec, sent_vecs).flatten()\n",
    "\n",
    "        # Get top-N most similar sentence indices\n",
    "        top_indices = sims.argsort()[-top_n:]\n",
    "        label = np.zeros(len(sents))\n",
    "        label[top_indices] = 1\n",
    "\n",
    "        # Pad to max_sents\n",
    "        padded_label = np.pad(label, (0, max_sents - len(label)), 'constant')\n",
    "        labels.append(padded_label)\n",
    "        \n",
    "    return np.array(labels)\n",
    "\n",
    "\n",
    "\n",
    "# === Model Definition ===\n",
    "input_layer = Input(shape=(max_sents, max_sent_len))\n",
    "embedding_layer = TimeDistributed(Embedding(input_dim=len(text_tokenizer.word_index)+1, output_dim=100,trainable=False))(input_layer)\n",
    "lstm_layer = TimeDistributed(LSTM(64, dropout=0.3, recurrent_dropout=0.3))(embedding_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(lstm_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# === Callbacks ===\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-5, verbose=1)\n",
    "checkpoint = ModelCheckpoint('best_extractive_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "\n",
    "# === Inference ===\n",
    "\n",
    "def extract_summary(article):\n",
    "    sents = sent_tokenize(article)[:max_sents]\n",
    "    tokenized = text_tokenizer.texts_to_sequences(sents)\n",
    "    padded = pad_sequences(tokenized, maxlen=max_sent_len, padding='post')\n",
    "    padded = np.pad(padded, ((0, max_sents - len(padded)), (0, 0)), mode='constant')\n",
    "    \n",
    "    prediction = model.predict(np.expand_dims(padded, 0))[0].flatten()\n",
    "    \n",
    "    # === Dynamic threshold based on mean score\n",
    "    threshold = prediction.mean()\n",
    "    \n",
    "    summary = [s for i, s in enumerate(sents) if prediction[i] > threshold]\n",
    "    # Fallback if no sentence is selected\n",
    "    if not summary:\n",
    "        top_idx = prediction.argmax()\n",
    "        summary = [sents[top_idx]]\n",
    "    \n",
    "    return ' '.join(summary)\n",
    "\n",
    "\n",
    "# === Example Prediction + Evaluation ===\n",
    "\n",
    "\n",
    "# === Load IMDB data ===\n",
    "texts = imdb_df[\"Article\"]\n",
    "summaries = ['starttoken ' + s + ' endtoken' for s in imdb_df[\"Summary\"]]\n",
    "\n",
    "# === Preprocess ===\n",
    "X = preprocess_articles(texts)\n",
    "y = label_sentences(texts, summaries, top_n=3)\n",
    "\n",
    "# === Train-test split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# === Train the model on IMDb dataset ===\n",
    "model.fit(\n",
    "    X_train,\n",
    "    np.expand_dims(y_train, -1),\n",
    "    validation_split=0.1,\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# === Evaluate on an IMDb example ===\n",
    "example_idx = 0\n",
    "article = texts.iloc[example_idx]\n",
    "reference_summary = imdb_df[\"Summary\"].iloc[example_idx].replace(\"starttoken \", \"\").replace(\" endtoken\", \"\")\n",
    "\n",
    "print(\"\\n--- IMDB Sample Article ---\")\n",
    "print(article[:500], \"...\")\n",
    "\n",
    "# Predict summary\n",
    "pred_summary = extract_summary(article)\n",
    "print(\"\\n--- Extracted Summary ---\")\n",
    "print(pred_summary)\n",
    "\n",
    "# Compute ROUGE\n",
    "rouge_scores = compute_rouge_scores(pred_summary, reference_summary)\n",
    "print(\"\\n--- ROUGE Scores ---\")\n",
    "for key, value in rouge_scores.items():\n",
    "    print(f\"{key}: Precision: {value.precision:.4f}, Recall: {value.recall:.4f}, F1: {value.fmeasure:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
