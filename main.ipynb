{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d0b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from utils import prepare_labeled_sentences, prepare_labeled_sentences_spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd3f019",
   "metadata": {},
   "source": [
    "Read Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d4506ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BBC Dataset\n",
    "bbc_df = pd.read_csv(\"data/bbc/bbc_dataset.csv\")\n",
    "\n",
    "#IMDB Dataset\n",
    "imdb_df = pd.read_csv(\"data/imdb/imdb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e05b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBC Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Musicians to tackle US red tape\\n\\nMusicians' ...</td>\n",
       "      <td>Nigel McCune from the Musicians' Union said Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U2's desire to be number one\\n\\nU2, who have w...</td>\n",
       "      <td>But they still want more.They have to want to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rocker Doherty in on-stage fight\\n\\nRock singe...</td>\n",
       "      <td>Babyshambles, which he formed after his acrimo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Snicket tops US box office chart\\n\\nThe film a...</td>\n",
       "      <td>A Series of Unfortunate Events also stars Scot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ocean's Twelve raids box office\\n\\nOcean's Twe...</td>\n",
       "      <td>Ocean's Twelve, the crime caper sequel starrin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  \\\n",
       "0  Musicians to tackle US red tape\\n\\nMusicians' ...   \n",
       "1  U2's desire to be number one\\n\\nU2, who have w...   \n",
       "2  Rocker Doherty in on-stage fight\\n\\nRock singe...   \n",
       "3  Snicket tops US box office chart\\n\\nThe film a...   \n",
       "4  Ocean's Twelve raids box office\\n\\nOcean's Twe...   \n",
       "\n",
       "                                             Summary  \n",
       "0  Nigel McCune from the Musicians' Union said Br...  \n",
       "1  But they still want more.They have to want to ...  \n",
       "2  Babyshambles, which he formed after his acrimo...  \n",
       "3  A Series of Unfortunate Events also stars Scot...  \n",
       "4  Ocean's Twelve, the crime caper sequel starrin...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview to confirm structure\n",
    "print(\"BBC Sample:\")\n",
    "display(bbc_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a3b0b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production The filming tech...</td>\n",
       "      <td>A wonderful little production The filming tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was wonderful way to spend time...</td>\n",
       "      <td>I thought it was proof that Woody Allen is sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there a family where little boy Jake...</td>\n",
       "      <td>Basically there a family where little boy Jake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei Love in the Time of Money is vis...</td>\n",
       "      <td>Petter Mattei Love in the Time of Money is vis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  \\\n",
       "0  One of the other reviewers has mentioned that ...   \n",
       "1  A wonderful little production The filming tech...   \n",
       "2  I thought this was wonderful way to spend time...   \n",
       "3  Basically there a family where little boy Jake...   \n",
       "4  Petter Mattei Love in the Time of Money is vis...   \n",
       "\n",
       "                                             Summary  \n",
       "0  One of the other reviewers has mentioned that ...  \n",
       "1  A wonderful little production The filming tech...  \n",
       "2  I thought it was proof that Woody Allen is sti...  \n",
       "3  Basically there a family where little boy Jake...  \n",
       "4  Petter Mattei Love in the Time of Money is vis...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"IMDB Sample:\")\n",
    "display(imdb_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3c1a94",
   "metadata": {},
   "source": [
    "Preprocess BBC Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b005f2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing articles: 100%|██████████| 2225/2225 [05:07<00:00,  7.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process the BBC dataset\n",
    "bbc_labeled_data = prepare_labeled_sentences_spacy(bbc_df)\n",
    "\n",
    "# Convert to DataFrame for modeling\n",
    "bbc_processed_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"article_id\": item[\"article_id\"],\n",
    "            \"article_sentences\": item[\"raw_sentence\"],\n",
    "            \"preprocessed_sentence\": item[\"preprocessed_sentence\"],\n",
    "            \"label\": item[\"label\"],\n",
    "        }\n",
    "        for item in bbc_labeled_data\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3309143b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41677, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6a9ee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary sentences: 16543 out of 41677 (39.69%)\n",
      "\n",
      "Example summary sentences:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_sentences</th>\n",
       "      <th>preprocessed_sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Musicians to tackle US red tape  Musicians' gr...</td>\n",
       "      <td>musician tackle u red tape musician group tack...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>A singer hoping to perform in the US can expec...</td>\n",
       "      <td>singer hop perform u expect pay simply obtain ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nigel McCune from the Musicians' Union said Br...</td>\n",
       "      <td>nigel mccune musician union say british musici...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                  article_sentences  \\\n",
       "0           0  Musicians to tackle US red tape  Musicians' gr...   \n",
       "1           0  A singer hoping to perform in the US can expec...   \n",
       "4           0  Nigel McCune from the Musicians' Union said Br...   \n",
       "\n",
       "                               preprocessed_sentence  label  \n",
       "0  musician tackle u red tape musician group tack...      1  \n",
       "1  singer hop perform u expect pay simply obtain ...      1  \n",
       "4  nigel mccune musician union say british musici...      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count how many sentences are labeled as summary sentences\n",
    "summary_count = bbc_processed_df['label'].sum()\n",
    "total_count = len(bbc_processed_df)\n",
    "print(f\"Summary sentences: {summary_count} out of {total_count} ({summary_count/total_count:.2%})\")\n",
    "\n",
    "# Show some examples of sentences included in summaries\n",
    "print(\"\\nExample summary sentences:\")\n",
    "display(bbc_processed_df[bbc_processed_df['label'] == 1].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65bf0a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_sentences</th>\n",
       "      <th>preprocessed_sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Musicians to tackle US red tape  Musicians' gr...</td>\n",
       "      <td>musician tackle u red tape musician group tack...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>A singer hoping to perform in the US can expec...</td>\n",
       "      <td>singer hop perform u expect pay simply obtain ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Groups including the Musicians' Union are call...</td>\n",
       "      <td>group include musician union call end raw deal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>US acts are not faced with comparable expense ...</td>\n",
       "      <td>u act face comparable expense bureaucracy visi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nigel McCune from the Musicians' Union said Br...</td>\n",
       "      <td>nigel mccune musician union say british musici...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>A sponsor has to make a petition on their beha...</td>\n",
       "      <td>sponsor make petition behalf form amount nearl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>\"If you make a mistake on your form, you risk ...</td>\n",
       "      <td>make mistake form risk ban thus ability career...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>\"The US is the world's biggest music market, w...</td>\n",
       "      <td>u world big music market mean something creaky...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>\"The current situation is preventing British a...</td>\n",
       "      <td>current situation prevent british act maintain...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>The Musicians' Union stance is being endorsed ...</td>\n",
       "      <td>musician union stance endorse music manager fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>The MMF's general secretary James Seller said:...</td>\n",
       "      <td>mmf general secretary james seller say imagine...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>Every member would have to travel to London to...</td>\n",
       "      <td>every member would travel london visa process</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>\"The US market is seen as the holy grail and o...</td>\n",
       "      <td>u market see holy grail one benchmark success ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>\"It's still very important, but there are othe...</td>\n",
       "      <td>still important market like europe india china...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>A Department for Media, Culture and Sport spok...</td>\n",
       "      <td>department medium culture sport spokeswoman sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>A US Embassy spokesman said: \"We are aware tha...</td>\n",
       "      <td>u embassy spokesman say aware entertainer requ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>\"We are aware of the importance of cultural ex...</td>\n",
       "      <td>aware importance cultural exchange best facili...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>U2's desire to be number one  U2, who have won...</td>\n",
       "      <td>desire number one win three prestigious grammy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>The most popular groups in the history of rock...</td>\n",
       "      <td>popular group history rock several thing common</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>The music must be inspired and appeal across g...</td>\n",
       "      <td>music must inspire appeal across generation di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>But such success is down to more than music.</td>\n",
       "      <td>success music</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>They have to be compelling performers, charism...</td>\n",
       "      <td>compel performer charismatic intelligent enoug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>They also have to want it.</td>\n",
       "      <td>also want</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>They have to want to be the biggest band ever ...</td>\n",
       "      <td>want big band ever stop want</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>The Beatles had it, the Rolling Stones still h...</td>\n",
       "      <td>beatles roll stone still rem hold onto queen c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>And U2 have it in spades, and keep churning it...</td>\n",
       "      <td>spade keep churn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>Their new album, How To Dismantle An Atomic Bo...</td>\n",
       "      <td>new album dismantle atomic bomb come year scho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>They may have lost some of the edginess and ra...</td>\n",
       "      <td>may lose edginess raw youthful force propel to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>Vertigo, the first single from the new album, ...</td>\n",
       "      <td>vertigo first single new album go straight uk ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>\"The challenge is to be bigger and bolder and ...</td>\n",
       "      <td>challenge big bolder good make record whole wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>Drummer Larry Mullen Jr echoed those sentiment...</td>\n",
       "      <td>drummer larry mullen jr echoed sentiment compe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>We don't want to be thought of as a veteran ba...</td>\n",
       "      <td>want think veteran band</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>The band have done \"everything in their consid...</td>\n",
       "      <td>band everything considerable power ensure rema...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>\"This makes them hugely determined and formida...</td>\n",
       "      <td>make hugely determine formidable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>He added: \"They are equally determined to push...</td>\n",
       "      <td>add equally determine push make music continue...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>\"As such, they've constantly re-invented and c...</td>\n",
       "      <td>constantly challenge</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>They are, perhaps, alone as the only rock band...</td>\n",
       "      <td>perhaps alone rock band get well age</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>The other key ingredient was the fact they wer...</td>\n",
       "      <td>key ingredient fact highly organise mr rees say</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>\"They do everything in the right way.\"</td>\n",
       "      <td>everything right way</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>The group were born when Mullen put an appeal ...</td>\n",
       "      <td>group bear mullen put appeal bandmates high sc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>Dick Evans soon dropped out and the four-piece...</td>\n",
       "      <td>dick evans soon drop know feedback hype settle</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>By 1978, they had won a talent contest and got...</td>\n",
       "      <td>win talent contest get notice manager paul mcg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>\"They were brilliant, but very coarse,\" McGuin...</td>\n",
       "      <td>brilliant coarse mcguinness recently say</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>\"In a way, they were doing exactly what they d...</td>\n",
       "      <td>way exactly</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>Only badly.\"</td>\n",
       "      <td>badly</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>They struggled to attract record company atten...</td>\n",
       "      <td>struggle attract record company attention late...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>They released two Ireland-only singles, which ...</td>\n",
       "      <td>release two single top national chart lead dea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>The stadium-filling, anthemic sound was U2's a...</td>\n",
       "      <td>anthemic sound aim start third album war saw m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>Songs like Sunday Bloody Sunday and New Year's...</td>\n",
       "      <td>song like sunday bloody sunday new year day br...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>His stage performances - which included flag-w...</td>\n",
       "      <td>stage performance include earn reputation elec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>In 1987, The Joshua Tree broke sales records a...</td>\n",
       "      <td>joshua tree break sale record saw band reach h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>Those songs took the band's epic, atmospheric ...</td>\n",
       "      <td>song take band epic atmospheric sound simple p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>The end of the decade marked a crucial point f...</td>\n",
       "      <td>end decade mark crucial point band reach top s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>These came in the form of explorations of diff...</td>\n",
       "      <td>come form exploration different branch rock fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>The Achtung Baby album in 1991 was followed by...</td>\n",
       "      <td>achtung baby album follow zooropa pop correspo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>He was also building a parallel reputation - n...</td>\n",
       "      <td>also build parallel reputation always pleasure...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "      <td>Before the release of How To Dismantle An Atom...</td>\n",
       "      <td>release dismantle atomic bomb sell million alb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "      <td>But they still want more.</td>\n",
       "      <td>still want</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>Rocker Doherty in on-stage fight  Rock singer ...</td>\n",
       "      <td>rocker doherty fight rock singer pete doherty ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>Babyshambles played for 5,000 fans at London's...</td>\n",
       "      <td>babyshambles play fan london brixton academy t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id                                  article_sentences  \\\n",
       "0            0  Musicians to tackle US red tape  Musicians' gr...   \n",
       "1            0  A singer hoping to perform in the US can expec...   \n",
       "2            0  Groups including the Musicians' Union are call...   \n",
       "3            0  US acts are not faced with comparable expense ...   \n",
       "4            0  Nigel McCune from the Musicians' Union said Br...   \n",
       "5            0  A sponsor has to make a petition on their beha...   \n",
       "6            0  \"If you make a mistake on your form, you risk ...   \n",
       "7            0  \"The US is the world's biggest music market, w...   \n",
       "8            0  \"The current situation is preventing British a...   \n",
       "9            0  The Musicians' Union stance is being endorsed ...   \n",
       "10           0  The MMF's general secretary James Seller said:...   \n",
       "11           0  Every member would have to travel to London to...   \n",
       "12           0  \"The US market is seen as the holy grail and o...   \n",
       "13           0  \"It's still very important, but there are othe...   \n",
       "14           0  A Department for Media, Culture and Sport spok...   \n",
       "15           0  A US Embassy spokesman said: \"We are aware tha...   \n",
       "16           0  \"We are aware of the importance of cultural ex...   \n",
       "17           1  U2's desire to be number one  U2, who have won...   \n",
       "18           1  The most popular groups in the history of rock...   \n",
       "19           1  The music must be inspired and appeal across g...   \n",
       "20           1       But such success is down to more than music.   \n",
       "21           1  They have to be compelling performers, charism...   \n",
       "22           1                         They also have to want it.   \n",
       "23           1  They have to want to be the biggest band ever ...   \n",
       "24           1  The Beatles had it, the Rolling Stones still h...   \n",
       "25           1  And U2 have it in spades, and keep churning it...   \n",
       "26           1  Their new album, How To Dismantle An Atomic Bo...   \n",
       "27           1  They may have lost some of the edginess and ra...   \n",
       "28           1  Vertigo, the first single from the new album, ...   \n",
       "29           1  \"The challenge is to be bigger and bolder and ...   \n",
       "30           1  Drummer Larry Mullen Jr echoed those sentiment...   \n",
       "31           1  We don't want to be thought of as a veteran ba...   \n",
       "32           1  The band have done \"everything in their consid...   \n",
       "33           1  \"This makes them hugely determined and formida...   \n",
       "34           1  He added: \"They are equally determined to push...   \n",
       "35           1  \"As such, they've constantly re-invented and c...   \n",
       "36           1  They are, perhaps, alone as the only rock band...   \n",
       "37           1  The other key ingredient was the fact they wer...   \n",
       "38           1             \"They do everything in the right way.\"   \n",
       "39           1  The group were born when Mullen put an appeal ...   \n",
       "40           1  Dick Evans soon dropped out and the four-piece...   \n",
       "41           1  By 1978, they had won a talent contest and got...   \n",
       "42           1  \"They were brilliant, but very coarse,\" McGuin...   \n",
       "43           1  \"In a way, they were doing exactly what they d...   \n",
       "44           1                                       Only badly.\"   \n",
       "45           1  They struggled to attract record company atten...   \n",
       "46           1  They released two Ireland-only singles, which ...   \n",
       "47           1  The stadium-filling, anthemic sound was U2's a...   \n",
       "48           1  Songs like Sunday Bloody Sunday and New Year's...   \n",
       "49           1  His stage performances - which included flag-w...   \n",
       "50           1  In 1987, The Joshua Tree broke sales records a...   \n",
       "51           1  Those songs took the band's epic, atmospheric ...   \n",
       "52           1  The end of the decade marked a crucial point f...   \n",
       "53           1  These came in the form of explorations of diff...   \n",
       "54           1  The Achtung Baby album in 1991 was followed by...   \n",
       "55           1  He was also building a parallel reputation - n...   \n",
       "56           1  Before the release of How To Dismantle An Atom...   \n",
       "57           1                          But they still want more.   \n",
       "58           2  Rocker Doherty in on-stage fight  Rock singer ...   \n",
       "59           2  Babyshambles played for 5,000 fans at London's...   \n",
       "\n",
       "                                preprocessed_sentence  label  \n",
       "0   musician tackle u red tape musician group tack...      1  \n",
       "1   singer hop perform u expect pay simply obtain ...      1  \n",
       "2   group include musician union call end raw deal...      0  \n",
       "3   u act face comparable expense bureaucracy visi...      0  \n",
       "4   nigel mccune musician union say british musici...      1  \n",
       "5   sponsor make petition behalf form amount nearl...      0  \n",
       "6   make mistake form risk ban thus ability career...      0  \n",
       "7   u world big music market mean something creaky...      1  \n",
       "8   current situation prevent british act maintain...      1  \n",
       "9   musician union stance endorse music manager fo...      1  \n",
       "10  mmf general secretary james seller say imagine...      0  \n",
       "11      every member would travel london visa process      0  \n",
       "12  u market see holy grail one benchmark success ...      0  \n",
       "13  still important market like europe india china...      0  \n",
       "14  department medium culture sport spokeswoman sa...      0  \n",
       "15  u embassy spokesman say aware entertainer requ...      1  \n",
       "16  aware importance cultural exchange best facili...      0  \n",
       "17  desire number one win three prestigious grammy...      1  \n",
       "18    popular group history rock several thing common      0  \n",
       "19  music must inspire appeal across generation di...      0  \n",
       "20                                      success music      0  \n",
       "21  compel performer charismatic intelligent enoug...      0  \n",
       "22                                          also want      1  \n",
       "23                       want big band ever stop want      1  \n",
       "24  beatles roll stone still rem hold onto queen c...      0  \n",
       "25                                   spade keep churn      0  \n",
       "26  new album dismantle atomic bomb come year scho...      1  \n",
       "27  may lose edginess raw youthful force propel to...      0  \n",
       "28  vertigo first single new album go straight uk ...      1  \n",
       "29  challenge big bolder good make record whole wo...      1  \n",
       "30  drummer larry mullen jr echoed sentiment compe...      0  \n",
       "31                            want think veteran band      1  \n",
       "32  band everything considerable power ensure rema...      1  \n",
       "33                   make hugely determine formidable      0  \n",
       "34  add equally determine push make music continue...      0  \n",
       "35                               constantly challenge      0  \n",
       "36               perhaps alone rock band get well age      1  \n",
       "37    key ingredient fact highly organise mr rees say      0  \n",
       "38                               everything right way      0  \n",
       "39  group bear mullen put appeal bandmates high sc...      0  \n",
       "40     dick evans soon drop know feedback hype settle      0  \n",
       "41  win talent contest get notice manager paul mcg...      0  \n",
       "42           brilliant coarse mcguinness recently say      0  \n",
       "43                                        way exactly      0  \n",
       "44                                              badly      0  \n",
       "45  struggle attract record company attention late...      0  \n",
       "46  release two single top national chart lead dea...      0  \n",
       "47  anthemic sound aim start third album war saw m...      1  \n",
       "48  song like sunday bloody sunday new year day br...      1  \n",
       "49  stage performance include earn reputation elec...      0  \n",
       "50  joshua tree break sale record saw band reach h...      1  \n",
       "51  song take band epic atmospheric sound simple p...      0  \n",
       "52  end decade mark crucial point band reach top s...      1  \n",
       "53  come form exploration different branch rock fo...      1  \n",
       "54  achtung baby album follow zooropa pop correspo...      0  \n",
       "55  also build parallel reputation always pleasure...      0  \n",
       "56  release dismantle atomic bomb sell million alb...      1  \n",
       "57                                         still want      1  \n",
       "58  rocker doherty fight rock singer pete doherty ...      1  \n",
       "59  babyshambles play fan london brixton academy t...      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_processed_df.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa7f591",
   "metadata": {},
   "source": [
    "Preprocessed IMDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ac0d9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing articles: 100%|██████████| 4000/4000 [03:45<00:00, 17.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process the BBC dataset\n",
    "imdb_labeled_df = prepare_labeled_sentences_spacy(imdb_df[:4000])\n",
    "\n",
    "# Convert to DataFrame for modeling\n",
    "imdb_processed_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"article_id\": item[\"article_id\"],\n",
    "            \"article_sentences\": item[\"raw_sentence\"],\n",
    "            \"preprocessed_sentence\": item[\"preprocessed_sentence\"],\n",
    "            \"label\": item[\"label\"],\n",
    "        }\n",
    "        for item in imdb_labeled_df\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a67dd484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13024, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64901be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary sentences: 2934 out of 13024 (22.53%)\n",
      "\n",
      "Example summary sentences:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_sentences</th>\n",
       "      <th>preprocessed_sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A wonderful little production The filming tech...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>Basically there a family where little boy Jake...</td>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>Petter Mattei Love in the Time of Money is vis...</td>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id                                  article_sentences  \\\n",
       "2            1  A wonderful little production The filming tech...   \n",
       "9            3  Basically there a family where little boy Jake...   \n",
       "11           4  Petter Mattei Love in the Time of Money is vis...   \n",
       "\n",
       "                                preprocessed_sentence  label  \n",
       "2   wonderful little production filming technique ...      1  \n",
       "9   basically family little boy jake think zombie ...      1  \n",
       "11  petter mattei love time money visually stunnin...      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count how many sentences are labeled as summary sentences\n",
    "summary_count = imdb_processed_df['label'].sum()\n",
    "total_count = len(imdb_processed_df)\n",
    "print(f\"Summary sentences: {summary_count} out of {total_count} ({summary_count/total_count:.2%})\")\n",
    "\n",
    "# Show some examples of sentences included in summaries\n",
    "print(\"\\nExample summary sentences:\")\n",
    "display(imdb_processed_df[imdb_processed_df['label'] == 1].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a84aae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A wonderful little production The filming technique is very unassuming very old time BBC fashion and gives comforting and sometimes discomforting sense of realism to the entire piece The actors are extremely well chosen Michael Sheen not only has got all the polari\n"
     ]
    }
   ],
   "source": [
    "print(imdb_processed_df[\"article_sentences\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e1a68bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_sentences</th>\n",
       "      <th>preprocessed_sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>one reviewer mention watch oz episode hook rig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>This show pulls no punches with regards to dru...</td>\n",
       "      <td>show pull punch regard drug sex violence hardc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A wonderful little production The filming tech...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>but he has all the voices down pat too You can...</td>\n",
       "      <td>voice pat truly see seamless edit guide refere...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>but it is terrificly written and performed pie...</td>\n",
       "      <td>terrificly write perform piece masterful produ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>The realism really comes home with the little ...</td>\n",
       "      <td>realism really come home little thing fantasy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>I thought this was wonderful way to spend time...</td>\n",
       "      <td>think wonderful way spend time hot summer week...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>The plot is simplistic but the dialogue is wit...</td>\n",
       "      <td>plot simplistic dialogue witty character likab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>While some may be disappointed when they reali...</td>\n",
       "      <td>may disappoint realize match point risk addict...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>Basically there a family where little boy Jake...</td>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>And then we have Jake with his closet which to...</td>\n",
       "      <td>jake closet totally ruin film expect see booge...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>Petter Mattei Love in the Time of Money is vis...</td>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>This is movie that seems to be telling us what...</td>\n",
       "      <td>movie seem tell u money power success people d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>Kane Michael Imperioli Adrian Grenier and the ...</td>\n",
       "      <td>kane michael imperioli adrian grenier rest tal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>We wish Mr Mattei good luck and await anxiousl...</td>\n",
       "      <td>wish mr mattei good luck await anxiously next ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>Probably my all time favorite movie story of s...</td>\n",
       "      <td>probably time favorite movie story selflessnes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>The kids are as grandma says more like dressed...</td>\n",
       "      <td>kid grandma say like dress midget child make f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>I sure would like to see resurrection of up da...</td>\n",
       "      <td>sure would like see resurrection dated seahunt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>Oh by the way thank you for an outlet like thi...</td>\n",
       "      <td>oh way thank outlet like view many viewpoint t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>So any ole way believe ve got what wanna say W...</td>\n",
       "      <td>ole way believe get wan na say would nice read...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7</td>\n",
       "      <td>This show was an amazing fresh innovative idea...</td>\n",
       "      <td>show amazing fresh innovative idea first air f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>encourage positive comment film look forward w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9</td>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>like original gut wrench laughter like movie y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
       "      <td>phil alien one quirky film humour base around ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>At first it was very odd and pretty funny but ...</td>\n",
       "      <td>first odd pretty funny movie progress find jok...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>anymore</td>\n",
       "      <td>anymore</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10</td>\n",
       "      <td>Its low budget film thats never problem in its...</td>\n",
       "      <td>low budget film thats never problem pretty int...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11</td>\n",
       "      <td>I saw this movie when was about when it came o...</td>\n",
       "      <td>saw movie come recall scary scene big bird eat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11</td>\n",
       "      <td>The horror As young kid going to these cheesy ...</td>\n",
       "      <td>horror young kid go cheesy film saturday after...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12</td>\n",
       "      <td>So im not big fan of Boll work but then again ...</td>\n",
       "      <td>im big fan boll work many enjoy movie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12</td>\n",
       "      <td>Postal maybe im the only one Boll apparently b...</td>\n",
       "      <td>postal maybe im one boll apparently buy right ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12</td>\n",
       "      <td>So the tale goes like this Jack Carver played ...</td>\n",
       "      <td>tale go like jack carver play til schweiger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12</td>\n",
       "      <td>yes Carver is German all hail the bratwurst ea...</td>\n",
       "      <td>yes carver german hail bratwurst eat dude howe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12</td>\n",
       "      <td>but we only saw carver in first person perspec...</td>\n",
       "      <td>saw carver first person perspective</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>12</td>\n",
       "      <td>so we don really know what he looked like when...</td>\n",
       "      <td>really know look like kick however storyline f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>12</td>\n",
       "      <td>We see the evil mad scientist Dr Krieger playe...</td>\n",
       "      <td>see evil mad scientist dr krieger play udo kie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>13</td>\n",
       "      <td>The cast played Shakespeare Shakespeare lost a...</td>\n",
       "      <td>cast play shakespeare shakespeare lose appreci...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>14</td>\n",
       "      <td>This fantastic movie of three prisoners who be...</td>\n",
       "      <td>fantastic movie three prisoner become famous o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>14</td>\n",
       "      <td>but this roll is not bad Another good thing ab...</td>\n",
       "      <td>roll bad another good thing movie soundtrack m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>15</td>\n",
       "      <td>Kind of drawn in by the erotic scenes only to ...</td>\n",
       "      <td>kind drawn erotic scene realize one amateurish...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>15</td>\n",
       "      <td>What was with the bisexual relationship out of...</td>\n",
       "      <td>bisexual relationship nowhere heterosexual enc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>15</td>\n",
       "      <td>And what was with that absurd dance with every...</td>\n",
       "      <td>absurd dance everybody play stereotyped role g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>16</td>\n",
       "      <td>Some films just simply should not be remade Th...</td>\n",
       "      <td>film simply remake one bad film fail capture f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>16</td>\n",
       "      <td>But you will enjoy the friction of terror in t...</td>\n",
       "      <td>enjoy friction terror old version much</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>17</td>\n",
       "      <td>This movie made it into one of my top most awf...</td>\n",
       "      <td>movie make one top awful movie horrible contin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>17</td>\n",
       "      <td>The ghost scene at the end was stolen from the...</td>\n",
       "      <td>ghost scene end steal final scene old star war...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>17</td>\n",
       "      <td>hello</td>\n",
       "      <td>hello</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>17</td>\n",
       "      <td>And the whole machine vs humans theme WAS the ...</td>\n",
       "      <td>whole machine v human theme matrix terminator ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>18</td>\n",
       "      <td>I remember this film it was the first film had...</td>\n",
       "      <td>remember film first film watch cinema picture ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>19</td>\n",
       "      <td>An awful film It must have been up against som...</td>\n",
       "      <td>awful film must real stinker nominate golden g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>19</td>\n",
       "      <td>They ve taken the story of the first famous fe...</td>\n",
       "      <td>take story first famous female renaissance pai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>19</td>\n",
       "      <td>My complaint is not that they ve taken liberti...</td>\n",
       "      <td>complaint take liberty fact story good would p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>19</td>\n",
       "      <td>But it simply bizarre by all accounts the true...</td>\n",
       "      <td>simply bizarre account true story artist would...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>19</td>\n",
       "      <td>so why did they come up with this dishwater du...</td>\n",
       "      <td>come dishwater dull script suppose enough nake...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>20</td>\n",
       "      <td>After the success of Die Hard and it sequels i...</td>\n",
       "      <td>success die hard sequels surprise really glut ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>20</td>\n",
       "      <td>However if you an forget all the nonsense it a...</td>\n",
       "      <td>however forget nonsense actually lovable unden...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>20</td>\n",
       "      <td>And whilst he surely can be it really does loo...</td>\n",
       "      <td>whilst surely really look like ralph waite fra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>20</td>\n",
       "      <td>yes you can help enjoy that bit Hal needed goo...</td>\n",
       "      <td>yes help enjoy bit hal need good kicking</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>20</td>\n",
       "      <td>So forget your better judgement who cares if t...</td>\n",
       "      <td>forget good judgement care could never happen ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>20</td>\n",
       "      <td>And if you re looking for Qaulen he the one we...</td>\n",
       "      <td>look qaulen one wear helicopter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id                                  article_sentences  \\\n",
       "0            0  One of the other reviewers has mentioned that ...   \n",
       "1            0  This show pulls no punches with regards to dru...   \n",
       "2            1  A wonderful little production The filming tech...   \n",
       "3            1  but he has all the voices down pat too You can...   \n",
       "4            1  but it is terrificly written and performed pie...   \n",
       "5            1  The realism really comes home with the little ...   \n",
       "6            2  I thought this was wonderful way to spend time...   \n",
       "7            2  The plot is simplistic but the dialogue is wit...   \n",
       "8            2  While some may be disappointed when they reali...   \n",
       "9            3  Basically there a family where little boy Jake...   \n",
       "10           3  And then we have Jake with his closet which to...   \n",
       "11           4  Petter Mattei Love in the Time of Money is vis...   \n",
       "12           4  This is movie that seems to be telling us what...   \n",
       "13           4  Kane Michael Imperioli Adrian Grenier and the ...   \n",
       "14           4  We wish Mr Mattei good luck and await anxiousl...   \n",
       "15           5  Probably my all time favorite movie story of s...   \n",
       "16           5  The kids are as grandma says more like dressed...   \n",
       "17           6  I sure would like to see resurrection of up da...   \n",
       "18           6  Oh by the way thank you for an outlet like thi...   \n",
       "19           6  So any ole way believe ve got what wanna say W...   \n",
       "20           7  This show was an amazing fresh innovative idea...   \n",
       "21           8  Encouraged by the positive comments about this...   \n",
       "22           9  If you like original gut wrenching laughter yo...   \n",
       "23          10  Phil the Alien is one of those quirky films wh...   \n",
       "24          10  At first it was very odd and pretty funny but ...   \n",
       "25          10                                            anymore   \n",
       "26          10  Its low budget film thats never problem in its...   \n",
       "27          11  I saw this movie when was about when it came o...   \n",
       "28          11  The horror As young kid going to these cheesy ...   \n",
       "29          12  So im not big fan of Boll work but then again ...   \n",
       "30          12  Postal maybe im the only one Boll apparently b...   \n",
       "31          12  So the tale goes like this Jack Carver played ...   \n",
       "32          12  yes Carver is German all hail the bratwurst ea...   \n",
       "33          12  but we only saw carver in first person perspec...   \n",
       "34          12  so we don really know what he looked like when...   \n",
       "35          12  We see the evil mad scientist Dr Krieger playe...   \n",
       "36          13  The cast played Shakespeare Shakespeare lost a...   \n",
       "37          14  This fantastic movie of three prisoners who be...   \n",
       "38          14  but this roll is not bad Another good thing ab...   \n",
       "39          15  Kind of drawn in by the erotic scenes only to ...   \n",
       "40          15  What was with the bisexual relationship out of...   \n",
       "41          15  And what was with that absurd dance with every...   \n",
       "42          16  Some films just simply should not be remade Th...   \n",
       "43          16  But you will enjoy the friction of terror in t...   \n",
       "44          17  This movie made it into one of my top most awf...   \n",
       "45          17  The ghost scene at the end was stolen from the...   \n",
       "46          17                                              hello   \n",
       "47          17  And the whole machine vs humans theme WAS the ...   \n",
       "48          18  I remember this film it was the first film had...   \n",
       "49          19  An awful film It must have been up against som...   \n",
       "50          19  They ve taken the story of the first famous fe...   \n",
       "51          19  My complaint is not that they ve taken liberti...   \n",
       "52          19  But it simply bizarre by all accounts the true...   \n",
       "53          19  so why did they come up with this dishwater du...   \n",
       "54          20  After the success of Die Hard and it sequels i...   \n",
       "55          20  However if you an forget all the nonsense it a...   \n",
       "56          20  And whilst he surely can be it really does loo...   \n",
       "57          20  yes you can help enjoy that bit Hal needed goo...   \n",
       "58          20  So forget your better judgement who cares if t...   \n",
       "59          20  And if you re looking for Qaulen he the one we...   \n",
       "\n",
       "                                preprocessed_sentence  label  \n",
       "0   one reviewer mention watch oz episode hook rig...      0  \n",
       "1   show pull punch regard drug sex violence hardc...      0  \n",
       "2   wonderful little production filming technique ...      1  \n",
       "3   voice pat truly see seamless edit guide refere...      0  \n",
       "4   terrificly write perform piece masterful produ...      0  \n",
       "5   realism really come home little thing fantasy ...      0  \n",
       "6   think wonderful way spend time hot summer week...      0  \n",
       "7   plot simplistic dialogue witty character likab...      0  \n",
       "8   may disappoint realize match point risk addict...      0  \n",
       "9   basically family little boy jake think zombie ...      1  \n",
       "10  jake closet totally ruin film expect see booge...      0  \n",
       "11  petter mattei love time money visually stunnin...      1  \n",
       "12  movie seem tell u money power success people d...      0  \n",
       "13  kane michael imperioli adrian grenier rest tal...      1  \n",
       "14  wish mr mattei good luck await anxiously next ...      0  \n",
       "15  probably time favorite movie story selflessnes...      1  \n",
       "16  kid grandma say like dress midget child make f...      0  \n",
       "17  sure would like see resurrection dated seahunt...      1  \n",
       "18  oh way thank outlet like view many viewpoint t...      0  \n",
       "19  ole way believe get wan na say would nice read...      0  \n",
       "20  show amazing fresh innovative idea first air f...      0  \n",
       "21  encourage positive comment film look forward w...      0  \n",
       "22  like original gut wrench laughter like movie y...      1  \n",
       "23  phil alien one quirky film humour base around ...      1  \n",
       "24  first odd pretty funny movie progress find jok...      1  \n",
       "25                                            anymore      0  \n",
       "26  low budget film thats never problem pretty int...      0  \n",
       "27  saw movie come recall scary scene big bird eat...      1  \n",
       "28  horror young kid go cheesy film saturday after...      0  \n",
       "29              im big fan boll work many enjoy movie      0  \n",
       "30  postal maybe im one boll apparently buy right ...      0  \n",
       "31        tale go like jack carver play til schweiger      0  \n",
       "32  yes carver german hail bratwurst eat dude howe...      0  \n",
       "33                saw carver first person perspective      0  \n",
       "34  really know look like kick however storyline f...      0  \n",
       "35  see evil mad scientist dr krieger play udo kie...      0  \n",
       "36  cast play shakespeare shakespeare lose appreci...      0  \n",
       "37  fantastic movie three prisoner become famous o...      1  \n",
       "38  roll bad another good thing movie soundtrack m...      1  \n",
       "39  kind drawn erotic scene realize one amateurish...      0  \n",
       "40  bisexual relationship nowhere heterosexual enc...      0  \n",
       "41  absurd dance everybody play stereotyped role g...      0  \n",
       "42  film simply remake one bad film fail capture f...      0  \n",
       "43             enjoy friction terror old version much      0  \n",
       "44  movie make one top awful movie horrible contin...      0  \n",
       "45  ghost scene end steal final scene old star war...      0  \n",
       "46                                              hello      0  \n",
       "47  whole machine v human theme matrix terminator ...      0  \n",
       "48  remember film first film watch cinema picture ...      0  \n",
       "49  awful film must real stinker nominate golden g...      1  \n",
       "50  take story first famous female renaissance pai...      1  \n",
       "51  complaint take liberty fact story good would p...      0  \n",
       "52  simply bizarre account true story artist would...      0  \n",
       "53  come dishwater dull script suppose enough nake...      0  \n",
       "54  success die hard sequels surprise really glut ...      0  \n",
       "55  however forget nonsense actually lovable unden...      0  \n",
       "56  whilst surely really look like ralph waite fra...      0  \n",
       "57           yes help enjoy bit hal need good kicking      0  \n",
       "58  forget good judgement care could never happen ...      0  \n",
       "59                    look qaulen one wear helicopter      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_processed_df.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36012aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def balance_dataset(df):\n",
    "    df_majority = df[df.label == 0]\n",
    "    df_minority = df[df.label == 1]\n",
    "\n",
    "    df_minority_upsampled = resample(\n",
    "        df_minority, replace=True, n_samples=len(df_majority), random_state=42\n",
    "    )\n",
    "\n",
    "    return pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "\n",
    "# Balance both datasets\n",
    "bbc_balanced = balance_dataset(bbc_processed_df)\n",
    "imdb_balanced = balance_dataset(imdb_processed_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49d1bfc",
   "metadata": {},
   "source": [
    "#### Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ee6068",
   "metadata": {},
   "source": [
    "kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145708c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'tfidf__ngram_range': (1, 1), 'tfidf__min_df': 3, 'tfidf__max_features': 3000, 'clf__weights': 'distance', 'clf__n_neighbors': 7, 'clf__metric': 'cosine'}\n",
      "Best score: 0.7530351372268077\n",
      "BBC Dataset Evaluation (KNN):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.74      0.79      5043\n",
      "           1       0.77      0.86      0.81      5011\n",
      "\n",
      "    accuracy                           0.80     10054\n",
      "   macro avg       0.80      0.80      0.80     10054\n",
      "weighted avg       0.80      0.80      0.80     10054\n",
      "\n",
      "\n",
      "Article ID: 0\n",
      "Reference Summary: TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. For the full-year, Time...\n",
      "Generated Summary: TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. ...\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.7966101694915254, 'p': 1.0, 'f': 0.8867924478942684}, 'rouge-2': {'r': 0.7534246575342466, 'p': 0.9821428571428571, 'f': 0.8527131733814074}, 'rouge-l': {'r': 0.7966101694915254, 'p': 1.0, 'f': 0.8867924478942684}}\n",
      "\n",
      "Article ID: 1\n",
      "Reference Summary: \"I think the chairman's taking a much more sanguine view on the current account deficit than he's taken for some time,\" said Robert Sinche, head of currency strategy at Bank of America in New York. \"I...\n",
      "Generated Summary: \"I think the chairman's taking a much more sanguine view on the current account deficit than he's taken for some time,\" said Robert Sinche, head of currency strategy at Bank of America in New York. \"I...\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.5463917525773195, 'p': 1.0, 'f': 0.706666662096889}, 'rouge-2': {'r': 0.44360902255639095, 'p': 1.0, 'f': 0.6145833290760634}, 'rouge-l': {'r': 0.5463917525773195, 'p': 1.0, 'f': 0.706666662096889}}\n",
      "\n",
      "Article ID: 2\n",
      "Reference Summary: State-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part settle a $27.5bn tax claim against Yukos. But the company has said it intends to take action against Menatep t...\n",
      "Generated Summary: State-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part settle a $27.5bn tax claim against Yukos. But the company has said it intends to take action against Menatep t...\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.5128205128205128, 'p': 1.0, 'f': 0.6779660972134445}, 'rouge-2': {'r': 0.4666666666666667, 'p': 1.0, 'f': 0.6363636320247934}, 'rouge-l': {'r': 0.5128205128205128, 'p': 1.0, 'f': 0.6779660972134445}}\n",
      "\n",
      "Article ID: 3\n",
      "Reference Summary: BA had previously forecast a 2% to 3% rise in full-year revenue. \"It is quite good on the revenue side and it shows the impact of fuel surcharges and a positive cargo development, however, operating m...\n",
      "Generated Summary: BA had previously forecast a 2% to 3% rise in full-year revenue. \"It is quite good on the revenue side and it shows the impact of fuel surcharges and a positive cargo development, however, operating m...\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.43410852713178294, 'p': 1.0, 'f': 0.6054054011839299}, 'rouge-2': {'r': 0.3471502590673575, 'p': 1.0, 'f': 0.5153846115588758}, 'rouge-l': {'r': 0.43410852713178294, 'p': 1.0, 'f': 0.6054054011839299}}\n",
      "\n",
      "Article ID: 4\n",
      "Reference Summary: In terms of market value, Pernod - at 7.5bn euros ($9.7bn) - is about 9% smaller than Allied Domecq, which has a capitalisation of Â£5.7bn ($10.7bn; 8.2bn euros). Pernod said it was seeking acquisitio...\n",
      "Generated Summary: In terms of market value, Pernod - at 7.5bn euros ($9.7bn) - is about 9% smaller than Allied Domecq, which has a capitalisation of Â£5.7bn ($10.7bn; 8.2bn euros). Pernod said it was seeking acquisitio...\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.8, 'p': 1.0, 'f': 0.8888888839506174}, 'rouge-2': {'r': 0.7142857142857143, 'p': 1.0, 'f': 0.8333333284722222}, 'rouge-l': {'r': 0.8, 'p': 1.0, 'f': 0.8888888839506174}}\n"
     ]
    }
   ],
   "source": [
    "from ML_models.knn import KNNExtractiveSummarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare data\n",
    "X = bbc_balanced[\"preprocessed_sentence\"]\n",
    "y = bbc_balanced[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize and tune model\n",
    "knn_bbc = KNNExtractiveSummarizer()\n",
    "\n",
    "# Fine-tune the model on the training set\n",
    "knn_bbc.tune(X_train, y_train, n_iter=10, scoring=\"f1\")  # You can increase n_iter\n",
    "\n",
    "# Evaluate\n",
    "print(\"BBC Dataset Evaluation (KNN):\")\n",
    "knn_bbc.evaluate(X_test, y_test)\n",
    "\n",
    "# Generate summaries for a few articles\n",
    "sample_article_ids = bbc_balanced[\"article_id\"].unique()[:5]\n",
    "\n",
    "for article_id in sample_article_ids:\n",
    "    article_df = bbc_balanced[bbc_balanced[\"article_id\"] == article_id]\n",
    "    reference_summary = \" \".join(\n",
    "        article_df[article_df[\"label\"] == 1][\"article_sentences\"]\n",
    "    )\n",
    "    generated_summary = knn_bbc.summarize(\n",
    "        article_df[\"article_sentences\"].tolist(),\n",
    "        article_df[\"preprocessed_sentence\"].tolist(),\n",
    "    )\n",
    "\n",
    "    print(f\"\\nArticle ID: {article_id}\")\n",
    "    print(\"Reference Summary:\", reference_summary[:200] + \"...\")\n",
    "    print(\"Generated Summary:\", generated_summary[:200] + \"...\")\n",
    "\n",
    "    rouge_scores = knn_bbc.compute_rouge(generated_summary, reference_summary)\n",
    "    if rouge_scores is not None:\n",
    "        print(\"ROUGE Scores:\", rouge_scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aa701b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'tfidf__ngram_range': (1, 1), 'tfidf__min_df': 1, 'tfidf__max_features': 5000, 'clf__weights': 'distance', 'clf__n_neighbors': 7, 'clf__metric': 'euclidean'}\n",
      "Best score: 0.8969881150466228\n",
      "IMDB Dataset Evaluation (KNN):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      2013\n",
      "           1       0.94      0.92      0.93      2023\n",
      "\n",
      "    accuracy                           0.93      4036\n",
      "   macro avg       0.93      0.93      0.93      4036\n",
      "weighted avg       0.93      0.93      0.93      4036\n",
      "\n",
      "\n",
      "Article ID: 0\n",
      "Reference Summary: ...\n",
      "Generated Summary: One of the other reviewers has mentioned that after watching just Oz episode you ll be hooked They are right as this is exactly what happened with me The first thing that struck me about Oz was its br...\n",
      "Error computing ROUGE: Reference is empty.\n",
      "\n",
      "Article ID: 1\n",
      "Reference Summary: A wonderful little production The filming technique is very unassuming very old time BBC fashion and gives comforting and sometimes discomforting sense of realism to the entire piece The actors are ex...\n",
      "Generated Summary: but it is terrificly written and performed piece masterful production about one of the great master of comedy and his life A wonderful little production The filming technique is very unassuming very o...\n",
      "ROUGE Scores: {'rouge-1': {'r': 1.0, 'p': 0.75, 'f': 0.8571428522448981}, 'rouge-2': {'r': 1.0, 'p': 0.6666666666666666, 'f': 0.7999999952000001}, 'rouge-l': {'r': 1.0, 'p': 0.75, 'f': 0.8571428522448981}}\n",
      "\n",
      "Article ID: 2\n",
      "Reference Summary: ...\n",
      "Generated Summary: The plot is simplistic but the dialogue is witty and the characters are likable even the well bread suspected serial killer...\n",
      "Error computing ROUGE: Reference is empty.\n",
      "\n",
      "Article ID: 3\n",
      "Reference Summary: Basically there a family where little boy Jake thinks there a zombie in his closet his parents are fighting all the time This movie is slower than soap opera and suddenly Jake decides to become Rambo ...\n",
      "Generated Summary: Basically there a family where little boy Jake thinks there a zombie in his closet his parents are fighting all the time This movie is slower than soap opera and suddenly Jake decides to become Rambo ...\n",
      "ROUGE Scores: {'rouge-1': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-2': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}, 'rouge-l': {'r': 1.0, 'p': 1.0, 'f': 0.999999995}}\n",
      "\n",
      "Article ID: 4\n",
      "Reference Summary: Kane Michael Imperioli Adrian Grenier and the rest of the talented cast make these characters come alive Petter Mattei Love in the Time of Money is visually stunning film to watch Mr Mattei offers us ...\n",
      "Generated Summary: Petter Mattei Love in the Time of Money is visually stunning film to watch Mr Mattei offers us vivid portrait about human relations Petter Mattei Love in the Time of Money is visually stunning film to...\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.6111111111111112, 'p': 1.0, 'f': 0.7586206849464924}, 'rouge-2': {'r': 0.575, 'p': 1.0, 'f': 0.7301587255228017}, 'rouge-l': {'r': 0.6111111111111112, 'p': 1.0, 'f': 0.7586206849464924}}\n"
     ]
    }
   ],
   "source": [
    "from ML_models.knn import KNNExtractiveSummarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare data\n",
    "X = imdb_balanced[\"preprocessed_sentence\"]\n",
    "y = imdb_balanced[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize and tune model\n",
    "knn_bbc = KNNExtractiveSummarizer()\n",
    "\n",
    "# Fine-tune the model on the training set\n",
    "knn_bbc.tune(X_train, y_train, n_iter=10, scoring=\"f1\")  # You can increase n_iter\n",
    "\n",
    "# Evaluate\n",
    "print(\"IMDB Dataset Evaluation (KNN):\")\n",
    "knn_bbc.evaluate(X_test, y_test)\n",
    "\n",
    "# Generate summaries for a few articles\n",
    "sample_article_ids = imdb_balanced[\"article_id\"].unique()[:5]\n",
    "\n",
    "for article_id in sample_article_ids:\n",
    "    article_df = imdb_balanced[imdb_balanced[\"article_id\"] == article_id]\n",
    "    reference_summary = \" \".join(\n",
    "        article_df[article_df[\"label\"] == 1][\"article_sentences\"]\n",
    "    )\n",
    "    generated_summary = knn_bbc.summarize(\n",
    "        article_df[\"article_sentences\"].tolist(),\n",
    "        article_df[\"preprocessed_sentence\"].tolist(),\n",
    "    )\n",
    "\n",
    "    print(f\"\\nArticle ID: {article_id}\")\n",
    "    print(\"Reference Summary:\", reference_summary[:200] + \"...\")\n",
    "    print(\"Generated Summary:\", generated_summary[:200] + \"...\")\n",
    "\n",
    "    rouge_scores = knn_bbc.compute_rouge(generated_summary, reference_summary)\n",
    "    if rouge_scores is not None:\n",
    "        print(\"ROUGE Scores:\", rouge_scores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c925098",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55b135f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<<<<<<< local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best params: {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 3, 'tfidf__max_features': 5000, 'clf__max_iter': 1500, 'clf__C': 1}\n",
      "Best score: 0.5626295285604364\n",
      "BBC Dataset Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.66      0.69      5062\n",
      "           1       0.54      0.62      0.58      3274\n",
      "\n",
      "    accuracy                           0.65      8336\n",
      "   macro avg       0.64      0.64      0.64      8336\n",
      "weighted avg       0.66      0.65      0.65      8336\n",
      "\n",
      "\n",
      "Article ID: 0\n",
      "Reference Summary: TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. For the full-year, Time...\n",
      "Generated Summary: The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn ...\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.6101694915254238, 'p': 0.7058823529411765, 'f': 0.654545449571901}, 'rouge-2': {'r': 0.4794520547945205, 'p': 0.5932203389830508, 'f': 0.5303030253592746}, 'rouge-l': {'r': 0.6101694915254238, 'p': 0.7058823529411765, 'f': 0.654545449571901}}\n",
      "\n",
      "Article ID: 1\n",
      "Reference Summary: The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise. Market concerns about the deficit has hit the...\n",
      "Generated Summary: The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise. On Friday, Federal Reserve chairman Mr Greens...\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.2909090909090909, 'p': 0.47761194029850745, 'f': 0.36158191619904884}, 'rouge-2': {'r': 0.19480519480519481, 'p': 0.35294117647058826, 'f': 0.2510460205213495}, 'rouge-l': {'r': 0.2818181818181818, 'p': 0.4626865671641791, 'f': 0.35028248117080024}}\n",
      "\n",
      "Article ID: 2\n",
      "Reference Summary: State-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part settle a $27.5bn tax claim against Yukos. Yukos' owner Menatep Group says it will ask Rosneft to repay a loan ...\n",
      "Generated Summary: Yukos unit buyer faces loan claim  The owners of embattled Russian oil giant Yukos are to ask the buyer of its former production unit to pay back a $900m (Â£479m) loan. Yukos' owner Menatep Group says...\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.375, 'p': 0.6111111111111112, 'f': 0.4647887276810157}, 'rouge-2': {'r': 0.1693548387096774, 'p': 0.2916666666666667, 'f': 0.21428570963765106}, 'rouge-l': {'r': 0.3409090909090909, 'p': 0.5555555555555556, 'f': 0.42253520655425514}}\n"
     ]
    }
   ],
   "source": [
    "from ML_models.logistic_reg import LogisticRegressionSummarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = bbc_balanced[\"preprocessed_sentence\"]\n",
    "y = bbc_balanced[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "lr_bbc = LogisticRegressionSummarizer()\n",
    "\n",
    "# Fine-tune the model on the training set\n",
    "lr_bbc.tune(\n",
    "    X_train, y_train, n_iter=10, scoring=\"f1\"\n",
    ")  # You can increase n_iter if desired\n",
    "\n",
    "print(\"BBC Dataset Evaluation:\")\n",
    "lr_bbc.evaluate(X_test, y_test)\n",
    "\n",
    "sample_article_ids = bbc_balanced[\"article_id\"].unique()[:3]\n",
    "\n",
    "for article_id in sample_article_ids:\n",
    "    article_df = bbc_balanced[bbc_balanced[\"article_id\"] == article_id]\n",
    "    reference_summary = \" \".join(\n",
    "        article_df[article_df[\"label\"] == 1][\"article_sentences\"]\n",
    "    )\n",
    "    generated_summary = lr_bbc.summarize(\n",
    "        article_df[\"article_sentences\"].tolist(),\n",
    "        article_df[\"preprocessed_sentence\"].tolist(),\n",
    "    )\n",
    "\n",
    "    print(f\"\\nArticle ID: {article_id}\")\n",
    "    print(\"Reference Summary:\", reference_summary[:200] + \"...\")\n",
    "    print(\"Generated Summary:\", generated_summary[:200] + \"...\")\n",
    "\n",
    "    rouge_scores = lr_bbc.compute_rouge(generated_summary, reference_summary)\n",
    "    if rouge_scores is not None:\n",
    "        print(\"ROUGE Scores:\", rouge_scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63f7063f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<<<<<<< local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best params: {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 2, 'tfidf__max_features': 3000, 'clf__max_iter': 500, 'clf__C': 0.1}\n",
      "Best score: 0.40721609299234146\n",
      "IMDB Dataset Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76      2021\n",
      "           1       0.35      0.57      0.43       584\n",
      "\n",
      "    accuracy                           0.80      4036\n",
      "   macro avg       0.80      0.80      0.80      4036\n",
      "weighted avg       0.80      0.80      0.80      4036\n",
      "\n",
      "\n",
      "Article ID: 0\n",
      "Reference Summary: ...\n",
      "Generated Summary: One of the other reviewers has mentioned that after watching just Oz episode you ll be hooked They are right as this is exactly what happened with me The first thing that struck me about Oz was its br...\n",
      "Error computing ROUGE: Reference is empty.\n",
      "\n",
      "Article ID: 1\n",
      "Reference Summary: A wonderful little production The filming technique is very unassuming very old time BBC fashion and gives comforting and sometimes discomforting sense of realism to the entire piece The actors are ex...\n",
      "Generated Summary: A wonderful little production The filming technique is very unassuming very old time BBC fashion and gives comforting and sometimes discomforting sense of realism to the entire piece The actors are ex...\n",
      "ROUGE Scores: {'rouge-1': {'r': 1.0, 'p': 0.5492957746478874, 'f': 0.7090909045140497}, 'rouge-2': {'r': 1.0, 'p': 0.45161290322580644, 'f': 0.6222222179358025}, 'rouge-l': {'r': 1.0, 'p': 0.5492957746478874, 'f': 0.7090909045140497}}\n",
      "\n",
      "Article ID: 2\n",
      "Reference Summary: ...\n",
      "Generated Summary: I thought this was wonderful way to spend time on too hot summer weekend sitting in the air conditioned theater and watching light hearted comedy The plot is simplistic but the dialogue is witty and t...\n",
      "Error computing ROUGE: Reference is empty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>>>>> remote\n"
     ]
    }
   ],
   "source": [
    "from ML_models.logistic_reg import LogisticRegressionSummarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = imdb_balanced[\"preprocessed_sentence\"]\n",
    "y = imdb_balanced[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "lr_imdb = LogisticRegressionSummarizer()\n",
    "\n",
    "# Fine-tune the model on the training set\n",
    "lr_imdb.tune(X_train, y_train, n_iter=10, scoring=\"f1\")\n",
    "\n",
    "print(\"IMDB Dataset Evaluation:\")\n",
    "lr_imdb.evaluate(X_test, y_test)\n",
    "\n",
    "sample_article_ids = imdb_balanced[\"article_id\"].unique()[:3]\n",
    "\n",
    "for article_id in sample_article_ids:\n",
    "    article_df = imdb_balanced[imdb_balanced[\"article_id\"] == article_id]\n",
    "    article_sents = article_df[\"article_sentences\"].tolist()\n",
    "    preprocessed_sents = article_df[\"preprocessed_sentence\"].tolist()\n",
    "\n",
    "    if not preprocessed_sents or not article_sents:\n",
    "        print(f\"\\nArticle ID: {article_id}\")\n",
    "        print(\"Empty input. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    reference_summary = \" \".join(\n",
    "        article_df[article_df[\"label\"] == 1][\"article_sentences\"]\n",
    "    )\n",
    "    generated_summary = lr_imdb.summarize(article_sents, preprocessed_sents)\n",
    "\n",
    "    print(f\"\\nArticle ID: {article_id}\")\n",
    "    print(\"Reference Summary:\", reference_summary[:200] + \"...\")\n",
    "    print(\"Generated Summary:\", generated_summary[:200] + \"...\")\n",
    "\n",
    "    rouge_scores = lr_imdb.compute_rouge(generated_summary, reference_summary)\n",
    "    if rouge_scores is not None:\n",
    "        print(\"ROUGE Scores:\", rouge_scores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39d614e",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829982a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Fady\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running on BBC Dataset ===\n",
      "Train Accuracy: 0.8802\n",
      "Test Accuracy: 0.8588\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.92     12218\n",
      "           1       0.06      0.47      0.10       208\n",
      "\n",
      "    accuracy                           0.86     12426\n",
      "   macro avg       0.52      0.67      0.51     12426\n",
      "weighted avg       0.97      0.86      0.91     12426\n",
      "\n",
      "\n",
      "ROUGE Scores:\n",
      "rouge-1: 0.3920\n",
      "rouge-2: 0.2834\n",
      "rouge-l: 0.3817\n",
      "\n",
      "--- Article 1665 ---\n",
      "Predicted: Campaign groups including Friends of the Earth, the World Development Movement, and War on Want said UK government policy on free trade was a major barrier to fighting poverty.\n",
      "Reference: Mr Brown welcomed news that the Bill Gates Foundation and Norway are joining up to put an extra Â£0.53bn ($1bn ) into the Global Alliance for Vaccines and Immunisation (Gavi).UK Chancellor Gordon Brown has offered Â£960m ($1.8bn) over 15 years to an international scheme aiming to boost vaccination and immunisation schemes.If Gavi could increase its funding for immunisation by an extra Â£4bn ($7.4bn) over 10 years, then an extra five million lives could have been saved by 2015 and five million thereafter, Mr Brown argued.\"As long as Mr Blair and Mr Brown continue to push free trade and privatisation on developing countries, more and more people will be pushed deeper into poverty, not lifted out of it.\"Britain, France, Gavi and the Gates Foundation have drawn up proposals to apply the principles of the International Finance Facility (IFF) to the area of immunisation.Campaign groups including Friends of the Earth, the World Development Movement, and War on Want said UK government policy on free trade was a major barrier to fighting poverty.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 1348 ---\n",
      "Predicted: Injury sidelines Philippoussis\n",
      "\n",
      "Mark Philippoussis withdrew from the Sydney International tennis tournament as expected on Sunday after suffering a groin injury during the Hopman Cup.\n",
      "Reference: Defending women's champion Justine Henin-Hardenne is also out of the Sydney event because of a knee injury.Number one men's seed Lleyton Hewitt begins his quest for a fourth Sydney title on Tuesday when he plays Karol Beck.Lindsay Davenport, top seed in the women's draw, has been handed a first-round bye and plays France's Dechy in the second round on Tuesday.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 433 ---\n",
      "Predicted: \"We will submit a budget that fits the times,\" Mr Bush said. \"As well, we've got to deal with the long-term deficit issues.\"\n",
      "Reference: Mr Bush, however, has said the best way to halt the dollar's slide is to deal with the US deficit.US president George W Bush has pledged to introduce a \"tough\" federal budget next February in a bid to halve the country's deficit in five years.\"We will submit a budget that fits the times,\" Mr Bush said.The US budget and its trade deficit are both deep in the red, helping to push the dollar to lows against the euro and fuelling fears about the economy.Mr Bush indicated there would be \"strict discipline\" on non-defence spending in the budget.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 1436 ---\n",
      "Predicted: About 50,000 children live with foster families in the UK and carers have said they need more money to make ends meet. Ms Hodge said: \"Foster carers must not be out of pocket when meeting the costs of caring for a looked after child - a crucial role in society. \"We need to make sure that arrangements for paying foster carers are as fair and transparent as possible. \"Our proposal for a national minimum rate shows we are serious about creating a better deal for foster carers and about encouraging more people to come forward and consider fostering as a worthwhile and rewarding opportunity.\"\n",
      "Reference: About 50,000 children live with foster families in the UK and carers have said they need more money to make ends meet.\"And with a shortage of over 8,000 foster carers in England, it's not a sustainable situation to expect carers to fund foster care from their own pockets.\"\"We need to make sure that arrangements for paying foster carers are as fair and transparent as possible.Foster carers are to be guaranteed a minimum allowance to help cover their costs, the government has announced.\"But ADSS fully supports proper remuneration for valued foster carers and looks forward to working with ministers, local government and the fostering organisations themselves in order to make sure a sensible and practicable policy emerges.\"Ms Hodge said: \"Foster carers must not be out of pocket when meeting the costs of caring for a looked after child - a crucial role in society.\"Our proposal for a national minimum rate shows we are serious about creating a better deal for foster carers and about encouraging more people to come forward and consider fostering as a worthwhile and rewarding opportunity.\"\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 1375 ---\n",
      "Predicted: Butler said of her success: \"I felt great throughout the race and hope this is a good beginning for a marvellous 2005 season for me.\"\n",
      "Reference: Gelete Burka then crowned a great day for Ethiopia by claiming victory in the women's race.Elsewhere, Abebe Dinkessa of Ethiopia won the Brussels IAAF cross-country race on Sunday, completing the 10,500m course in 33.22.The Scot, who led GB to World Cross Country bronze earlier this year, moved away from the field with Ines Monteiro halfway into the 6.6km race.Butler said of her success: \"I felt great throughout the race and hope this is a good beginning for a marvellous 2005 season for me.\"\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ML_models.decisionTreeClassifierModel import DecisionTreeClassifierModel\n",
    "bbc_model = DecisionTreeClassifierModel(\"BBC\", bbc_processed_df)\n",
    "bbc_model.run()\n",
    "bbc_model.show_predictions(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d91c558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running on IMDB Dataset ===\n",
      "Train Accuracy: 0.9771\n",
      "Test Accuracy: 0.9684\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     11650\n",
      "           1       0.05      0.34      0.08        50\n",
      "\n",
      "    accuracy                           0.97     11700\n",
      "   macro avg       0.52      0.66      0.53     11700\n",
      "weighted avg       0.99      0.97      0.98     11700\n",
      "\n",
      "\n",
      "ROUGE Scores:\n",
      "rouge-1: 0.5617\n",
      "rouge-2: 0.4881\n",
      "rouge-l: 0.5612\n",
      "\n",
      "--- Article 13209 ---\n",
      "Predicted: Two old men sitting on park bench don really have problem with this scene Only problem is that it not scene it the entire movieYup movies don get anymore low concept than this They also don get anymore boring than this either but there worse to come because these two old men are chalk and cheese One is Nat Moyer who is Yiddish communist while the other is Midge Carter former golden gloves champion who also black Let me see now Jew and black man sitting on park bench getting along fine Well guess it possible though unlikely but if this film has such an inoffensive scenario why play up to the Jewish stereotype Why make them loud tribilistic rabble rousers who take hebrew oaths Slightly ironic that the Jews seen at the start of the movie are exactly the type of Jews seen in Nazi propaganda films in the sStereotypes aside moi dearz the problem with M NOT RAPPAPORT is that it written for an entirely different meduim than cinema it based on stage play and it shows Walter Matthau sleepwalks through his role as Nat while this commentator almost slept through the whole movie\n",
      "Reference: Two old men sitting on park bench don't really have problem with this scene. Only problem is that it not scene it the entire movie. Walter Matthau sleepwalks through his role as Nat while this commentator almost slept through the whole movie.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 6634 ---\n",
      "Predicted: Dark Harbor is moody little excursion into murky emotional waters that run extremely deep It basically character piece featuring finely layered performance by the always great Rickman with Polly Walker and Norman Reedus also excellent forming the other two sides of this strange triangle perfect late night cable film with surprise ending to boot\n",
      "Reference: Dark Harbor is moody little excursion into murky emotional waters that run extremely deep. It basically character piece featuring finely layered performance by the always great Rickman. Polly Walker and Norman Reedus also excellent forming the other two sides of this strange triangle.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 37454 ---\n",
      "Predicted: After long period in the space looking for the remains of planet Krypton Superman Brandon Routh returns to Earth He misses Lois Lane Kate Bosworth who got married and has son with Richard White James Marsden Meanwhile Lex Luthor Kevin Spacey plots an evil plan using crystals he stole from the Fortress of Solitude to create new land and submerge the USA After so many delightful movies of Superman with the unforgettable Christopher Reeve or TV shows like Lois and Clark and Teri Hatcher or Smallville great expectation was created for the return of Superman in this Bryan Singer version Unfortunately the awful story is too long and boring with many unnecessary parts lack of emotion and overrated in IMDb In addition the romance between Lois Lane and Superman is something shamefully ridiculous The twenty two years old actress Kate Bosworth is wrongly miscast playing the role of mature reporter and experienced mother of five years old boy Brandon Routh is two years younger than Tom Welling who plays teenager Clark Kent in Smallville The character of Parker Posey Kitty Kowalski is actually silly caricature Last but not the least and in spite of being terrific Lex Luthor Kevin Spacey is forty five years old therefore older and older than the rest of the lead cast The corny conclusion looks like soap opera and is terrible My vote is four Title Brazil Superman Returns\n",
      "Reference: After long period in the space looking for the remains of planet Krypton Superman Brandon Routh returns to Earth He misses Lois Lane Kate Bosworth who got married and has son with Richard White James Marsden Meanwhile Lex Luthor Kevin Spacey plots an evil plan using crystals he stole from the Fortress of Solitude to create new land and submerge the USA.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 8308 ---\n",
      "Predicted: There were lot of things going against this movie for me before watched it First was typical high school senior in Shakespeare class didn really even like much less understood half of Shakespeare would be no more than UNINTELLIGIBLE without me pouring ALL my concentration into his almost encrypted plays encrypted with his extremely difficult to understand language and then still wouldn get most of it Second it was hours long never thought that could be good thing Well let me tell you something This movie was so masterful so beautiful actually understood all the language as it was being performed Now the script was followed to the letter in this movie the same script that was incomprehensible to me in Shakespeare class And here was my mind opening and me understanding it was doubting myself while watching the movie almost But lo and behold when performed and only then Shakespeare comes to life So this version of Hamlet showed me that Shakespeare is indeed master who wrote great stories When saw it on the big screen especially in the high budget major motion picture style with beautiful cinematography and photography and acted amazingly by Brannagh and cast somehow understood what was going on What was being said The language is awesome and passionate It allows for more raw emotion when words can describe something maybe Shakespeare words can still hold to this day that Fist of The North Star animated english dub is the greatest movie ever made No movie provides more sheer entertainment But for movie to come close to dethroning Fist from that position which Hamlet did it came close is truly amazing awe inspiring It wasn a movie It was an event Even more amazing it made me appreciate shakespeare Wow Powerful Powerful is the word One of the rare TRULY powerful movies out there This gets hundred trillion stars out of infinity stars Yes yes By the way all you kids out there in Shakespeare class forget it You re wasting you re time You have to see the plays performed Only then will justice be done to them\n",
      "Reference: There were lot of things going against this movie for me before watched it. This movie was so masterful so beautiful actually understood all the language as it was being performed. The script was followed to the letter in this movie the same script that was incomprehensible to me in Shakespeare class.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 12120 ---\n",
      "Predicted: I sorry but even TJ Hooker Adrian Zmed couldn save this sequel went through half the movie thinking that this was spoof of the original Then came that wild and wacky motorcycle scene notice that this is the only movie that Patricia Birch directs and sadly realized they were trying to be serious did get kick out of the fact that the opposing gang having lost their wheels due to their gambling habits in the original Grease were forced to use motorcycles in the second movie Being shamed by that putz character Carrington d hate to see what they would resort to later maybe Mopeds also never bought the hackneyed theme hunky Australian boy can fit into Outsiders dominated school ergo goes for tough guy with stupid biker helmet look It was Disney story gone horribly awry So it looks like you CAN ruin good thing by placing bubble gum smacking Michelle Pfeiffer in musical The only thing took away from this movie was an idea of how many points out of ten to give it\n",
      "Reference: I sorry but even TJ Hooker Adrian Zmed couldn't save this sequel. It was Disney story gone horribly awry. So it looks like you CAN ruin good thing by placing bubble gum smacking Michelle Pfeiffer in musical.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ML_models.decisionTreeClassifierModel import DecisionTreeClassifierModel\n",
    "bbc_model = DecisionTreeClassifierModel(\"imdb\", imdb_processed_df)\n",
    "bbc_model.run()\n",
    "bbc_model.show_predictions(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2502619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML_models.decision_tree import DecisionTreeSummarizer\n",
    "\n",
    "bbc_summarizer = DecisionTreeSummarizer(\"BBC\", bbc_df)\n",
    "bbc_summarizer.run()\n",
    "bbc_summarizer.show_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_summarizer = DecisionTreeSummarizer(\"IMDB\", imdb_df)\n",
    "bbc_summarizer.run()\n",
    "bbc_summarizer.show_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa1b59",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0d669517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running classification on BBC Dataset ===\n",
      "\n",
      "Train Accuracy: 0.6780\n",
      "Test Accuracy: 0.6516\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.66      7557\n",
      "           1       0.66      0.63      0.64      7524\n",
      "\n",
      "    accuracy                           0.65     15081\n",
      "   macro avg       0.65      0.65      0.65     15081\n",
      "weighted avg       0.65      0.65      0.65     15081\n",
      "\n",
      "\n",
      "=== Article-wise Summary Evaluation ===\n",
      "\n",
      "Article ID: 0\n",
      "Reference Summary: Musicians to tackle US red tape  Musicians' groups are to tackle US visa regulations which are blamed for hindering British acts' chances of succeeding across the Atlantic. A singer hoping to perform in the US can expect to pay $1,300 (Â£680) simply for obtaining a visa. Nigel McCune from the Musicians' Union said British musicians are \"disadvantaged\" compared to their US counterparts. \"The US is the world's biggest music market, which means something has to be done about the creaky bureaucracy,\" says Mr McCune. \"The current situation is preventing British acts from maintaining momentum and developing in the US,\" he added. The Musicians' Union stance is being endorsed by the Music Managers' Forum (MMF), who say British artists face \"an uphill struggle\" to succeed in the US, thanks to the tough visa requirements, which are also seen as impractical. A US Embassy spokesman said: \"We are aware that entertainers require visas for time-specific visas and are doing everything we can to process those applications speedily.\"\n",
      "Generated Summary: Musicians to tackle US red tape  Musicians' groups are to tackle US visa regulations which are blamed for hindering British acts' chances of succeeding across the Atlantic. Nigel McCune from the Musicians' Union said British musicians are \"disadvantaged\" compared to their US counterparts. \"If you make a mistake on your form, you risk a five-year ban and thus the ability to further your career,\" says Mr McCune. \"The US is the world's biggest music market, which means something has to be done about the creaky bureaucracy,\" says Mr McCune. The Musicians' Union stance is being endorsed by the Music Managers' Forum (MMF), who say British artists face \"an uphill struggle\" to succeed in the US, thanks to the tough visa requirements, which are also seen as impractical. The MMF's general secretary James Seller said: \"Imagine if you were an orchestra from the Orkneys? \"It's still very important, but there are other markets like Europe, India and China,\" added Mr Seller. A Department for Media, Culture and Sport spokeswoman said: \"We're aware that people are experiencing problems, and are working with the US embassy and record industry to see what we can do about it.\" A US Embassy spokesman said: \"We are aware that entertainers require visas for time-specific visas and are doing everything we can to process those applications speedily.\"\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.8448, 'p': 0.6405, 'f': 0.7286}, 'rouge-2': {'r': 0.7736, 'p': 0.5829, 'f': 0.6649}, 'rouge-l': {'r': 0.8362, 'p': 0.634, 'f': 0.7212}}\n",
      "\n",
      "Article ID: 1\n",
      "Reference Summary: U2's desire to be number one  U2, who have won three prestigious Grammy Awards for their hit Vertigo, are stubbornly clinging to their status as one of the biggest bands in the world. They also have to want it. They have to want to be the biggest band ever and not stop wanting it. Their new album, How To Dismantle An Atomic Bomb, comes 28 years after the schoolfriends got together in Dublin and 17 years after The Joshua Tree cemented their place on the all-time rock A-list. Vertigo, the first single from the new album, went straight into the UK singles chart at number one, knocking Eminem off the top spot and giving them their 26th top 10 hit. \"The challenge is to be bigger and bolder and better - to make records the whole world will listen to,\" Bono recently said. We don't want to be thought of as a veteran band.\" The band have done \"everything in their considerable powers\" to ensure they remain the biggest band in the world, according to Q magazine editor Paul Rees. They are, perhaps, alone as the only rock band that has got better with age.\" The stadium-filling, anthemic sound was U2's aim from the start, and their third album, War, saw them make the breakthrough on both sides of the Atlantic, going to number one in the UK and 12 in the US. Songs like Sunday Bloody Sunday and New Year's Day brought success and an image as a political and spiritual band - which Bono rejected as a cliche. In 1987, The Joshua Tree broke sales records and saw the band reach the height of their powers with hits including Where the Streets Have No Name, I Still Haven't Found What I'm Looking For and With Or Without You. The end of the decade marked a crucial point for the band - they had reached the top but still yearned for new challenges and achievements. These came in the form of explorations of different branches of rock and forays into electronic dance music, plus wildly extravagant stage shows, while still trying to retain their mass appeal. Before the release of How To Dismantle An Atomic Bomb, they had sold 125 million albums around the world. But they still want more.\n",
      "Generated Summary: U2's desire to be number one  U2, who have won three prestigious Grammy Awards for their hit Vertigo, are stubbornly clinging to their status as one of the biggest bands in the world. The music must be inspired and appeal across generations and be distinctive, if not always groundbreaking. Their new album, How To Dismantle An Atomic Bomb, comes 28 years after the schoolfriends got together in Dublin and 17 years after The Joshua Tree cemented their place on the all-time rock A-list. Vertigo, the first single from the new album, went straight into the UK singles chart at number one, knocking Eminem off the top spot and giving them their 26th top 10 hit. \"The challenge is to be bigger and bolder and better - to make records the whole world will listen to,\" Bono recently said. The band have done \"everything in their considerable powers\" to ensure they remain the biggest band in the world, according to Q magazine editor Paul Rees. The other key ingredient was the fact they were highly organised, Mr Rees said. Songs like Sunday Bloody Sunday and New Year's Day brought success and an image as a political and spiritual band - which Bono rejected as a cliche. In 1987, The Joshua Tree broke sales records and saw the band reach the height of their powers with hits including Where the Streets Have No Name, I Still Haven't Found What I'm Looking For and With Or Without You. Those songs took the band's epic, atmospheric sound to a simple, powerful and popular pinnacle. The end of the decade marked a crucial point for the band - they had reached the top but still yearned for new challenges and achievements. These came in the form of explorations of different branches of rock and forays into electronic dance music, plus wildly extravagant stage shows, while still trying to retain their mass appeal. The Achtung Baby album in 1991 was followed by Zooropa, Pop and their corresponding stadium tours, which featured giant olives, flying cars, live phone calls to the White House and Bono's transformation into alter-egos The Fly and MacPhisto.\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.821, 'p': 0.7801, 'f': 0.8}, 'rouge-2': {'r': 0.7349, 'p': 0.7478, 'f': 0.7413}, 'rouge-l': {'r': 0.8166, 'p': 0.7759, 'f': 0.7957}}\n",
      "\n",
      "Article ID: 2\n",
      "Reference Summary: Rocker Doherty in on-stage fight  Rock singer Pete Doherty has been involved in a fight with his band's guitarist at their biggest gig to date. Babyshambles played for 5,000 fans at London's Brixton Academy on Tuesday. The former Libertines singer traded blows with guitarist Patrick Walden. On Monday Doherty faced blackmail and robbery charges in court, which he denies. He is out on Â£50,000 bail and the judge agreed to extend his 2200 GMT curfew deadline by two hours so he could play the Brixton gig. Babyshambles, which he formed after his acrimonious departure from the Libertines, played a warm-up show at The Garage, north London, on Monday. On Tuesday, Doherty and his three bandmates were introduced to the crowd by Mick Jones, the former Clash guitarist who produced the Libertines' second album. Doherty, 25, had to be home by midnight to observe the curfew, which is one of the conditions of his bail.\n",
      "Generated Summary: Rocker Doherty in on-stage fight  Rock singer Pete Doherty has been involved in a fight with his band's guitarist at their biggest gig to date. But the group had to stop during the next song to persuade fans not to push forward and allow security guards to pull people out of the crush. Doherty appealed to fans to calm down, saying: \"There's a few people getting hurt down the front, you've got to move back.\" The music resumed minutes later but after several more songs, the singer appeared to accidentally disconnect Walden's guitar, leading the pair to trade kicks and punches.\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.283, 'p': 0.3797, 'f': 0.3243}, 'rouge-2': {'r': 0.1711, 'p': 0.2574, 'f': 0.2055}, 'rouge-l': {'r': 0.2736, 'p': 0.3671, 'f': 0.3135}}\n"
     ]
    }
   ],
   "source": [
    "from ML_models.randomforest import RandomForestClassifierModel\n",
    "model_bbc_rf = RandomForestClassifierModel(\"BBC\", bbc_processed_df)\n",
    "model_bbc_rf.run()\n",
    "model_bbc_rf.show_predictions(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c670cdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running classification on imdb Dataset ===\n",
      "\n",
      "Train Accuracy: 0.7743\n",
      "Test Accuracy: 0.7241\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.67      0.71      3037\n",
      "           1       0.70      0.78      0.74      3017\n",
      "\n",
      "    accuracy                           0.72      6054\n",
      "   macro avg       0.73      0.72      0.72      6054\n",
      "weighted avg       0.73      0.72      0.72      6054\n",
      "\n",
      "\n",
      "=== Article-wise Summary Evaluation ===\n",
      "\n",
      "Article ID: 0\n",
      "Reference Summary: ...\n",
      "Generated Summary: One of the other reviewers has mentioned that after watching just Oz episode you ll be hooked They are right as this is exactly what happened with me The first thing that struck me about Oz was its brutality and unflinching scenes of violence which set in right from the word GO Trust me this is not show for the faint hearted or timid\n",
      "Error computing ROUGE: Reference or generated summary is empty.\n",
      "\n",
      "Article ID: 1\n",
      "Reference Summary: A wonderful little production The filming technique is very unassuming very old time BBC fashion and gives comforting and sometimes discomforting sense of realism to the entire piece The actors are extremely well chosen Michael Sheen not only has got all the polari\n",
      "Generated Summary: A wonderful little production The filming technique is very unassuming very old time BBC fashion and gives comforting and sometimes discomforting sense of realism to the entire piece The actors are extremely well chosen Michael Sheen not only has got all the polari but he has all the voices down pat too You can truly see the seamless editing guided by the references to Williams diary entries not only is it well worth the watching\n",
      "ROUGE Scores: {'rouge-1': {'r': 1.0, 'p': 0.65, 'f': 0.7879}, 'rouge-2': {'r': 1.0, 'p': 0.5833, 'f': 0.7368}, 'rouge-l': {'r': 1.0, 'p': 0.65, 'f': 0.7879}}\n",
      "\n",
      "Article ID: 2\n",
      "Reference Summary: ...\n",
      "Generated Summary: I thought this was wonderful way to spend time on too hot summer weekend sitting in the air conditioned theater and watching light hearted comedy The plot is simplistic but the dialogue is witty and the characters are likable even the well bread suspected serial killer\n",
      "Error computing ROUGE: Reference or generated summary is empty.\n"
     ]
    }
   ],
   "source": [
    "from ML_models.randomforest import RandomForestClassifierModel\n",
    "model_bbc_rf = RandomForestClassifierModel(\"imdb\", imdb_processed_df)\n",
    "model_bbc_rf.run()\n",
    "model_bbc_rf.show_predictions(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e97a3c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Fady\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running on BBC Dataset ===\n",
      "Train Accuracy: 0.9407\n",
      "Test Accuracy: 0.9315\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96     12226\n",
      "           1       0.07      0.27      0.11       200\n",
      "\n",
      "    accuracy                           0.93     12426\n",
      "   macro avg       0.53      0.60      0.54     12426\n",
      "weighted avg       0.97      0.93      0.95     12426\n",
      "\n",
      "\n",
      "ROUGE Scores:\n",
      "rouge-1: 0.3028\n",
      "rouge-2: 0.2067\n",
      "rouge-l: 0.2960\n",
      "\n",
      "--- Article 1665 ---\n",
      "Predicted: \"Things have been building up over the past few years and I think this is the year for Ireland,\" he told BBC Sport. A lot of things are in our favour with England and France at home.\" \"For Ireland to win it we need to stay relatively injury free, and fortunately we are one of the few teams that have done that so far,\" Wood added. \"It is going to be tough and we need to take all the luck and opportunities that come our way.\"\n",
      "Reference: \"So many of the major England players have either retired in the last year or are injured that I think it will be very hard for them down in Cardiff,\" Wood added.Former captain Keith Wood believes Ireland can win only their second Grand Slam - and first since 1948 - in this year's RBS Six Nations Championship.After claiming their first Triple Crown for 19 years last season, Wood tips his former team-mates to go one better.\"For Ireland to win it we need to stay relatively injury free, and fortunately we are one of the few teams that have done that so far,\" Wood added.\"Wales have had four brilliant games in the last year or so and lost all four, so the time is right for them now to beat one of the major teams.\"Ireland's last game of the tournament is against Wales in Cardiff - a fixture they have not lost since 1983.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 1348 ---\n",
      "Predicted: USADA chief executive officer Terry Madden said the action taken against Collins was further proof of that.\n",
      "Reference: Sprinter Michelle Collins has received an eight-year ban for doping offences after a hearing at the North American Court of Arbitration for Sport (CAS).\"The USADA has proved, beyond a reasonable doubt, that Collins took EPO, the testosterone/epitestosterone cream and THG,\" said a CAS statement.Collins' ban is a result of her connection to the federal inquiry into the Balco doping scandal.USADA chief executive officer Terry Madden said the action taken against Collins was further proof of that.The USADA has built its cases on verbal evidence given to the federal investigation into Balco rather than test results.So far a total of 13 athletes have been sanctioned for violations involving drugs associated with the Balco doping scandal.The US Anti-Doping Agency (USADA) decided to press charges against Collins in the summer.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 433 ---\n",
      "Predicted: Cairn Energy in Indian gas find\n",
      "\n",
      "Shares in Cairn Energy rose 3.8% to 1,088 pence on Tuesday after the UK firm announced a fresh gas discovery in northern India.\n",
      "Reference: The firm, which last year made a number of other new finds in the Rajasthan area, said the latest discovery could lead to large gas volumes.Cairn has also been granted approval to extend its Rajasthan exploration area.A spokesman said the company's decision to carry out further investigations at the new find showed that it believed there was significant gas.Cairn's string of finds in Rajasthan last year saw it elevated to the FTSE 100 index of the UK's leading listed companies.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 1436 ---\n",
      "Predicted: England's defensive crisis grows\n",
      "\n",
      "England's defensive worries have deepened following the withdrawal of Tottenham's Ledley King from the squad to face Holland.\n",
      "Reference: But now he has pulled out with a bruised knee and is likely to be replaced by Carragher, alongside Brown.The 25-year-old was only called into the squad on Sunday night as cover following the enforced withdrawal of Upson, who has a hamstring injury.Injured Rio Ferdinand and Sol Campbell were both left out of the squad, and Matthew Upson has already pulled out.Eriksson has still not decided whether to call up any further back-up, having already summoned Phil Neville after Bridge pulled out with a foot injury.Wes Brown and Jamie Carragher are likely to be the makeshift partnership.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 1375 ---\n",
      "Predicted: Brizzel to run AAA's in Sheffield\n",
      "\n",
      "Ballymena sprinter Paul Brizzel will be among eight of Ireland's European Indoor hopefuls competing in this weekend's AAA's Championships.\n",
      "Reference: Corkman Mark Carroll confirmed in midweek that he would join Cragg in the European Championships.In-form James McIlroy will hope to confirm his place in the British team for Madrid by winning the 800m title.US-based Alistair Cragg and Mark Carroll are the only Irish athletes selected so far for the Europeans who will not run in Sheffield.Ballymena sprinter Paul Brizzel will be among eight of Ireland's European Indoor hopefuls competing in this weekend's AAA's Championships.Brizzel will defend his 200m title in the British trials.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ML_models.random_forest import RandomForestSummarizer\n",
    "\n",
    "bbc_summarizer = RandomForestSummarizer(\"BBC\", bbc_df)\n",
    "bbc_summarizer.run()\n",
    "bbc_summarizer.show_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23de144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running on IMDB Dataset ===\n",
      "Train Accuracy: 0.9968\n",
      "Test Accuracy: 0.9924\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     11650\n",
      "           1       0.15      0.16      0.15        50\n",
      "\n",
      "    accuracy                           0.99     11700\n",
      "   macro avg       0.57      0.58      0.57     11700\n",
      "weighted avg       0.99      0.99      0.99     11700\n",
      "\n",
      "\n",
      "ROUGE Scores:\n",
      "rouge-1: 0.5617\n",
      "rouge-2: 0.4881\n",
      "rouge-l: 0.5612\n",
      "\n",
      "--- Article 13209 ---\n",
      "Predicted: Two old men sitting on park bench don really have problem with this scene Only problem is that it not scene it the entire movieYup movies don get anymore low concept than this They also don get anymore boring than this either but there worse to come because these two old men are chalk and cheese One is Nat Moyer who is Yiddish communist while the other is Midge Carter former golden gloves champion who also black Let me see now Jew and black man sitting on park bench getting along fine Well guess it possible though unlikely but if this film has such an inoffensive scenario why play up to the Jewish stereotype Why make them loud tribilistic rabble rousers who take hebrew oaths Slightly ironic that the Jews seen at the start of the movie are exactly the type of Jews seen in Nazi propaganda films in the sStereotypes aside moi dearz the problem with M NOT RAPPAPORT is that it written for an entirely different meduim than cinema it based on stage play and it shows Walter Matthau sleepwalks through his role as Nat while this commentator almost slept through the whole movie\n",
      "Reference: Two old men sitting on park bench don't really have problem with this scene. Only problem is that it not scene it the entire movie. Walter Matthau sleepwalks through his role as Nat while this commentator almost slept through the whole movie.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 6634 ---\n",
      "Predicted: Dark Harbor is moody little excursion into murky emotional waters that run extremely deep It basically character piece featuring finely layered performance by the always great Rickman with Polly Walker and Norman Reedus also excellent forming the other two sides of this strange triangle perfect late night cable film with surprise ending to boot\n",
      "Reference: Dark Harbor is moody little excursion into murky emotional waters that run extremely deep. It basically character piece featuring finely layered performance by the always great Rickman. Polly Walker and Norman Reedus also excellent forming the other two sides of this strange triangle.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 37454 ---\n",
      "Predicted: After long period in the space looking for the remains of planet Krypton Superman Brandon Routh returns to Earth He misses Lois Lane Kate Bosworth who got married and has son with Richard White James Marsden Meanwhile Lex Luthor Kevin Spacey plots an evil plan using crystals he stole from the Fortress of Solitude to create new land and submerge the USA After so many delightful movies of Superman with the unforgettable Christopher Reeve or TV shows like Lois and Clark and Teri Hatcher or Smallville great expectation was created for the return of Superman in this Bryan Singer version Unfortunately the awful story is too long and boring with many unnecessary parts lack of emotion and overrated in IMDb In addition the romance between Lois Lane and Superman is something shamefully ridiculous The twenty two years old actress Kate Bosworth is wrongly miscast playing the role of mature reporter and experienced mother of five years old boy Brandon Routh is two years younger than Tom Welling who plays teenager Clark Kent in Smallville The character of Parker Posey Kitty Kowalski is actually silly caricature Last but not the least and in spite of being terrific Lex Luthor Kevin Spacey is forty five years old therefore older and older than the rest of the lead cast The corny conclusion looks like soap opera and is terrible My vote is four Title Brazil Superman Returns\n",
      "Reference: After long period in the space looking for the remains of planet Krypton Superman Brandon Routh returns to Earth He misses Lois Lane Kate Bosworth who got married and has son with Richard White James Marsden Meanwhile Lex Luthor Kevin Spacey plots an evil plan using crystals he stole from the Fortress of Solitude to create new land and submerge the USA.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 8308 ---\n",
      "Predicted: There were lot of things going against this movie for me before watched it First was typical high school senior in Shakespeare class didn really even like much less understood half of Shakespeare would be no more than UNINTELLIGIBLE without me pouring ALL my concentration into his almost encrypted plays encrypted with his extremely difficult to understand language and then still wouldn get most of it Second it was hours long never thought that could be good thing Well let me tell you something This movie was so masterful so beautiful actually understood all the language as it was being performed Now the script was followed to the letter in this movie the same script that was incomprehensible to me in Shakespeare class And here was my mind opening and me understanding it was doubting myself while watching the movie almost But lo and behold when performed and only then Shakespeare comes to life So this version of Hamlet showed me that Shakespeare is indeed master who wrote great stories When saw it on the big screen especially in the high budget major motion picture style with beautiful cinematography and photography and acted amazingly by Brannagh and cast somehow understood what was going on What was being said The language is awesome and passionate It allows for more raw emotion when words can describe something maybe Shakespeare words can still hold to this day that Fist of The North Star animated english dub is the greatest movie ever made No movie provides more sheer entertainment But for movie to come close to dethroning Fist from that position which Hamlet did it came close is truly amazing awe inspiring It wasn a movie It was an event Even more amazing it made me appreciate shakespeare Wow Powerful Powerful is the word One of the rare TRULY powerful movies out there This gets hundred trillion stars out of infinity stars Yes yes By the way all you kids out there in Shakespeare class forget it You re wasting you re time You have to see the plays performed Only then will justice be done to them\n",
      "Reference: There were lot of things going against this movie for me before watched it. This movie was so masterful so beautiful actually understood all the language as it was being performed. The script was followed to the letter in this movie the same script that was incomprehensible to me in Shakespeare class.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article 12120 ---\n",
      "Predicted: I sorry but even TJ Hooker Adrian Zmed couldn save this sequel went through half the movie thinking that this was spoof of the original Then came that wild and wacky motorcycle scene notice that this is the only movie that Patricia Birch directs and sadly realized they were trying to be serious did get kick out of the fact that the opposing gang having lost their wheels due to their gambling habits in the original Grease were forced to use motorcycles in the second movie Being shamed by that putz character Carrington d hate to see what they would resort to later maybe Mopeds also never bought the hackneyed theme hunky Australian boy can fit into Outsiders dominated school ergo goes for tough guy with stupid biker helmet look It was Disney story gone horribly awry So it looks like you CAN ruin good thing by placing bubble gum smacking Michelle Pfeiffer in musical The only thing took away from this movie was an idea of how many points out of ten to give it\n",
      "Reference: I sorry but even TJ Hooker Adrian Zmed couldn't save this sequel. It was Disney story gone horribly awry. So it looks like you CAN ruin good thing by placing bubble gum smacking Michelle Pfeiffer in musical.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ML_models.random_forest import RandomForestSummarizer\n",
    "\n",
    "bbc_summarizer = RandomForestSummarizer(\"IMDB\", imdb_df)\n",
    "bbc_summarizer.run()\n",
    "bbc_summarizer.show_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2801c4",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea16ccce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running classification on BBC Dataset ===\n",
      "\n",
      "Train Accuracy: 0.7293\n",
      "Test Accuracy: 0.6651\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.87      0.76      5027\n",
      "           1       0.64      0.36      0.46      3309\n",
      "\n",
      "    accuracy                           0.67      8336\n",
      "   macro avg       0.66      0.61      0.61      8336\n",
      "weighted avg       0.66      0.67      0.64      8336\n",
      "\n",
      "\n",
      "=== Article-wise Summary Evaluation ===\n",
      "\n",
      "Article ID: 1385\n",
      "Reference Summary: Martinez sees off Vinci challenge  Veteran Spaniard Conchita Martinez came from a set down to beat Italian Roberta Vinci at the Qatar Open in Doha. Slovakian Daniela Hantuchova beat Bulgarian Magdaleena Maleeva 4-6 6-4 6-3 to set up a second round clash with Russian Elena Bovina. The veteran Martinez found herself in trouble early on against Vinci with the Italian clinching the set thanks to breaks in the third and 11th games.\n",
      "Generated Summary: The veteran Martinez found herself in trouble early on against Vinci with the Italian clinching the set thanks to breaks in the third and 11th games. In the day's other matches, Japan's Ai Sugiyama defeated Australian Samantha Stosur 6-2 6-3 while Australian Nicole Pratt beat Tunisian Selima Sfar 7-5 6-2 and will next face compatriot Alicia Molik.\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.45454545454545453, 'p': 0.5, 'f': 0.47619047120181407}, 'rouge-2': {'r': 0.352112676056338, 'p': 0.44642857142857145, 'f': 0.393700782471325}, 'rouge-l': {'r': 0.43636363636363634, 'p': 0.48, 'f': 0.4571428521541951}}\n",
      "\n",
      "Article ID: 311\n",
      "Reference Summary: Dance music not dead says Fatboy  DJ Norman Cook - aka Fatboy Slim - has said that dance music is not dead, but has admitted it is currently going through a \"fallow patch\". The commercial failure of the latest albums by Britain's two biggest dance acts - Fatboy Slim's Palookaville and The Prodigy's Always Outnumbered Never Outgunned - has been coupled with the closure of many \"superclubs,\" and the folding of three dance music magazines. These developments lead some to suggest that dance was finished as a popular music genre. Cook acknowledged that much change in the dance world in the four years since his last album, Halfway Between The Gutter And The Stars, but he stressed this did not mean the dance scene was permanently over. \"Every week when I was making the album, I was reading articles about the demise of dance music - and obviously that affects you somewhat,\" he told BBC World Service's The Ticket programme. \"So I think, consciously or subconsciously, reading every week that dance music was dead I would think 'right, scrub that track then'.\" \"With a crowd that big, if the weather's nice, the atmosphere before I even go is so good that about halfway through the first record I think 'I've got them',\" Cook said. In particular, he said he had struggled to cope with tabloid intrusion during the temporary break-up of his marriage to Radio One presenter Zoe Ball, after she was linked with DJ Dan Peppe. \"The tabloid thing has been difficult at times,\" Cook said. He said that he had been \"determined\" that what had happened with Ball did not affect the album. \"At first I was doing deliberately jolly tunes so that people wouldn't think I was depressed,\" he explained. \"I said to Zoe, 'I did this track called My Masochistic Baby Went And Left Me, do you mind if it's on the album?'\" he recalled.\n",
      "Generated Summary: Dance music not dead says Fatboy  DJ Norman Cook - aka Fatboy Slim - has said that dance music is not dead, but has admitted it is currently going through a \"fallow patch\". The commercial failure of the latest albums by Britain's two biggest dance acts - Fatboy Slim's Palookaville and The Prodigy's Always Outnumbered Never Outgunned - has been coupled with the closure of many \"superclubs,\" and the folding of three dance music magazines. Last month the Brit Awards announced they would no longer be awarding a Best Dance Act prize, with the Brits committee announcing that \"dance music is no longer where it's happening in music.\" In particular, he said he had struggled to cope with tabloid intrusion during the temporary break-up of his marriage to Radio One presenter Zoe Ball, after she was linked with DJ Dan Peppe.\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.4271356783919598, 'p': 0.8173076923076923, 'f': 0.5610561011020707}, 'rouge-2': {'r': 0.3432343234323432, 'p': 0.7647058823529411, 'f': 0.4738040959513495}, 'rouge-l': {'r': 0.41708542713567837, 'p': 0.7980769230769231, 'f': 0.5478547809700575}}\n",
      "\n",
      "Article ID: 1972\n",
      "Reference Summary: The real danger is not what happens to your data as it crosses the net, argues analyst Bill Thompson. The Financial Services Authority has warned banks and other financial institutions that members of criminal gangs may be applying for jobs which give them access to confidential customer data. The fear is not that they will steal money from our bank accounts but that they will instead steal something far more valuable in our digital society - our identities. Armed with the personal details that a bank holds, plus a fake letter or two, it is apparently easy to get a loan, open a bank account with an overdraft or get a credit card in someone else's name. But, however careful you may be, if the organisations you trust with your personal data, bank accounts and credit cards are not able to look after their databases properly then you are in trouble. And as we all become aware of the danger of identity theft and look more carefully for unexpected transactions on our statements, banks should have good enough records and logs to trace the people who might have accessed the account details. Fortunately there are now ways to keep bank systems more secure from the sort of data theft that involves taking a portable hard drive or flash memory card into the office, plugging it into a USB slot and sucking down customer files. In fact I do not know of a single case where an e-mail containing payment details has led to card fraud. And just last week the online bank Cahoot admitted that its customer account details could be read by anyone who could guess a login name. Whether it is external hackers breaking in because of poor system security or internal staff abusing the access they get as part of their job, the issue is the same: how do we make sure that our personal data is not abused? After all, I bank with Cahoot but it would be so much hassle to move my accounts that I did not even consider it when I heard about their security problems. I doubt many others have closed their accounts, especially when there is little guarantee that other banks are not going to make the same sort of mistake in future. The two options would seem to be more stringent data protection law, so that companies really feel the pressure to improve their internal processes, or a wave of civil lawsuits against financial institutions with sloppy practices whose customers suffer from identity theft.\n",
      "Generated Summary: The two options would seem to be more stringent data protection law, so that companies really feel the pressure to improve their internal processes, or a wave of civil lawsuits against financial institutions with sloppy practices whose customers suffer from identity theft.\n",
      "ROUGE Scores: {'rouge-1': {'r': 0.1659919028340081, 'p': 1.0, 'f': 0.2847222197803338}, 'rouge-2': {'r': 0.1, 'p': 1.0, 'f': 0.18181818016528928}, 'rouge-l': {'r': 0.1659919028340081, 'p': 1.0, 'f': 0.2847222197803338}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ML_models.xgboost import XGBoostClassifierModel\n",
    "\n",
    "# ✅ Use the actual DataFrame variable, not a string\n",
    "# Assuming bbc_processed_df was defined earlier\n",
    "df = bbc_processed_df\n",
    "\n",
    "# Run the model\n",
    "model = XGBoostClassifierModel(dataset_name=\"BBC\", df=df)\n",
    "model.run()\n",
    "model.show_predictions(n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b2c80b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running classification on imdb Dataset ===\n",
      "\n",
      "Train Accuracy: 0.8545\n",
      "Test Accuracy: 0.775\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87      2018\n",
      "           1       0.50      0.11      0.18       587\n",
      "\n",
      "    accuracy                           0.78      2605\n",
      "   macro avg       0.65      0.54      0.53      2605\n",
      "weighted avg       0.72      0.78      0.71      2605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ML_models.xgboost import XGBoostClassifierModel\n",
    "\n",
    "df = imdb_processed_df  # Your preprocessed DataFrame with 'text' and 'label' columns\n",
    "\n",
    "model = XGBoostClassifierModel(dataset_name=\"imdb\", df=df)\n",
    "model.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4f1578",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aafc69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== BBC Dataset Results =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.55      0.67      5043\n",
      "           1       0.67      0.91      0.77      5011\n",
      "\n",
      "    accuracy                           0.73     10054\n",
      "   macro avg       0.77      0.73      0.72     10054\n",
      "weighted avg       0.77      0.73      0.72     10054\n",
      "\n",
      "\n",
      "===== IMDB Dataset Results =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.75      0.83      2013\n",
      "           1       0.79      0.95      0.86      2023\n",
      "\n",
      "    accuracy                           0.85      4036\n",
      "   macro avg       0.86      0.85      0.85      4036\n",
      "weighted avg       0.86      0.85      0.85      4036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def train_and_evaluate(df, dataset_name=\"\"):\n",
    "    X = df[\"preprocessed_sentence\"]\n",
    "    y = df[\"label\"]\n",
    "\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\")\n",
    "    X_vec = vectorizer.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_vec, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(f\"\\n===== {dataset_name} Dataset Results =====\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Train on BBC\n",
    "train_and_evaluate(bbc_balanced, dataset_name=\"BBC\")\n",
    "\n",
    "# Train on IMDB\n",
    "train_and_evaluate(imdb_balanced, dataset_name=\"IMDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18e9d8b",
   "metadata": {},
   "source": [
    "#### Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09d5c0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fady\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Fady\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "c:\\Users\\Fady\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Fady\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Training model...\n",
      "Epoch 1 - Val Accuracy: 0.9923\n",
      "Epoch 2 - Val Accuracy: 0.9923\n",
      "Epoch 3 - Val Accuracy: 0.9923\n",
      "Epoch 4 - Val Accuracy: 0.9923\n",
      "Epoch 5 - Val Accuracy: 0.9923\n",
      "\n",
      "Sample Evaluation:\n",
      "\n",
      "📄 Article:\n",
      "Ad sales boost Time Warner profit\n",
      "\n",
      "Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.\n",
      "\n",
      "The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and high...\n",
      "\n",
      "✂️ Predicted Summary:\n",
      "Ad sales boost Time Warner profit  Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. \"Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility,\" chairman and chief executive Richard Parsons said.\n",
      "\n",
      "✅ ROUGE:\n",
      "{'rouge1': Score(precision=0.7123287671232876, recall=0.33986928104575165, fmeasure=0.4601769911504425), 'rouge2': Score(precision=0.5694444444444444, recall=0.26973684210526316, fmeasure=0.3660714285714286), 'rougeL': Score(precision=0.589041095890411, recall=0.28104575163398693, fmeasure=0.38053097345132747)}\n",
      "\n",
      "📄 Article:\n",
      "Dollar gains on Greenspan speech\n",
      "\n",
      "The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise.\n",
      "\n",
      "And Alan Greenspan highlighted the US government's willingness to curb spending and rising household savings a...\n",
      "\n",
      "✂️ Predicted Summary:\n",
      "The dollar has hit its highest level against the euro in almost three months after the Federal Reserve head said the US trade deficit is set to stabilise. In late trading in New York, the dollar reached $1.2871 against the euro, from $1.2974 on Thursday. China's currency remains pegged to the dollar and the US currency's sharp falls in recent months have therefore made Chinese export prices highly competitive.\n",
      "\n",
      "✅ ROUGE:\n",
      "{'rouge1': Score(precision=0.8356164383561644, recall=0.3588235294117647, fmeasure=0.5020576131687242), 'rouge2': Score(precision=0.7638888888888888, recall=0.3254437869822485, fmeasure=0.4564315352697095), 'rougeL': Score(precision=0.7397260273972602, recall=0.3176470588235294, fmeasure=0.44444444444444436)}\n",
      "\n",
      "📄 Article:\n",
      "Yukos unit buyer faces loan claim\n",
      "\n",
      "The owners of embattled Russian oil giant Yukos are to ask the buyer of its former production unit to pay back a $900m (Â£479m) loan.\n",
      "\n",
      "State-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part settle a $27.5bn tax claim against Yukos...\n",
      "\n",
      "✂️ Predicted Summary:\n",
      "Yukos unit buyer faces loan claim  The owners of embattled Russian oil giant Yukos are to ask the buyer of its former production unit to pay back a $900m (Â£479m) loan. State-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part settle a $27.5bn tax claim against Yukos. Yukos' owner Menatep Group says it will ask Rosneft to repay a loan that Yugansk had secured on its assets.\n",
      "\n",
      "✅ ROUGE:\n",
      "{'rouge1': Score(precision=0.7272727272727273, recall=0.4307692307692308, fmeasure=0.5410628019323672), 'rouge2': Score(precision=0.5921052631578947, recall=0.3488372093023256, fmeasure=0.43902439024390244), 'rougeL': Score(precision=0.4935064935064935, recall=0.2923076923076923, fmeasure=0.36714975845410625)}\n"
     ]
    }
   ],
   "source": [
    "from DL_models.vanilla_transformer import run_pipeline\n",
    "\n",
    "model = run_pipeline(bbc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830f84fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65c34c2e",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef86af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from DL_models.cnn import CNNExtractiveSummarizer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Prepare data\n",
    "# X = bbc_processed_df[\"preprocessed_sentence\"]\n",
    "# y = bbc_processed_df[\"label\"]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize model\n",
    "# cnn_bbc = CNNExtractiveSummarizer()\n",
    "\n",
    "# # Train/tune the model\n",
    "# cnn_bbc.tune(X_train, y_train, X_val_raw=X_test, y_val=y_test, epochs=30)\n",
    "\n",
    "# # Evaluate\n",
    "# print(\"BBC Dataset Evaluation (CNN):\")\n",
    "# cnn_bbc.evaluate(X_test, y_test)\n",
    "\n",
    "# # Generate summaries for a few articles\n",
    "# sample_article_ids = bbc_processed_df[\"article_id\"].unique()[:5]\n",
    "\n",
    "# for article_id in sample_article_ids:\n",
    "#     article_df = bbc_processed_df[bbc_processed_df[\"article_id\"] == article_id]\n",
    "#     reference_summary = \" \".join(\n",
    "#         article_df[article_df[\"label\"] == 1][\"article_sentences\"]\n",
    "#     )\n",
    "#     generated_summary = cnn_bbc.summarize(\n",
    "#         article_df[\"article_sentences\"].tolist(),\n",
    "#         article_df[\"preprocessed_sentence\"].tolist()\n",
    "#     )\n",
    "\n",
    "#     print(f\"\\nArticle ID: {article_id}\")\n",
    "#     print(\"Reference Summary:\", reference_summary[:200] + \"...\")\n",
    "#     print(\"Generated Summary:\", generated_summary[:200] + \"...\")\n",
    "\n",
    "#     rouge_scores = cnn_bbc.compute_rouge(generated_summary, reference_summary)\n",
    "#     if rouge_scores is not None:\n",
    "#         print(\"ROUGE Scores:\", rouge_scores[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c088b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from DL_models.cnn import CNNExtractiveSummarizer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Prepare data\n",
    "# X = imdb_processed_df[\"preprocessed_sentence\"]\n",
    "# y = imdb_processed_df[\"label\"]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize model\n",
    "# cnn_bbc = CNNExtractiveSummarizer()\n",
    "\n",
    "# # Train/tune the model\n",
    "# cnn_bbc.tune(X_train, y_train, X_val_raw=X_test, y_val=y_test, epochs=30)\n",
    "\n",
    "# # Evaluate\n",
    "# print(\"IMDB Dataset Evaluation (CNN):\")\n",
    "# cnn_bbc.evaluate(X_test, y_test)\n",
    "\n",
    "# # Generate summaries for a few articles\n",
    "# sample_article_ids = imdb_processed_df[\"article_id\"].unique()[:5]\n",
    "\n",
    "# for article_id in sample_article_ids:\n",
    "#     article_df = imdb_processed_df[imdb_processed_df[\"article_id\"] == article_id]\n",
    "#     reference_summary = \" \".join(\n",
    "#         article_df[article_df[\"label\"] == 1][\"article_sentences\"]\n",
    "#     )\n",
    "#     generated_summary = cnn_bbc.summarize(\n",
    "#         article_df[\"article_sentences\"].tolist(),\n",
    "#         article_df[\"preprocessed_sentence\"].tolist()\n",
    "#     )\n",
    "\n",
    "#     print(f\"\\nArticle ID: {article_id}\")\n",
    "#     print(\"Reference Summary:\", reference_summary[:200] + \"...\")\n",
    "#     print(\"Generated Summary:\", generated_summary[:200] + \"...\")\n",
    "\n",
    "#     rouge_scores = cnn_bbc.compute_rouge(generated_summary, reference_summary)\n",
    "#     if rouge_scores is not None:\n",
    "#         print(\"ROUGE Scores:\", rouge_scores[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b33e981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training on BBC ===\n",
      "Epoch 1 Loss: 1.0872\n",
      "Epoch 2 Loss: 1.0021\n",
      "Epoch 3 Loss: 0.8830\n",
      "Epoch 4 Loss: 0.6982\n",
      "Epoch 5 Loss: 0.4818\n",
      "Training completed in 281.33s\n",
      "Best Threshold: 0.25, F1: 0.6022\n",
      "\n",
      "ROUGE Scores:\n",
      "rouge-1: 0.3566\n",
      "rouge-2: 0.2505\n",
      "rouge-l: 0.3027\n",
      "\n",
      "--- Article ID: 1217 ---\n",
      "Predicted Summary:\n",
      " lord drayson whose company powderject win pound contract provide smallpox vaccine government september terror attack give party day christmas\n",
      "Reference Summary:\n",
      " party build poll war chests labour party receive donation final quarter new figure show significant donation come retire millionaire businessman philanthropist sir christopher ondaatje give party sum refrigerator magnate william haughey obe give also donation top conservative scottish business group focus scotland institute international research world large independent conference company also among gift tory donation total bearwood corporate service liberal democrat large donor joseph rowntree reform trust ltd company promote political reform constitutional change give sum registered political party require set quarter donation headquarters local constituency party receive\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article ID: 945 ---\n",
      "Predicted Summary:\n",
      " say fine would levy employer licence would remove mr mcconnell add near nine per cent rise tax revenue new york bar restaurant ireland one point three per cent volume sale fall decline ban main point plan comprehensive ban smoking enclose public place scotland scottish green party health spokeswoman eleanor scott say pleased scotland would follow success story new york ireland\n",
      "Reference Summary:\n",
      " tell scottish parliament wednesday comprehensive ban smoke public place would introduce spring mr mcconnell say country health rate lamentable least smoking say fine would levy employer licence would remove earlier scottish executive consider range option agree unanimously introduce ban smoke public place statement parliament mr mcconnell say licensed trade would ask join expert committee prior ban come force health argument far outweigh linger public disquiet complete ban claim licensed trade job would lose tell msps clear scotland must hold back poor public health single big contribution devolve government make reduce toll preventable death cause smoke mr mcconnell claim evidence smoke ban help smoker either give quicker smoke less scottish conservative party leader david mcletchie question would exempt ban scottish green party health spokeswoman eleanor scott say pleased scotland would follow success story new york ireland\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article ID: 572 ---\n",
      "Predicted Summary:\n",
      " film direct jeunet receive best actress picture director nomination\n",
      "Reference Summary:\n",
      " tautou film top cesar prize nod french film long engagement receive nomination france cesar film award despite recent ruling french enough cesar organiser modify rule allow film compete film direct jeunet receive best actress picture director nomination last november court judge film american compete french film festival ruling mean movie film france used french actor technician eligible compete french prize film best film category include police drama quai de orfevres arnaud desplechin king queen abdellatif kechiche france number one film chorus\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article ID: 695 ---\n",
      "Predicted Summary:\n",
      " add pair bring real warmth saturday night end felt enough format show\n",
      "Reference Summary:\n",
      " johnny denise lose passport johnny vaughan denise van outen saturday night entertainment show passport paradise return screen bbc say bbc spokeswoman say graham norton strictly dance fever would priority much card next year concentrate moment strictly come dancing phenomenally well say\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article ID: 1975 ---\n",
      "Predicted Summary:\n",
      " still want drink merry long day winter draw good pub guide offer service give location address near recommend pub\n",
      "Reference Summary:\n",
      " new year texting break record mobile phone essential recent new year festivity party mood auld lang syne number text message send anything go midnight december midnight january text message send uk wish happy new year friend family via text message become staple ingredient year large party case new year eve party texting useful unable speak hear noisy background say restaurant use text message tell customer special offer promotion anyone need bit january cheer party season use service set jongleur comedy club text joke day\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from DL_models.bilstm_attention import BiLSTMSummarizer\n",
    "\n",
    "bilstmn = BiLSTMSummarizer(\"BBC\", bbc_processed_df)\n",
    "bilstmn.train()\n",
    "bilstmn.evaluate()\n",
    "bilstmn.show_samples(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dee05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training on IMDB ===\n",
      "Epoch 1 Loss: 0.9286\n",
      "Epoch 2 Loss: 0.8791\n",
      "Epoch 3 Loss: 0.8417\n",
      "Epoch 4 Loss: 0.8230\n",
      "Epoch 5 Loss: 0.7406\n",
      "Training completed in 88.23s\n",
      "Best Threshold: 0.40, F1: 0.4321\n",
      "\n",
      "ROUGE Scores:\n",
      "rouge-1: 0.4443\n",
      "rouge-2: 0.3931\n",
      "rouge-l: 0.4315\n",
      "\n",
      "--- Article ID: 3460 ---\n",
      "Predicted Summary:\n",
      " hit rock bottom right begin bad act jumbled sequence event mean sure freddy movie suppose dreamlike creepy one like train wreck poor sequence event awful plot setup feel like come terrible headache like get scar freddy annoyance see many time one nothing different lot time want take awful one liner get tv screen\n",
      "Reference Summary:\n",
      " hit rock bottom right begin bad act jumbled sequence event mean sure freddy movie suppose dreamlike creepy one like train wreck poor sequence event awful plot setup feel like come terrible headache like get scar directing totally fail none suspense well craft horror previous sequel find even death scene mostly crass moronic death food especially except one cool scene craft like comic book battle movie get point storyline lame lame lame lame\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article ID: 1213 ---\n",
      "Predicted Summary:\n",
      " high school student take health class year topic drug learn harm cause person talk still believe know drug really mess person anyway teacher want u watch naturally groan start sleep like rest class actually enjoy movie totally real sugar coat character amazing believable even plot outstandingly realistic believable like movie mainly get point effect drug take abuser consequence person deal everyone reassure nothing bad happen well let get serious anything happen small town even best friend like sam chris movie show person really learn lot watch pretty effective\n",
      "Reference Summary:\n",
      " \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article ID: 885 ---\n",
      "Predicted Summary:\n",
      " one bad movie ever see comedy funny also badly make top direction full unnecessary split screen effect two hero fantasy language annoy confuse quite lot touch others genitals time bad nonsense cheap attempt give movie appeal refer german history show sensitive aspect hero find climax show erkan stefan cure mentally ill woman joyful lifestyle expect anything good director michael bully herbig also make two funny tv show funny western movie nearly funny sf comedy movie\n",
      "Reference Summary:\n",
      " \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article ID: 2761 ---\n",
      "Predicted Summary:\n",
      " want daft little horror film hark back style eighty woodland flick might find enjoyment\n",
      "Reference Summary:\n",
      " film actually work fairly original idea never see nymph throw heaven horror movie\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Article ID: 768 ---\n",
      "Predicted Summary:\n",
      " teacher show u movie first grade see since watch trailer though look like first grade movie think horrify movie could barely watch\n",
      "Reference Summary:\n",
      " teacher show u movie first grade see since watch trailer though look like first grade movie think horrify movie could barely watch\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "bilstm = BiLSTMSummarizer(\"IMDB\", imdb_processed_df)\n",
    "bilstm.train()\n",
    "bilstm.evaluate()\n",
    "bilstm.show_samples(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1ba7ef",
   "metadata": {},
   "source": [
    "FeedForward Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bc676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ===== Cell 1: Imports =====\n",
    "# from DL_models.FNN import (FeedForwardNet, extract_features, prepare_dataloaders,\n",
    "#                            compute_class_weight, train_model)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c821c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ===== Cell 2: Data Preparation =====\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# X_train_df, X_val_df, y_train, y_val = train_test_split(\n",
    "#     bbc_processed_df[['preprocessed_sentence']],\n",
    "#     bbc_processed_df['label'].values,\n",
    "#     test_size=0.2,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# X_train, X_val, vectorizer = extract_features(X_train_df, X_val_df)\n",
    "\n",
    "# train_loader, val_loader = prepare_dataloaders(X_train, y_train, X_val, y_val, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1adffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ===== Cell 3: Model Initialization =====\n",
    "# input_size = X_train.shape[1]\n",
    "# model = FeedForwardNet(input_size)\n",
    "# pos_weight = compute_class_weight(y_train).to(device)\n",
    "# criterion = torch.nn.BCELoss(pos_weight)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77061a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ===== Cell 4: Training =====\n",
    "# train_model(model, train_loader, val_loader, criterion, optimizer, device=device, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405290ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rouge_score import rouge_scorer\n",
    "# import numpy as np\n",
    "\n",
    "# # ===== Cell 6: ROUGE Evaluation =====\n",
    "# def evaluate_rouge(df, model, vectorizer, top_k=3):\n",
    "#     scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "#     scores = []\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for article_id in df['article_id'].unique():\n",
    "#             article_df = df[df['article_id'] == article_id]\n",
    "#             X = vectorizer.transform(article_df['preprocessed_sentence']).toarray()\n",
    "#             preds = model(torch.tensor(X, dtype=torch.float32)).numpy()\n",
    "\n",
    "#             top_indices = preds.argsort()[-top_k:][::-1]\n",
    "#             predicted_summary = \" \".join(article_df.iloc[top_indices][\"article_sentences\"])\n",
    "#             reference_summary = imdb_df.loc[article_id][\"Summary\"]\n",
    "\n",
    "#             score = scorer.score(reference_summary, predicted_summary)\n",
    "#             scores.append(score)\n",
    "\n",
    "#     return scores\n",
    "\n",
    "# rouge_scores = evaluate_rouge(bbc_processed_df, model, vectorizer)\n",
    "\n",
    "# avg_rouge1 = np.mean([s[\"rouge1\"].fmeasure for s in rouge_scores])\n",
    "# avg_rouge2 = np.mean([s[\"rouge2\"].fmeasure for s in rouge_scores])\n",
    "# avg_rougeL = np.mean([s[\"rougeL\"].fmeasure for s in rouge_scores])\n",
    "\n",
    "# print(f\"Average ROUGE-1: {avg_rouge1:.4f}\")\n",
    "# print(f\"Average ROUGE-2: {avg_rouge2:.4f}\")\n",
    "# print(f\"Average ROUGE-L: {avg_rougeL:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ca856e",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b595aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\fady\\appdata\\roaming\\python\\python312\\site-packages (from rouge) (1.16.0)\n",
      "Requirement already satisfied: rouge_score in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rouge_score) (2.2.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rouge_score) (2.1.3)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\fady\\appdata\\roaming\\python\\python312\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk->rouge_score) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk->rouge_score) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\fady\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk->rouge_score) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Fady\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,142,336</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m30\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │     \u001b[38;5;34m4,142,336\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,191,809</span> (15.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,191,809\u001b[0m (15.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,191,809</span> (15.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,191,809\u001b[0m (15.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6207 - loss: 0.6479\n",
      "Epoch 1: val_loss improved from inf to 0.61103, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 82ms/step - accuracy: 0.6209 - loss: 0.6477 - val_accuracy: 0.6716 - val_loss: 0.6110 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7358 - loss: 0.5395\n",
      "Epoch 2: val_loss did not improve from 0.61103\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.7358 - loss: 0.5395 - val_accuracy: 0.6587 - val_loss: 0.6332 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.8141 - loss: 0.4359\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.61103\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.8139 - loss: 0.4361 - val_accuracy: 0.6517 - val_loss: 0.6659 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.8610 - loss: 0.3611\n",
      "Epoch 4: val_loss did not improve from 0.61103\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.8609 - loss: 0.3612 - val_accuracy: 0.6378 - val_loss: 0.8631 - learning_rate: 5.0000e-04\n",
      "Epoch 4: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\n",
      "--- Example Article ---\n",
      "Ad sales boost Time Warner profit\n",
      "\n",
      "Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier.\n",
      "\n",
      "The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL.\n",
      "\n",
      "Time  ...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step\n",
      "\n",
      "--- Extracted Summary ---\n",
      "Ad sales boost Time Warner profit\n",
      "\n",
      "Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier. The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales.\n",
      "\n",
      "--- ROUGE Scores BBC ---\n",
      "rouge1: Precision: 0.7358, Recall: 0.2549, F1: 0.3786\n",
      "rouge2: Precision: 0.4423, Recall: 0.1513, F1: 0.2255\n",
      "rougeL: Precision: 0.5849, Recall: 0.2026, F1: 0.3010\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def compute_rouge_scores(pred_summary, reference_summary):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference_summary, pred_summary)\n",
    "    return scores\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, TimeDistributed, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# === Load your data ===\n",
    "\n",
    "texts = bbc_df[\"Article\"]\n",
    "summaries = ['starttoken ' + s + ' endtoken' for s in bbc_df[\"Summary\"]]\n",
    "\n",
    "# === Tokenizer setup ===\n",
    "text_tokenizer = Tokenizer(num_words=5000, oov_token='UNK')\n",
    "text_tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# === Parameters ===\n",
    "max_sent_len = 30\n",
    "max_sents = 5\n",
    "\n",
    "# === Preprocess articles ===\n",
    "def preprocess_articles(texts):\n",
    "    all_articles = []\n",
    "    for article in texts:\n",
    "        sents = sent_tokenize(article)[:max_sents]\n",
    "        tokenized = text_tokenizer.texts_to_sequences(sents)\n",
    "        padded = pad_sequences(tokenized, maxlen=max_sent_len, padding='post')\n",
    "        padded = np.pad(padded, ((0, max_sents - len(padded)), (0, 0)), mode='constant')\n",
    "        all_articles.append(padded)\n",
    "    return np.array(all_articles)\n",
    "\n",
    "X = preprocess_articles(texts)\n",
    "\n",
    "# # === Generate labels for extractive summary ===\n",
    "def label_sentences(texts, summaries, top_n=3):\n",
    "    labels = []\n",
    "    for article, summary in zip(texts, summaries):\n",
    "        sents = sent_tokenize(article)[:max_sents]\n",
    "        summary_text = summary.replace(\"starttoken \", \"\").replace(\" endtoken\", \"\")\n",
    "        \n",
    "        if not sents:\n",
    "            labels.append(np.zeros(max_sents))\n",
    "            continue\n",
    "\n",
    "        # Compute TF-IDF similarity\n",
    "        tfidf = TfidfVectorizer().fit(sents + [summary_text])\n",
    "        sent_vecs = tfidf.transform(sents)\n",
    "        summary_vec = tfidf.transform([summary_text])\n",
    "        sims = cosine_similarity(summary_vec, sent_vecs).flatten()\n",
    "\n",
    "        # Get top-N most similar sentence indices\n",
    "        top_indices = sims.argsort()[-top_n:]\n",
    "        label = np.zeros(len(sents))\n",
    "        label[top_indices] = 1\n",
    "\n",
    "        # Pad to max_sents\n",
    "        padded_label = np.pad(label, (0, max_sents - len(label)), 'constant')\n",
    "        labels.append(padded_label)\n",
    "        \n",
    "    return np.array(labels)\n",
    "\n",
    "\n",
    "y = label_sentences(texts, summaries, top_n=3)\n",
    "\n",
    "# === Train-test split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# === Model Definition ===\n",
    "input_layer = Input(shape=(max_sents, max_sent_len))\n",
    "embedding_layer = TimeDistributed(Embedding(input_dim=len(text_tokenizer.word_index)+1, output_dim=128))(input_layer)\n",
    "lstm_layer = TimeDistributed(LSTM(64))(embedding_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(lstm_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# === Callbacks ===\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-5, verbose=1)\n",
    "checkpoint = ModelCheckpoint('best_extractive_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "# === Train ===\n",
    "model.fit(\n",
    "    X_train,\n",
    "    np.expand_dims(y_train, -1),\n",
    "    validation_split=0.1,\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# === Inference ===\n",
    "\n",
    "def extract_summary(article):\n",
    "    sents = sent_tokenize(article)[:max_sents]\n",
    "    tokenized = text_tokenizer.texts_to_sequences(sents)\n",
    "    padded = pad_sequences(tokenized, maxlen=max_sent_len, padding='post')\n",
    "    padded = np.pad(padded, ((0, max_sents - len(padded)), (0, 0)), mode='constant')\n",
    "    \n",
    "    prediction = model.predict(np.expand_dims(padded, 0))[0].flatten()\n",
    "    \n",
    "    # === Dynamic threshold based on mean score\n",
    "    threshold = prediction.mean()\n",
    "    \n",
    "    summary = [s for i, s in enumerate(sents) if prediction[i] > threshold]\n",
    "    # Fallback if no sentence is selected\n",
    "    if not summary:\n",
    "        top_idx = prediction.argmax()\n",
    "        summary = [sents[top_idx]]\n",
    "    \n",
    "    return ' '.join(summary)\n",
    "\n",
    "# === Example Prediction + Evaluation ===\n",
    "example_idx = 0\n",
    "article = texts.iloc[example_idx]\n",
    "reference_summary = bbc_df[\"Summary\"].iloc[example_idx].replace(\"starttoken \", \"\").replace(\" endtoken\", \"\")\n",
    "\n",
    "print(\"\\n--- Example Article ---\")\n",
    "print(article[:500], \"...\")\n",
    "\n",
    "# Predict summary\n",
    "pred_summary = extract_summary(article)\n",
    "print(\"\\n--- Extracted Summary ---\")\n",
    "print(pred_summary)\n",
    "\n",
    "# Compute ROUGE\n",
    "rouge_scores = compute_rouge_scores(pred_summary, reference_summary)\n",
    "print(\"\\n--- ROUGE Scores BBC ---\")\n",
    "for key, value in rouge_scores.items():\n",
    "    print(f\"{key}: Precision: {value.precision:.4f}, Recall: {value.recall:.4f}, F1: {value.fmeasure:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e42c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\fady\\appdata\\roaming\\python\\python312\\site-packages (from rouge) (1.16.0)\n",
      "Requirement already satisfied: rouge_score in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rouge_score) (2.2.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rouge_score) (2.1.3)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\fady\\appdata\\roaming\\python\\python312\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk->rouge_score) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\fady\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk->rouge_score) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\fady\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk->rouge_score) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Fady\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,236,200</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m30\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m100\u001b[0m)     │     \u001b[38;5;34m3,236,200\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m42,240\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,278,505</span> (12.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,278,505\u001b[0m (12.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,305</span> (165.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m42,305\u001b[0m (165.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,236,200</span> (12.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,236,200\u001b[0m (12.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9857 - loss: 0.0331\n",
      "Epoch 1: val_loss improved from inf to 0.00001, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 59ms/step - accuracy: 0.9857 - loss: 0.0331 - val_accuracy: 1.0000 - val_loss: 1.0450e-05 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 1.0317e-05\n",
      "Epoch 2: val_loss improved from 0.00001 to 0.00000, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 1.0315e-05 - val_accuracy: 1.0000 - val_loss: 2.3533e-06 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1974/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 2.6681e-06\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 3: val_loss improved from 0.00000 to 0.00000, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 2.6675e-06 - val_accuracy: 1.0000 - val_loss: 7.4317e-07 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 1.0023e-06\n",
      "Epoch 4: val_loss improved from 0.00000 to 0.00000, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 1.0023e-06 - val_accuracy: 1.0000 - val_loss: 3.8727e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 5.1363e-07\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 5: val_loss improved from 0.00000 to 0.00000, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 5.1358e-07 - val_accuracy: 1.0000 - val_loss: 1.7012e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 2.4595e-07\n",
      "Epoch 6: val_loss improved from 0.00000 to 0.00000, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 2.4593e-07 - val_accuracy: 1.0000 - val_loss: 9.8545e-08 - learning_rate: 2.5000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 1.3991e-07\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 7: val_loss improved from 0.00000 to 0.00000, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 1.3990e-07 - val_accuracy: 1.0000 - val_loss: 4.7582e-08 - learning_rate: 2.5000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 7.3384e-08\n",
      "Epoch 8: val_loss improved from 0.00000 to 0.00000, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 7.3380e-08 - val_accuracy: 1.0000 - val_loss: 2.9140e-08 - learning_rate: 1.2500e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 4.4152e-08\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 9: val_loss improved from 0.00000 to 0.00000, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 4.4149e-08 - val_accuracy: 1.0000 - val_loss: 1.5255e-08 - learning_rate: 1.2500e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 2.5486e-08\n",
      "Epoch 10: val_loss improved from 0.00000 to 0.00000, saving model to best_extractive_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1975/1975\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 2.5485e-08 - val_accuracy: 1.0000 - val_loss: 1.0603e-08 - learning_rate: 6.2500e-05\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "\n",
      "--- IMDB Sample Article ---\n",
      "One of the other reviewers has mentioned that after watching just Oz episode you ll be hooked They are right as this is exactly what happened with me The first thing that struck me about Oz was its brutality and unflinching scenes of violence which set in right from the word GO Trust me this is not show for the faint hearted or timid This show pulls no punches with regards to drugs sex or violence Its is hardcore in the classic use of the word It is called OZ as that is the nickname given to the ...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\n",
      "--- Extracted Summary ---\n",
      "One of the other reviewers has mentioned that after watching just Oz episode you ll be hooked They are right as this is exactly what happened with me The first thing that struck me about Oz was its brutality and unflinching scenes of violence which set in right from the word GO Trust me this is not show for the faint hearted or timid This show pulls no punches with regards to drugs sex or violence Its is hardcore in the classic use of the word It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary It focuses mainly on Emerald City an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda Em City is home to many Aryans Muslims gangstas Latinos Christians Italians Irish and more so scuffles death stares dodgy dealings and shady agreements are never far away would say the main appeal of the show is due to the fact that it goes where other shows wouldn dare Forget pretty pictures painted for mainstream audiences forget charm forget romance OZ doesn mess around The first episode ever saw struck me as so nasty it was surreal couldn say was ready for it but as watched more developed taste for Oz and got accustomed to the high levels of graphic violence Not just violence but injustice crooked guards who ll be sold out for nickel inmates who ll kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience Watching Oz you may become comfortable with what is uncomfortable viewing thats if you can get in touch with your darker side\n",
      "\n",
      "--- ROUGE Scores ---\n",
      "rouge1: Precision: 0.1860, Recall: 1.0000, F1: 0.3137\n",
      "rouge2: Precision: 0.1800, Recall: 0.9818, F1: 0.3042\n",
      "rougeL: Precision: 0.1860, Recall: 1.0000, F1: 0.3137\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "!pip install rouge\n",
    "!pip install rouge_score\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def compute_rouge_scores(pred_summary, reference_summary):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference_summary, pred_summary)\n",
    "    return scores\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, TimeDistributed, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "nltk.download('punkt')\n",
    "# === Tokenizer setup ===\n",
    "text_tokenizer = Tokenizer(num_words=5000, oov_token='UNK')\n",
    "text_tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# === Parameters ===\n",
    "max_sent_len = 30\n",
    "max_sents = 5\n",
    "\n",
    "# === Preprocess articles ===\n",
    "def preprocess_articles(texts):\n",
    "    all_articles = []\n",
    "    for article in texts:\n",
    "        sents = sent_tokenize(article)[:max_sents]\n",
    "        tokenized = text_tokenizer.texts_to_sequences(sents)\n",
    "        padded = pad_sequences(tokenized, maxlen=max_sent_len, padding='post')\n",
    "        padded = np.pad(padded, ((0, max_sents - len(padded)), (0, 0)), mode='constant')\n",
    "        all_articles.append(padded)\n",
    "    return np.array(all_articles)\n",
    "\n",
    "\n",
    "\n",
    "# # === Generate labels for extractive summary ===\n",
    "def label_sentences(texts, summaries, top_n=3):\n",
    "    labels = []\n",
    "    for article, summary in zip(texts, summaries):\n",
    "        sents = sent_tokenize(article)[:max_sents]\n",
    "        summary_text = summary.replace(\"starttoken \", \"\").replace(\" endtoken\", \"\")\n",
    "        \n",
    "        if not sents:\n",
    "            labels.append(np.zeros(max_sents))\n",
    "            continue\n",
    "\n",
    "        # Compute TF-IDF similarity\n",
    "        tfidf = TfidfVectorizer().fit(sents + [summary_text])\n",
    "        sent_vecs = tfidf.transform(sents)\n",
    "        summary_vec = tfidf.transform([summary_text])\n",
    "        sims = cosine_similarity(summary_vec, sent_vecs).flatten()\n",
    "\n",
    "        # Get top-N most similar sentence indices\n",
    "        top_indices = sims.argsort()[-top_n:]\n",
    "        label = np.zeros(len(sents))\n",
    "        label[top_indices] = 1\n",
    "\n",
    "        # Pad to max_sents\n",
    "        padded_label = np.pad(label, (0, max_sents - len(label)), 'constant')\n",
    "        labels.append(padded_label)\n",
    "        \n",
    "    return np.array(labels)\n",
    "\n",
    "\n",
    "\n",
    "# === Model Definition ===\n",
    "input_layer = Input(shape=(max_sents, max_sent_len))\n",
    "embedding_layer = TimeDistributed(Embedding(input_dim=len(text_tokenizer.word_index)+1, output_dim=100,trainable=False))(input_layer)\n",
    "lstm_layer = TimeDistributed(LSTM(64, dropout=0.3, recurrent_dropout=0.3))(embedding_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(lstm_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# === Callbacks ===\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-5, verbose=1)\n",
    "checkpoint = ModelCheckpoint('best_extractive_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "\n",
    "# === Inference ===\n",
    "\n",
    "def extract_summary(article):\n",
    "    sents = sent_tokenize(article)[:max_sents]\n",
    "    tokenized = text_tokenizer.texts_to_sequences(sents)\n",
    "    padded = pad_sequences(tokenized, maxlen=max_sent_len, padding='post')\n",
    "    padded = np.pad(padded, ((0, max_sents - len(padded)), (0, 0)), mode='constant')\n",
    "    \n",
    "    prediction = model.predict(np.expand_dims(padded, 0))[0].flatten()\n",
    "    \n",
    "    # === Dynamic threshold based on mean score\n",
    "    threshold = prediction.mean()\n",
    "    \n",
    "    summary = [s for i, s in enumerate(sents) if prediction[i] > threshold]\n",
    "    # Fallback if no sentence is selected\n",
    "    if not summary:\n",
    "        top_idx = prediction.argmax()\n",
    "        summary = [sents[top_idx]]\n",
    "    \n",
    "    return ' '.join(summary)\n",
    "\n",
    "\n",
    "# === Example Prediction + Evaluation ===\n",
    "\n",
    "\n",
    "# === Load IMDB data ===\n",
    "texts = imdb_df[\"Article\"]\n",
    "summaries = ['starttoken ' + s + ' endtoken' for s in imdb_df[\"Summary\"]]\n",
    "\n",
    "# === Preprocess ===\n",
    "X = preprocess_articles(texts)\n",
    "y = label_sentences(texts, summaries, top_n=3)\n",
    "\n",
    "# === Train-test split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# === Train the model on IMDb dataset ===\n",
    "model.fit(\n",
    "    X_train,\n",
    "    np.expand_dims(y_train, -1),\n",
    "    validation_split=0.1,\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# === Evaluate on an IMDb example ===\n",
    "example_idx = 0\n",
    "article = texts.iloc[example_idx]\n",
    "reference_summary = imdb_df[\"Summary\"].iloc[example_idx].replace(\"starttoken \", \"\").replace(\" endtoken\", \"\")\n",
    "\n",
    "print(\"\\n--- IMDB Sample Article ---\")\n",
    "print(article[:500], \"...\")\n",
    "\n",
    "# Predict summary\n",
    "pred_summary = extract_summary(article)\n",
    "print(\"\\n--- Extracted Summary ---\")\n",
    "print(pred_summary)\n",
    "\n",
    "# Compute ROUGE\n",
    "rouge_scores = compute_rouge_scores(pred_summary, reference_summary)\n",
    "print(\"\\n--- ROUGE Scores ---\")\n",
    "for key, value in rouge_scores.items():\n",
    "    print(f\"{key}: Precision: {value.precision:.4f}, Recall: {value.recall:.4f}, F1: {value.fmeasure:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
