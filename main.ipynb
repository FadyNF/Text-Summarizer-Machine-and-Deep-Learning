{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d0b769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mohamedkenya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mohamedkenya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mohamedkenya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/mohamedkenya/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/mohamedkenya/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/mohamedkenya/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from utils import prepare_labeled_sentences, prepare_labeled_sentences_spacy\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd3f019",
   "metadata": {},
   "source": [
    "Read Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d4506ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BBC Dataset\n",
    "bbc_df = pd.read_csv(\"data/bbc/bbc_dataset.csv\")\n",
    "\n",
    "# CNN Datasets\n",
    "# cnn_train_df = pd.read_csv(\"data/cnn/cnn_dailymail_train.csv\")\n",
    "# cnn_valid_df = pd.read_csv(\"data/cnn/cnn_dailymail_valid.csv\")\n",
    "# cnn_test_df = pd.read_csv(\"data/cnn/cnn_dailymail_test.csv\")\n",
    "\n",
    "imdb_df = pd.read_csv(\"data/imdb/imdb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01e05b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBC Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Musicians to tackle US red tape\\n\\nMusicians' ...</td>\n",
       "      <td>Nigel McCune from the Musicians' Union said Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U2's desire to be number one\\n\\nU2, who have w...</td>\n",
       "      <td>But they still want more.They have to want to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rocker Doherty in on-stage fight\\n\\nRock singe...</td>\n",
       "      <td>Babyshambles, which he formed after his acrimo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Snicket tops US box office chart\\n\\nThe film a...</td>\n",
       "      <td>A Series of Unfortunate Events also stars Scot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ocean's Twelve raids box office\\n\\nOcean's Twe...</td>\n",
       "      <td>Ocean's Twelve, the crime caper sequel starrin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  \\\n",
       "0  Musicians to tackle US red tape\\n\\nMusicians' ...   \n",
       "1  U2's desire to be number one\\n\\nU2, who have w...   \n",
       "2  Rocker Doherty in on-stage fight\\n\\nRock singe...   \n",
       "3  Snicket tops US box office chart\\n\\nThe film a...   \n",
       "4  Ocean's Twelve raids box office\\n\\nOcean's Twe...   \n",
       "\n",
       "                                             Summary  \n",
       "0  Nigel McCune from the Musicians' Union said Br...  \n",
       "1  But they still want more.They have to want to ...  \n",
       "2  Babyshambles, which he formed after his acrimo...  \n",
       "3  A Series of Unfortunate Events also stars Scot...  \n",
       "4  Ocean's Twelve, the crime caper sequel starrin...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview to confirm structure\n",
    "print(\"BBC Sample:\")\n",
    "display(bbc_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "851acf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"CNN Sample:\")\n",
    "# display(cnn_train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a3b0b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production The filming tech...</td>\n",
       "      <td>A wonderful little production The filming tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was wonderful way to spend time...</td>\n",
       "      <td>I thought it was proof that Woody Allen is sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there a family where little boy Jake...</td>\n",
       "      <td>Basically there a family where little boy Jake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei Love in the Time of Money is vis...</td>\n",
       "      <td>Petter Mattei Love in the Time of Money is vis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  \\\n",
       "0  One of the other reviewers has mentioned that ...   \n",
       "1  A wonderful little production The filming tech...   \n",
       "2  I thought this was wonderful way to spend time...   \n",
       "3  Basically there a family where little boy Jake...   \n",
       "4  Petter Mattei Love in the Time of Money is vis...   \n",
       "\n",
       "                                             Summary  \n",
       "0  One of the other reviewers has mentioned that ...  \n",
       "1  A wonderful little production The filming tech...  \n",
       "2  I thought it was proof that Woody Allen is sti...  \n",
       "3  Basically there a family where little boy Jake...  \n",
       "4  Petter Mattei Love in the Time of Money is vis...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"IMDB Sample:\")\n",
    "display(imdb_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3c1a94",
   "metadata": {},
   "source": [
    "Preprocess BBC Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b005f2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing articles: 100%|██████████| 2225/2225 [04:39<00:00,  7.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process the BBC dataset\n",
    "bbc_labeled_data = prepare_labeled_sentences_spacy(bbc_df)\n",
    "\n",
    "# Convert to DataFrame for modeling\n",
    "bbc_processed_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"article_id\": item[\"article_id\"],\n",
    "            \"article_sentences\": item[\"raw_sentence\"],\n",
    "            \"preprocessed_sentence\": item[\"preprocessed_sentence\"],\n",
    "            \"label\": item[\"label\"],\n",
    "        }\n",
    "        for item in bbc_labeled_data\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3309143b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41677, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6a9ee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary sentences: 16543 out of 41677 (39.69%)\n",
      "\n",
      "Example summary sentences:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_sentences</th>\n",
       "      <th>preprocessed_sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Musicians to tackle US red tape  Musicians' gr...</td>\n",
       "      <td>musician tackle u red tape musician group tack...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>A singer hoping to perform in the US can expec...</td>\n",
       "      <td>singer hop perform u expect pay simply obtain ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nigel McCune from the Musicians' Union said Br...</td>\n",
       "      <td>nigel mccune musician union say british musici...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                  article_sentences  \\\n",
       "0           0  Musicians to tackle US red tape  Musicians' gr...   \n",
       "1           0  A singer hoping to perform in the US can expec...   \n",
       "4           0  Nigel McCune from the Musicians' Union said Br...   \n",
       "\n",
       "                               preprocessed_sentence  label  \n",
       "0  musician tackle u red tape musician group tack...      1  \n",
       "1  singer hop perform u expect pay simply obtain ...      1  \n",
       "4  nigel mccune musician union say british musici...      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count how many sentences are labeled as summary sentences\n",
    "summary_count = bbc_processed_df['label'].sum()\n",
    "total_count = len(bbc_processed_df)\n",
    "print(f\"Summary sentences: {summary_count} out of {total_count} ({summary_count/total_count:.2%})\")\n",
    "\n",
    "# Show some examples of sentences included in summaries\n",
    "print(\"\\nExample summary sentences:\")\n",
    "display(bbc_processed_df[bbc_processed_df['label'] == 1].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65bf0a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_sentences</th>\n",
       "      <th>preprocessed_sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Musicians to tackle US red tape  Musicians' gr...</td>\n",
       "      <td>musician tackle u red tape musician group tack...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>A singer hoping to perform in the US can expec...</td>\n",
       "      <td>singer hop perform u expect pay simply obtain ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Groups including the Musicians' Union are call...</td>\n",
       "      <td>group include musician union call end raw deal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>US acts are not faced with comparable expense ...</td>\n",
       "      <td>u act face comparable expense bureaucracy visi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nigel McCune from the Musicians' Union said Br...</td>\n",
       "      <td>nigel mccune musician union say british musici...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>A sponsor has to make a petition on their beha...</td>\n",
       "      <td>sponsor make petition behalf form amount nearl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>\"If you make a mistake on your form, you risk ...</td>\n",
       "      <td>make mistake form risk ban thus ability career...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>\"The US is the world's biggest music market, w...</td>\n",
       "      <td>u world big music market mean something creaky...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>\"The current situation is preventing British a...</td>\n",
       "      <td>current situation prevent british act maintain...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>The Musicians' Union stance is being endorsed ...</td>\n",
       "      <td>musician union stance endorse music manager fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>The MMF's general secretary James Seller said:...</td>\n",
       "      <td>mmf general secretary james seller say imagine...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>Every member would have to travel to London to...</td>\n",
       "      <td>every member would travel london visa process</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>\"The US market is seen as the holy grail and o...</td>\n",
       "      <td>u market see holy grail one benchmark success ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>\"It's still very important, but there are othe...</td>\n",
       "      <td>still important market like europe india china...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>A Department for Media, Culture and Sport spok...</td>\n",
       "      <td>department medium culture sport spokeswoman sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>A US Embassy spokesman said: \"We are aware tha...</td>\n",
       "      <td>u embassy spokesman say aware entertainer requ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>\"We are aware of the importance of cultural ex...</td>\n",
       "      <td>aware importance cultural exchange best facili...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>U2's desire to be number one  U2, who have won...</td>\n",
       "      <td>desire number one win three prestigious grammy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>The most popular groups in the history of rock...</td>\n",
       "      <td>popular group history rock several thing common</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>The music must be inspired and appeal across g...</td>\n",
       "      <td>music must inspire appeal across generation di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>But such success is down to more than music.</td>\n",
       "      <td>success music</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>They have to be compelling performers, charism...</td>\n",
       "      <td>compel performer charismatic intelligent enoug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>They also have to want it.</td>\n",
       "      <td>also want</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>They have to want to be the biggest band ever ...</td>\n",
       "      <td>want big band ever stop want</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>The Beatles had it, the Rolling Stones still h...</td>\n",
       "      <td>beatles roll stone still rem hold onto queen c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>And U2 have it in spades, and keep churning it...</td>\n",
       "      <td>spade keep churn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>Their new album, How To Dismantle An Atomic Bo...</td>\n",
       "      <td>new album dismantle atomic bomb come year scho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>They may have lost some of the edginess and ra...</td>\n",
       "      <td>may lose edginess raw youthful force propel to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>Vertigo, the first single from the new album, ...</td>\n",
       "      <td>vertigo first single new album go straight uk ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>\"The challenge is to be bigger and bolder and ...</td>\n",
       "      <td>challenge big bolder good make record whole wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>Drummer Larry Mullen Jr echoed those sentiment...</td>\n",
       "      <td>drummer larry mullen jr echoed sentiment compe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>We don't want to be thought of as a veteran ba...</td>\n",
       "      <td>want think veteran band</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>The band have done \"everything in their consid...</td>\n",
       "      <td>band everything considerable power ensure rema...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>\"This makes them hugely determined and formida...</td>\n",
       "      <td>make hugely determine formidable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>He added: \"They are equally determined to push...</td>\n",
       "      <td>add equally determine push make music continue...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>\"As such, they've constantly re-invented and c...</td>\n",
       "      <td>constantly challenge</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>They are, perhaps, alone as the only rock band...</td>\n",
       "      <td>perhaps alone rock band get well age</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>The other key ingredient was the fact they wer...</td>\n",
       "      <td>key ingredient fact highly organise mr rees say</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>\"They do everything in the right way.\"</td>\n",
       "      <td>everything right way</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>The group were born when Mullen put an appeal ...</td>\n",
       "      <td>group bear mullen put appeal bandmates high sc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>Dick Evans soon dropped out and the four-piece...</td>\n",
       "      <td>dick evans soon drop know feedback hype settle</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>By 1978, they had won a talent contest and got...</td>\n",
       "      <td>win talent contest get notice manager paul mcg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>\"They were brilliant, but very coarse,\" McGuin...</td>\n",
       "      <td>brilliant coarse mcguinness recently say</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>\"In a way, they were doing exactly what they d...</td>\n",
       "      <td>way exactly</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>Only badly.\"</td>\n",
       "      <td>badly</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>They struggled to attract record company atten...</td>\n",
       "      <td>struggle attract record company attention late...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>They released two Ireland-only singles, which ...</td>\n",
       "      <td>release two single top national chart lead dea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>The stadium-filling, anthemic sound was U2's a...</td>\n",
       "      <td>anthemic sound aim start third album war saw m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>Songs like Sunday Bloody Sunday and New Year's...</td>\n",
       "      <td>song like sunday bloody sunday new year day br...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>His stage performances - which included flag-w...</td>\n",
       "      <td>stage performance include earn reputation elec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>In 1987, The Joshua Tree broke sales records a...</td>\n",
       "      <td>joshua tree break sale record saw band reach h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>Those songs took the band's epic, atmospheric ...</td>\n",
       "      <td>song take band epic atmospheric sound simple p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>The end of the decade marked a crucial point f...</td>\n",
       "      <td>end decade mark crucial point band reach top s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>These came in the form of explorations of diff...</td>\n",
       "      <td>come form exploration different branch rock fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>The Achtung Baby album in 1991 was followed by...</td>\n",
       "      <td>achtung baby album follow zooropa pop correspo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>He was also building a parallel reputation - n...</td>\n",
       "      <td>also build parallel reputation always pleasure...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "      <td>Before the release of How To Dismantle An Atom...</td>\n",
       "      <td>release dismantle atomic bomb sell million alb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "      <td>But they still want more.</td>\n",
       "      <td>still want</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>Rocker Doherty in on-stage fight  Rock singer ...</td>\n",
       "      <td>rocker doherty fight rock singer pete doherty ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>Babyshambles played for 5,000 fans at London's...</td>\n",
       "      <td>babyshambles play fan london brixton academy t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id                                  article_sentences  \\\n",
       "0            0  Musicians to tackle US red tape  Musicians' gr...   \n",
       "1            0  A singer hoping to perform in the US can expec...   \n",
       "2            0  Groups including the Musicians' Union are call...   \n",
       "3            0  US acts are not faced with comparable expense ...   \n",
       "4            0  Nigel McCune from the Musicians' Union said Br...   \n",
       "5            0  A sponsor has to make a petition on their beha...   \n",
       "6            0  \"If you make a mistake on your form, you risk ...   \n",
       "7            0  \"The US is the world's biggest music market, w...   \n",
       "8            0  \"The current situation is preventing British a...   \n",
       "9            0  The Musicians' Union stance is being endorsed ...   \n",
       "10           0  The MMF's general secretary James Seller said:...   \n",
       "11           0  Every member would have to travel to London to...   \n",
       "12           0  \"The US market is seen as the holy grail and o...   \n",
       "13           0  \"It's still very important, but there are othe...   \n",
       "14           0  A Department for Media, Culture and Sport spok...   \n",
       "15           0  A US Embassy spokesman said: \"We are aware tha...   \n",
       "16           0  \"We are aware of the importance of cultural ex...   \n",
       "17           1  U2's desire to be number one  U2, who have won...   \n",
       "18           1  The most popular groups in the history of rock...   \n",
       "19           1  The music must be inspired and appeal across g...   \n",
       "20           1       But such success is down to more than music.   \n",
       "21           1  They have to be compelling performers, charism...   \n",
       "22           1                         They also have to want it.   \n",
       "23           1  They have to want to be the biggest band ever ...   \n",
       "24           1  The Beatles had it, the Rolling Stones still h...   \n",
       "25           1  And U2 have it in spades, and keep churning it...   \n",
       "26           1  Their new album, How To Dismantle An Atomic Bo...   \n",
       "27           1  They may have lost some of the edginess and ra...   \n",
       "28           1  Vertigo, the first single from the new album, ...   \n",
       "29           1  \"The challenge is to be bigger and bolder and ...   \n",
       "30           1  Drummer Larry Mullen Jr echoed those sentiment...   \n",
       "31           1  We don't want to be thought of as a veteran ba...   \n",
       "32           1  The band have done \"everything in their consid...   \n",
       "33           1  \"This makes them hugely determined and formida...   \n",
       "34           1  He added: \"They are equally determined to push...   \n",
       "35           1  \"As such, they've constantly re-invented and c...   \n",
       "36           1  They are, perhaps, alone as the only rock band...   \n",
       "37           1  The other key ingredient was the fact they wer...   \n",
       "38           1             \"They do everything in the right way.\"   \n",
       "39           1  The group were born when Mullen put an appeal ...   \n",
       "40           1  Dick Evans soon dropped out and the four-piece...   \n",
       "41           1  By 1978, they had won a talent contest and got...   \n",
       "42           1  \"They were brilliant, but very coarse,\" McGuin...   \n",
       "43           1  \"In a way, they were doing exactly what they d...   \n",
       "44           1                                       Only badly.\"   \n",
       "45           1  They struggled to attract record company atten...   \n",
       "46           1  They released two Ireland-only singles, which ...   \n",
       "47           1  The stadium-filling, anthemic sound was U2's a...   \n",
       "48           1  Songs like Sunday Bloody Sunday and New Year's...   \n",
       "49           1  His stage performances - which included flag-w...   \n",
       "50           1  In 1987, The Joshua Tree broke sales records a...   \n",
       "51           1  Those songs took the band's epic, atmospheric ...   \n",
       "52           1  The end of the decade marked a crucial point f...   \n",
       "53           1  These came in the form of explorations of diff...   \n",
       "54           1  The Achtung Baby album in 1991 was followed by...   \n",
       "55           1  He was also building a parallel reputation - n...   \n",
       "56           1  Before the release of How To Dismantle An Atom...   \n",
       "57           1                          But they still want more.   \n",
       "58           2  Rocker Doherty in on-stage fight  Rock singer ...   \n",
       "59           2  Babyshambles played for 5,000 fans at London's...   \n",
       "\n",
       "                                preprocessed_sentence  label  \n",
       "0   musician tackle u red tape musician group tack...      1  \n",
       "1   singer hop perform u expect pay simply obtain ...      1  \n",
       "2   group include musician union call end raw deal...      0  \n",
       "3   u act face comparable expense bureaucracy visi...      0  \n",
       "4   nigel mccune musician union say british musici...      1  \n",
       "5   sponsor make petition behalf form amount nearl...      0  \n",
       "6   make mistake form risk ban thus ability career...      0  \n",
       "7   u world big music market mean something creaky...      1  \n",
       "8   current situation prevent british act maintain...      1  \n",
       "9   musician union stance endorse music manager fo...      1  \n",
       "10  mmf general secretary james seller say imagine...      0  \n",
       "11      every member would travel london visa process      0  \n",
       "12  u market see holy grail one benchmark success ...      0  \n",
       "13  still important market like europe india china...      0  \n",
       "14  department medium culture sport spokeswoman sa...      0  \n",
       "15  u embassy spokesman say aware entertainer requ...      1  \n",
       "16  aware importance cultural exchange best facili...      0  \n",
       "17  desire number one win three prestigious grammy...      1  \n",
       "18    popular group history rock several thing common      0  \n",
       "19  music must inspire appeal across generation di...      0  \n",
       "20                                      success music      0  \n",
       "21  compel performer charismatic intelligent enoug...      0  \n",
       "22                                          also want      1  \n",
       "23                       want big band ever stop want      1  \n",
       "24  beatles roll stone still rem hold onto queen c...      0  \n",
       "25                                   spade keep churn      0  \n",
       "26  new album dismantle atomic bomb come year scho...      1  \n",
       "27  may lose edginess raw youthful force propel to...      0  \n",
       "28  vertigo first single new album go straight uk ...      1  \n",
       "29  challenge big bolder good make record whole wo...      1  \n",
       "30  drummer larry mullen jr echoed sentiment compe...      0  \n",
       "31                            want think veteran band      1  \n",
       "32  band everything considerable power ensure rema...      1  \n",
       "33                   make hugely determine formidable      0  \n",
       "34  add equally determine push make music continue...      0  \n",
       "35                               constantly challenge      0  \n",
       "36               perhaps alone rock band get well age      1  \n",
       "37    key ingredient fact highly organise mr rees say      0  \n",
       "38                               everything right way      0  \n",
       "39  group bear mullen put appeal bandmates high sc...      0  \n",
       "40     dick evans soon drop know feedback hype settle      0  \n",
       "41  win talent contest get notice manager paul mcg...      0  \n",
       "42           brilliant coarse mcguinness recently say      0  \n",
       "43                                        way exactly      0  \n",
       "44                                              badly      0  \n",
       "45  struggle attract record company attention late...      0  \n",
       "46  release two single top national chart lead dea...      0  \n",
       "47  anthemic sound aim start third album war saw m...      1  \n",
       "48  song like sunday bloody sunday new year day br...      1  \n",
       "49  stage performance include earn reputation elec...      0  \n",
       "50  joshua tree break sale record saw band reach h...      1  \n",
       "51  song take band epic atmospheric sound simple p...      0  \n",
       "52  end decade mark crucial point band reach top s...      1  \n",
       "53  come form exploration different branch rock fo...      1  \n",
       "54  achtung baby album follow zooropa pop correspo...      0  \n",
       "55  also build parallel reputation always pleasure...      0  \n",
       "56  release dismantle atomic bomb sell million alb...      1  \n",
       "57                                         still want      1  \n",
       "58  rocker doherty fight rock singer pete doherty ...      1  \n",
       "59  babyshambles play fan london brixton academy t...      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_processed_df.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa7f591",
   "metadata": {},
   "source": [
    "Preprocessed IMDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ac0d9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing articles: 100%|██████████| 4000/4000 [03:23<00:00, 19.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process the BBC dataset\n",
    "imdb_labeled_df = prepare_labeled_sentences_spacy(imdb_df[:4000])\n",
    "\n",
    "# Convert to DataFrame for modeling\n",
    "imdb_processed_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"article_id\": item[\"article_id\"],\n",
    "            \"article_sentences\": item[\"raw_sentence\"],\n",
    "            \"preprocessed_sentence\": item[\"preprocessed_sentence\"],\n",
    "            \"label\": item[\"label\"],\n",
    "        }\n",
    "        for item in imdb_labeled_df\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a67dd484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13024, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64901be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary sentences: 2934 out of 13024 (22.53%)\n",
      "\n",
      "Example summary sentences:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_sentences</th>\n",
       "      <th>preprocessed_sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A wonderful little production The filming tech...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>Basically there a family where little boy Jake...</td>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>Petter Mattei Love in the Time of Money is vis...</td>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id                                  article_sentences  \\\n",
       "2            1  A wonderful little production The filming tech...   \n",
       "9            3  Basically there a family where little boy Jake...   \n",
       "11           4  Petter Mattei Love in the Time of Money is vis...   \n",
       "\n",
       "                                preprocessed_sentence  label  \n",
       "2   wonderful little production filming technique ...      1  \n",
       "9   basically family little boy jake think zombie ...      1  \n",
       "11  petter mattei love time money visually stunnin...      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count how many sentences are labeled as summary sentences\n",
    "summary_count = imdb_processed_df['label'].sum()\n",
    "total_count = len(imdb_processed_df)\n",
    "print(f\"Summary sentences: {summary_count} out of {total_count} ({summary_count/total_count:.2%})\")\n",
    "\n",
    "# Show some examples of sentences included in summaries\n",
    "print(\"\\nExample summary sentences:\")\n",
    "display(imdb_processed_df[imdb_processed_df['label'] == 1].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a84aae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(imdb_processed_df[\"raw_sentence\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e1a68bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_sentences</th>\n",
       "      <th>preprocessed_sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>one reviewer mention watch oz episode hook rig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>This show pulls no punches with regards to dru...</td>\n",
       "      <td>show pull punch regard drug sex violence hardc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A wonderful little production The filming tech...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>but he has all the voices down pat too You can...</td>\n",
       "      <td>voice pat truly see seamless edit guide refere...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>but it is terrificly written and performed pie...</td>\n",
       "      <td>terrificly write perform piece masterful produ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>The realism really comes home with the little ...</td>\n",
       "      <td>realism really come home little thing fantasy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>I thought this was wonderful way to spend time...</td>\n",
       "      <td>think wonderful way spend time hot summer week...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>The plot is simplistic but the dialogue is wit...</td>\n",
       "      <td>plot simplistic dialogue witty character likab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>While some may be disappointed when they reali...</td>\n",
       "      <td>may disappoint realize match point risk addict...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>Basically there a family where little boy Jake...</td>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>And then we have Jake with his closet which to...</td>\n",
       "      <td>jake closet totally ruin film expect see booge...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>Petter Mattei Love in the Time of Money is vis...</td>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>This is movie that seems to be telling us what...</td>\n",
       "      <td>movie seem tell u money power success people d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>Kane Michael Imperioli Adrian Grenier and the ...</td>\n",
       "      <td>kane michael imperioli adrian grenier rest tal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>We wish Mr Mattei good luck and await anxiousl...</td>\n",
       "      <td>wish mr mattei good luck await anxiously next ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>Probably my all time favorite movie story of s...</td>\n",
       "      <td>probably time favorite movie story selflessnes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>The kids are as grandma says more like dressed...</td>\n",
       "      <td>kid grandma say like dress midget child make f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>I sure would like to see resurrection of up da...</td>\n",
       "      <td>sure would like see resurrection dated seahunt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>Oh by the way thank you for an outlet like thi...</td>\n",
       "      <td>oh way thank outlet like view many viewpoint t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>So any ole way believe ve got what wanna say W...</td>\n",
       "      <td>ole way believe get wan na say would nice read...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7</td>\n",
       "      <td>This show was an amazing fresh innovative idea...</td>\n",
       "      <td>show amazing fresh innovative idea first air f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>encourage positive comment film look forward w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9</td>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>like original gut wrench laughter like movie y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
       "      <td>phil alien one quirky film humour base around ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>At first it was very odd and pretty funny but ...</td>\n",
       "      <td>first odd pretty funny movie progress find jok...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>anymore</td>\n",
       "      <td>anymore</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10</td>\n",
       "      <td>Its low budget film thats never problem in its...</td>\n",
       "      <td>low budget film thats never problem pretty int...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11</td>\n",
       "      <td>I saw this movie when was about when it came o...</td>\n",
       "      <td>saw movie come recall scary scene big bird eat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11</td>\n",
       "      <td>The horror As young kid going to these cheesy ...</td>\n",
       "      <td>horror young kid go cheesy film saturday after...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12</td>\n",
       "      <td>So im not big fan of Boll work but then again ...</td>\n",
       "      <td>im big fan boll work many enjoy movie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12</td>\n",
       "      <td>Postal maybe im the only one Boll apparently b...</td>\n",
       "      <td>postal maybe im one boll apparently buy right ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12</td>\n",
       "      <td>So the tale goes like this Jack Carver played ...</td>\n",
       "      <td>tale go like jack carver play til schweiger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12</td>\n",
       "      <td>yes Carver is German all hail the bratwurst ea...</td>\n",
       "      <td>yes carver german hail bratwurst eat dude howe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12</td>\n",
       "      <td>but we only saw carver in first person perspec...</td>\n",
       "      <td>saw carver first person perspective</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>12</td>\n",
       "      <td>so we don really know what he looked like when...</td>\n",
       "      <td>really know look like kick however storyline f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>12</td>\n",
       "      <td>We see the evil mad scientist Dr Krieger playe...</td>\n",
       "      <td>see evil mad scientist dr krieger play udo kie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>13</td>\n",
       "      <td>The cast played Shakespeare Shakespeare lost a...</td>\n",
       "      <td>cast play shakespeare shakespeare lose appreci...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>14</td>\n",
       "      <td>This fantastic movie of three prisoners who be...</td>\n",
       "      <td>fantastic movie three prisoner become famous o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>14</td>\n",
       "      <td>but this roll is not bad Another good thing ab...</td>\n",
       "      <td>roll bad another good thing movie soundtrack m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>15</td>\n",
       "      <td>Kind of drawn in by the erotic scenes only to ...</td>\n",
       "      <td>kind drawn erotic scene realize one amateurish...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>15</td>\n",
       "      <td>What was with the bisexual relationship out of...</td>\n",
       "      <td>bisexual relationship nowhere heterosexual enc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>15</td>\n",
       "      <td>And what was with that absurd dance with every...</td>\n",
       "      <td>absurd dance everybody play stereotyped role g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>16</td>\n",
       "      <td>Some films just simply should not be remade Th...</td>\n",
       "      <td>film simply remake one bad film fail capture f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>16</td>\n",
       "      <td>But you will enjoy the friction of terror in t...</td>\n",
       "      <td>enjoy friction terror old version much</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>17</td>\n",
       "      <td>This movie made it into one of my top most awf...</td>\n",
       "      <td>movie make one top awful movie horrible contin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>17</td>\n",
       "      <td>The ghost scene at the end was stolen from the...</td>\n",
       "      <td>ghost scene end steal final scene old star war...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>17</td>\n",
       "      <td>hello</td>\n",
       "      <td>hello</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>17</td>\n",
       "      <td>And the whole machine vs humans theme WAS the ...</td>\n",
       "      <td>whole machine v human theme matrix terminator ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>18</td>\n",
       "      <td>I remember this film it was the first film had...</td>\n",
       "      <td>remember film first film watch cinema picture ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>19</td>\n",
       "      <td>An awful film It must have been up against som...</td>\n",
       "      <td>awful film must real stinker nominate golden g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>19</td>\n",
       "      <td>They ve taken the story of the first famous fe...</td>\n",
       "      <td>take story first famous female renaissance pai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>19</td>\n",
       "      <td>My complaint is not that they ve taken liberti...</td>\n",
       "      <td>complaint take liberty fact story good would p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>19</td>\n",
       "      <td>But it simply bizarre by all accounts the true...</td>\n",
       "      <td>simply bizarre account true story artist would...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>19</td>\n",
       "      <td>so why did they come up with this dishwater du...</td>\n",
       "      <td>come dishwater dull script suppose enough nake...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>20</td>\n",
       "      <td>After the success of Die Hard and it sequels i...</td>\n",
       "      <td>success die hard sequels surprise really glut ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>20</td>\n",
       "      <td>However if you an forget all the nonsense it a...</td>\n",
       "      <td>however forget nonsense actually lovable unden...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>20</td>\n",
       "      <td>And whilst he surely can be it really does loo...</td>\n",
       "      <td>whilst surely really look like ralph waite fra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>20</td>\n",
       "      <td>yes you can help enjoy that bit Hal needed goo...</td>\n",
       "      <td>yes help enjoy bit hal need good kicking</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>20</td>\n",
       "      <td>So forget your better judgement who cares if t...</td>\n",
       "      <td>forget good judgement care could never happen ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>20</td>\n",
       "      <td>And if you re looking for Qaulen he the one we...</td>\n",
       "      <td>look qaulen one wear helicopter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id                                  article_sentences  \\\n",
       "0            0  One of the other reviewers has mentioned that ...   \n",
       "1            0  This show pulls no punches with regards to dru...   \n",
       "2            1  A wonderful little production The filming tech...   \n",
       "3            1  but he has all the voices down pat too You can...   \n",
       "4            1  but it is terrificly written and performed pie...   \n",
       "5            1  The realism really comes home with the little ...   \n",
       "6            2  I thought this was wonderful way to spend time...   \n",
       "7            2  The plot is simplistic but the dialogue is wit...   \n",
       "8            2  While some may be disappointed when they reali...   \n",
       "9            3  Basically there a family where little boy Jake...   \n",
       "10           3  And then we have Jake with his closet which to...   \n",
       "11           4  Petter Mattei Love in the Time of Money is vis...   \n",
       "12           4  This is movie that seems to be telling us what...   \n",
       "13           4  Kane Michael Imperioli Adrian Grenier and the ...   \n",
       "14           4  We wish Mr Mattei good luck and await anxiousl...   \n",
       "15           5  Probably my all time favorite movie story of s...   \n",
       "16           5  The kids are as grandma says more like dressed...   \n",
       "17           6  I sure would like to see resurrection of up da...   \n",
       "18           6  Oh by the way thank you for an outlet like thi...   \n",
       "19           6  So any ole way believe ve got what wanna say W...   \n",
       "20           7  This show was an amazing fresh innovative idea...   \n",
       "21           8  Encouraged by the positive comments about this...   \n",
       "22           9  If you like original gut wrenching laughter yo...   \n",
       "23          10  Phil the Alien is one of those quirky films wh...   \n",
       "24          10  At first it was very odd and pretty funny but ...   \n",
       "25          10                                            anymore   \n",
       "26          10  Its low budget film thats never problem in its...   \n",
       "27          11  I saw this movie when was about when it came o...   \n",
       "28          11  The horror As young kid going to these cheesy ...   \n",
       "29          12  So im not big fan of Boll work but then again ...   \n",
       "30          12  Postal maybe im the only one Boll apparently b...   \n",
       "31          12  So the tale goes like this Jack Carver played ...   \n",
       "32          12  yes Carver is German all hail the bratwurst ea...   \n",
       "33          12  but we only saw carver in first person perspec...   \n",
       "34          12  so we don really know what he looked like when...   \n",
       "35          12  We see the evil mad scientist Dr Krieger playe...   \n",
       "36          13  The cast played Shakespeare Shakespeare lost a...   \n",
       "37          14  This fantastic movie of three prisoners who be...   \n",
       "38          14  but this roll is not bad Another good thing ab...   \n",
       "39          15  Kind of drawn in by the erotic scenes only to ...   \n",
       "40          15  What was with the bisexual relationship out of...   \n",
       "41          15  And what was with that absurd dance with every...   \n",
       "42          16  Some films just simply should not be remade Th...   \n",
       "43          16  But you will enjoy the friction of terror in t...   \n",
       "44          17  This movie made it into one of my top most awf...   \n",
       "45          17  The ghost scene at the end was stolen from the...   \n",
       "46          17                                              hello   \n",
       "47          17  And the whole machine vs humans theme WAS the ...   \n",
       "48          18  I remember this film it was the first film had...   \n",
       "49          19  An awful film It must have been up against som...   \n",
       "50          19  They ve taken the story of the first famous fe...   \n",
       "51          19  My complaint is not that they ve taken liberti...   \n",
       "52          19  But it simply bizarre by all accounts the true...   \n",
       "53          19  so why did they come up with this dishwater du...   \n",
       "54          20  After the success of Die Hard and it sequels i...   \n",
       "55          20  However if you an forget all the nonsense it a...   \n",
       "56          20  And whilst he surely can be it really does loo...   \n",
       "57          20  yes you can help enjoy that bit Hal needed goo...   \n",
       "58          20  So forget your better judgement who cares if t...   \n",
       "59          20  And if you re looking for Qaulen he the one we...   \n",
       "\n",
       "                                preprocessed_sentence  label  \n",
       "0   one reviewer mention watch oz episode hook rig...      0  \n",
       "1   show pull punch regard drug sex violence hardc...      0  \n",
       "2   wonderful little production filming technique ...      1  \n",
       "3   voice pat truly see seamless edit guide refere...      0  \n",
       "4   terrificly write perform piece masterful produ...      0  \n",
       "5   realism really come home little thing fantasy ...      0  \n",
       "6   think wonderful way spend time hot summer week...      0  \n",
       "7   plot simplistic dialogue witty character likab...      0  \n",
       "8   may disappoint realize match point risk addict...      0  \n",
       "9   basically family little boy jake think zombie ...      1  \n",
       "10  jake closet totally ruin film expect see booge...      0  \n",
       "11  petter mattei love time money visually stunnin...      1  \n",
       "12  movie seem tell u money power success people d...      0  \n",
       "13  kane michael imperioli adrian grenier rest tal...      1  \n",
       "14  wish mr mattei good luck await anxiously next ...      0  \n",
       "15  probably time favorite movie story selflessnes...      1  \n",
       "16  kid grandma say like dress midget child make f...      0  \n",
       "17  sure would like see resurrection dated seahunt...      1  \n",
       "18  oh way thank outlet like view many viewpoint t...      0  \n",
       "19  ole way believe get wan na say would nice read...      0  \n",
       "20  show amazing fresh innovative idea first air f...      0  \n",
       "21  encourage positive comment film look forward w...      0  \n",
       "22  like original gut wrench laughter like movie y...      1  \n",
       "23  phil alien one quirky film humour base around ...      1  \n",
       "24  first odd pretty funny movie progress find jok...      1  \n",
       "25                                            anymore      0  \n",
       "26  low budget film thats never problem pretty int...      0  \n",
       "27  saw movie come recall scary scene big bird eat...      1  \n",
       "28  horror young kid go cheesy film saturday after...      0  \n",
       "29              im big fan boll work many enjoy movie      0  \n",
       "30  postal maybe im one boll apparently buy right ...      0  \n",
       "31        tale go like jack carver play til schweiger      0  \n",
       "32  yes carver german hail bratwurst eat dude howe...      0  \n",
       "33                saw carver first person perspective      0  \n",
       "34  really know look like kick however storyline f...      0  \n",
       "35  see evil mad scientist dr krieger play udo kie...      0  \n",
       "36  cast play shakespeare shakespeare lose appreci...      0  \n",
       "37  fantastic movie three prisoner become famous o...      1  \n",
       "38  roll bad another good thing movie soundtrack m...      1  \n",
       "39  kind drawn erotic scene realize one amateurish...      0  \n",
       "40  bisexual relationship nowhere heterosexual enc...      0  \n",
       "41  absurd dance everybody play stereotyped role g...      0  \n",
       "42  film simply remake one bad film fail capture f...      0  \n",
       "43             enjoy friction terror old version much      0  \n",
       "44  movie make one top awful movie horrible contin...      0  \n",
       "45  ghost scene end steal final scene old star war...      0  \n",
       "46                                              hello      0  \n",
       "47  whole machine v human theme matrix terminator ...      0  \n",
       "48  remember film first film watch cinema picture ...      0  \n",
       "49  awful film must real stinker nominate golden g...      1  \n",
       "50  take story first famous female renaissance pai...      1  \n",
       "51  complaint take liberty fact story good would p...      0  \n",
       "52  simply bizarre account true story artist would...      0  \n",
       "53  come dishwater dull script suppose enough nake...      0  \n",
       "54  success die hard sequels surprise really glut ...      0  \n",
       "55  however forget nonsense actually lovable unden...      0  \n",
       "56  whilst surely really look like ralph waite fra...      0  \n",
       "57           yes help enjoy bit hal need good kicking      0  \n",
       "58  forget good judgement care could never happen ...      0  \n",
       "59                    look qaulen one wear helicopter      0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_processed_df.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ee6068",
   "metadata": {},
   "source": [
    "BiLSTM + Attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb73e5e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6b1f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aa5ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mohamedkenya/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running on BBC Dataset ===\n",
      "Train Accuracy for BBC: 0.7290\n",
      "Test Accuracy for BBC: 0.6457\n",
      "\n",
      "Classification Report for BBC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.71      7616\n",
      "           1       0.54      0.53      0.54      4810\n",
      "\n",
      "    accuracy                           0.65     12426\n",
      "   macro avg       0.63      0.62      0.62     12426\n",
      "weighted avg       0.64      0.65      0.64     12426\n",
      "\n",
      "\n",
      "Average ROUGE-1 (F1) for BBC sample (200 articles): 0.6494\n",
      "Average ROUGE-2 (F1) for BBC sample (200 articles): 0.5573\n",
      "Average ROUGE-L (F1) for BBC sample (200 articles): 0.6427\n",
      "\n",
      "=== Running on IMDB Dataset ===\n",
      "Train Accuracy for IMDB: 0.9709\n",
      "Test Accuracy for IMDB: 0.9606\n",
      "\n",
      "Classification Report for IMDB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     11591\n",
      "           1       0.11      0.47      0.18       109\n",
      "\n",
      "    accuracy                           0.96     11700\n",
      "   macro avg       0.55      0.72      0.58     11700\n",
      "weighted avg       0.99      0.96      0.97     11700\n",
      "\n",
      "\n",
      "Average ROUGE-1 (F1) for IMDB sample (200 articles): 0.5617\n",
      "Average ROUGE-2 (F1) for IMDB sample (200 articles): 0.4881\n",
      "Average ROUGE-L (F1) for IMDB sample (200 articles): 0.5612\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from rouge import Rouge\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def prepare_dataset(df):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    for _, row in df.iterrows():\n",
    "        article = row['article']\n",
    "        summary = row['summary']\n",
    "        sents = sent_tokenize(article)\n",
    "        for sent in sents:\n",
    "            sentences.append(sent)\n",
    "            labels.append(1 if sent in summary else 0)\n",
    "    return sentences, labels\n",
    "\n",
    "def extract_summary(article, clf, vectorizer):\n",
    "    sents = sent_tokenize(article)\n",
    "    X_sents = vectorizer.transform(sents)\n",
    "    preds = clf.predict(X_sents)\n",
    "    extracted = [s for s, p in zip(sents, preds) if p == 1]\n",
    "    # Return first sentence if no sentence predicted\n",
    "    return \" \".join(extracted) if extracted else sents[0]\n",
    "\n",
    "def run_on_dataset(name, df):\n",
    "    print(f\"\\n=== Running on {name} Dataset ===\")\n",
    "    \n",
    "    # Prepare data\n",
    "    sentences, labels = prepare_dataset(df)\n",
    "    vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "    X = vectorizer.fit_transform(sentences)\n",
    "    y = labels\n",
    "\n",
    "    # Split train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Create Decision Tree classifier with tuned hyperparameters\n",
    "    clf = DecisionTreeClassifier(\n",
    "        max_depth=30,\n",
    "        min_samples_leaf=10,\n",
    "        min_samples_split=10,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Train/Test accuracy\n",
    "    train_acc = clf.score(X_train, y_train)\n",
    "    test_acc = clf.score(X_test, y_test)\n",
    "    print(f\"Train Accuracy for {name}: {train_acc:.4f}\")\n",
    "    print(f\"Test Accuracy for {name}: {test_acc:.4f}\")\n",
    "\n",
    "    # Classification report on test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f\"\\nClassification Report for {name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # ROUGE evaluation on 200 samples\n",
    "    sample_df = df.sample(n=200, random_state=42)\n",
    "    rouge = Rouge()\n",
    "    rouge_1_scores = []\n",
    "    rouge_2_scores = []\n",
    "    rouge_l_scores = []\n",
    "\n",
    "    for _, row in sample_df.iterrows():\n",
    "        pred_summary = extract_summary(row['article'], clf, vectorizer)\n",
    "        true_summary = row['summary']\n",
    "        scores = rouge.get_scores(pred_summary, true_summary)[0]\n",
    "        rouge_1_scores.append(scores['rouge-1']['f'])\n",
    "        rouge_2_scores.append(scores['rouge-2']['f'])\n",
    "        rouge_l_scores.append(scores['rouge-l']['f'])\n",
    "\n",
    "    print(f\"\\nAverage ROUGE-1 (F1) for {name} sample (200 articles): {sum(rouge_1_scores)/len(rouge_1_scores):.4f}\")\n",
    "    print(f\"Average ROUGE-2 (F1) for {name} sample (200 articles): {sum(rouge_2_scores)/len(rouge_2_scores):.4f}\")\n",
    "    print(f\"Average ROUGE-L (F1) for {name} sample (200 articles): {sum(rouge_l_scores)/len(rouge_l_scores):.4f}\")\n",
    "\n",
    "# Make sure your datasets columns are correctly named\n",
    "bbc_df = bbc_df.rename(columns={\"Article\": \"article\", \"Summary\": \"summary\"})\n",
    "imdb_df = imdb_df.rename(columns={\"Article\": \"article\", \"Summary\": \"summary\"})\n",
    "\n",
    "# Run on both datasets\n",
    "run_on_dataset(\"BBC\", bbc_df)\n",
    "run_on_dataset(\"IMDB\", imdb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2c7166d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Extractive Summarization on BBC Dataset ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ct/bhg1rsxd2ml7nqj_0l8bn9980000gn/T/ipykernel_16467/4167071687.py:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.6280\n",
      "Epoch 2 Loss: 0.5823\n",
      "Epoch 3 Loss: 0.5087\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74      5081\n",
      "           1       0.59      0.48      0.53      3255\n",
      "\n",
      "    accuracy                           0.67      8336\n",
      "   macro avg       0.65      0.63      0.64      8336\n",
      "weighted avg       0.66      0.67      0.66      8336\n",
      "\n",
      "Accuracy: 0.6665067178502879\n",
      "Execution Time: 122.48 seconds\n",
      "\n",
      "=== Running Extractive Summarization on IMDB Dataset ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ct/bhg1rsxd2ml7nqj_0l8bn9980000gn/T/ipykernel_16467/4167071687.py:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.5160\n",
      "Epoch 2 Loss: 0.4829\n",
      "Epoch 3 Loss: 0.4578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.87      2021\n",
      "           1       0.00      0.00      0.00       584\n",
      "\n",
      "    accuracy                           0.78      2605\n",
      "   macro avg       0.39      0.50      0.44      2605\n",
      "weighted avg       0.60      0.78      0.68      2605\n",
      "\n",
      "Accuracy: 0.7754318618042226\n",
      "Execution Time: 40.92 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "\n",
    "# =====================\n",
    "# Dataset Class\n",
    "# =====================\n",
    "class ExtractiveDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.sentences = df['preprocessed_sentence'].values\n",
    "        self.labels = df['label'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sentences[idx], self.labels[idx]\n",
    "\n",
    "# =====================\n",
    "# Tokenizer + Vocab\n",
    "# =====================\n",
    "class Vocab:\n",
    "    def __init__(self, texts, min_freq=1):\n",
    "        from collections import Counter\n",
    "        self.token2idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "        counter = Counter(word for text in texts for word in text.split())\n",
    "        for word, freq in counter.items():\n",
    "            if freq >= min_freq:\n",
    "                self.token2idx[word] = len(self.token2idx)\n",
    "        self.idx2token = {i: t for t, i in self.token2idx.items()}\n",
    "\n",
    "    def encode(self, text, max_len=50):\n",
    "        tokens = text.split()\n",
    "        ids = [self.token2idx.get(t, self.token2idx['<UNK>']) for t in tokens]\n",
    "        ids = ids[:max_len] + [0] * (max_len - len(ids))\n",
    "        return torch.tensor(ids)\n",
    "\n",
    "# =====================\n",
    "# BiLSTM + Attention\n",
    "# =====================\n",
    "class BiLSTMAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=100, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.bilstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.attn = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.bilstm(embedded)\n",
    "        attn_weights = torch.softmax(self.attn(lstm_out).squeeze(2), dim=1)\n",
    "        context = torch.sum(lstm_out * attn_weights.unsqueeze(2), dim=1)\n",
    "        out = self.sigmoid(self.fc(context)).squeeze(1)\n",
    "        return out\n",
    "\n",
    "# =====================\n",
    "# Training / Evaluation\n",
    "# =====================\n",
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for texts, labels in loader:\n",
    "        inputs = torch.stack([vocab.encode(t) for t in texts]).to(device)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in loader:\n",
    "            inputs = torch.stack([vocab.encode(t) for t in texts]).to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = (outputs > 0.5).int().cpu().tolist()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "    print(classification_report(all_labels, all_preds))\n",
    "    print(\"Accuracy:\", accuracy_score(all_labels, all_preds))\n",
    "\n",
    "# =====================\n",
    "# Run Function\n",
    "# =====================\n",
    "def run_pipeline(name, df):\n",
    "    print(f\"\\n=== Running Extractive Summarization on {name} Dataset ===\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    global vocab\n",
    "    vocab = Vocab(train_df['preprocessed_sentence'].tolist())\n",
    "\n",
    "    train_dataset = ExtractiveDataset(train_df)\n",
    "    test_dataset = ExtractiveDataset(test_df)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = BiLSTMAttention(len(vocab.token2idx)).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    for epoch in range(3):\n",
    "        loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        print(f\"Epoch {epoch+1} Loss: {loss:.4f}\")\n",
    "\n",
    "    evaluate(model, test_loader, device)\n",
    "    print(\"Execution Time: {:.2f} seconds\".format(time.time() - start_time))\n",
    "\n",
    "# =====================\n",
    "# Load Your Datasets\n",
    "# =====================\n",
    "# Make sure these are loaded correctly beforehand\n",
    "# imdb_processed_df and bbc_processed_df should have 'preprocessed_sentence' and 'label'\n",
    "\n",
    "# Example call:\n",
    "run_pipeline(\"BBC\", bbc_processed_df)\n",
    "run_pipeline(\"IMDB\", imdb_processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bbec441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from rouge import Rouge\n",
    "\n",
    "# =====================\n",
    "# Dataset Class\n",
    "# =====================\n",
    "class ExtractiveDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.sentences = df['preprocessed_sentence'].values\n",
    "        self.labels = df['label'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sentences[idx], self.labels[idx]\n",
    "\n",
    "# =====================\n",
    "# Tokenizer + Vocab\n",
    "# =====================\n",
    "class Vocab:\n",
    "    def __init__(self, texts, min_freq=1):\n",
    "        from collections import Counter\n",
    "        self.token2idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "        counter = Counter(word for text in texts for word in text.split())\n",
    "        for word, freq in counter.items():\n",
    "            if freq >= min_freq:\n",
    "                self.token2idx[word] = len(self.token2idx)\n",
    "        self.idx2token = {i: t for t, i in self.token2idx.items()}\n",
    "\n",
    "    def encode(self, text, max_len=50):\n",
    "        tokens = text.split()\n",
    "        ids = [self.token2idx.get(t, self.token2idx['<UNK>']) for t in tokens]\n",
    "        ids = ids[:max_len] + [0] * (max_len - len(ids))\n",
    "        return torch.tensor(ids)\n",
    "\n",
    "# =====================\n",
    "# BiLSTM + Attention\n",
    "# =====================\n",
    "class BiLSTMAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=100, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.bilstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.attn = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.bilstm(embedded)\n",
    "        attn_weights = torch.softmax(self.attn(lstm_out).squeeze(2), dim=1)\n",
    "        context = torch.sum(lstm_out * attn_weights.unsqueeze(2), dim=1)\n",
    "        out = self.sigmoid(self.fc(context)).squeeze(1)\n",
    "        return out\n",
    "\n",
    "# =====================\n",
    "# Training / Evaluation\n",
    "# =====================\n",
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for texts, labels in loader:\n",
    "        inputs = torch.stack([vocab.encode(t) for t in texts]).to(device)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, all_texts = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in loader:\n",
    "            inputs = torch.stack([vocab.encode(t) for t in texts]).to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = (outputs > 0.5).int().cpu().tolist()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "            all_texts.extend(texts)\n",
    "    print(classification_report(all_labels, all_preds))\n",
    "    print(\"Accuracy:\", accuracy_score(all_labels, all_preds))\n",
    "    return all_preds, all_texts\n",
    "\n",
    "# =====================\n",
    "# Run Function (Modified to return preds & texts)\n",
    "# =====================\n",
    "def run_pipeline(name, df):\n",
    "    print(f\"\\n=== Running Extractive Summarization on {name} Dataset ===\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    global vocab\n",
    "    vocab = Vocab(train_df['preprocessed_sentence'].tolist())\n",
    "\n",
    "    train_dataset = ExtractiveDataset(train_df)\n",
    "    test_dataset = ExtractiveDataset(test_df)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = BiLSTMAttention(len(vocab.token2idx)).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    for epoch in range(5):\n",
    "        loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        print(f\"Epoch {epoch+1} Loss: {loss:.4f}\")\n",
    "\n",
    "    preds, pred_texts = evaluate(model, test_loader, device)\n",
    "\n",
    "    # Optional ROUGE evaluation\n",
    "    if 'reference_summary' in df.columns and 'article_id' in df.columns:\n",
    "        print(\"Computing ROUGE Scores...\")\n",
    "        pred_by_article = defaultdict(list)\n",
    "        for text, pred, row in zip(pred_texts, preds, test_df.itertuples()):\n",
    "            if pred == 1:\n",
    "                pred_by_article[row.article_id].append(text)\n",
    "\n",
    "        rouge = Rouge()\n",
    "        scores_1, scores_2, scores_l = [], [], []\n",
    "\n",
    "        grouped_refs = test_df[['article_id', 'reference_summary']].drop_duplicates().set_index('article_id')['reference_summary']\n",
    "\n",
    "        for aid, pred_sents in pred_by_article.items():\n",
    "            if aid in grouped_refs:\n",
    "                pred_summary = ' '.join(pred_sents)\n",
    "                ref_summary = grouped_refs[aid]\n",
    "                try:\n",
    "                    score = rouge.get_scores(pred_summary, ref_summary)[0]\n",
    "                    scores_1.append(score['rouge-1']['f'])\n",
    "                    scores_2.append(score['rouge-2']['f'])\n",
    "                    scores_l.append(score['rouge-l']['f'])\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        if scores_1:\n",
    "            print(f\"\\nROUGE-1 F1: {sum(scores_1)/len(scores_1):.4f}\")\n",
    "            print(f\"ROUGE-2 F1: {sum(scores_2)/len(scores_2):.4f}\")\n",
    "            print(f\"ROUGE-L F1: {sum(scores_l)/len(scores_l):.4f}\")\n",
    "        else:\n",
    "            print(\"No valid ROUGE scores could be calculated.\")\n",
    "\n",
    "    else:\n",
    "        print(\"Skipping ROUGE score: 'reference_summary' column not found.\")\n",
    "\n",
    "    print(\"Execution Time: {:.2f} seconds\".format(time.time() - start_time))\n",
    "    return preds, pred_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6934f079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Extractive Summarization on BBC Dataset ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ct/bhg1rsxd2ml7nqj_0l8bn9980000gn/T/ipykernel_19259/2734600125.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.6291\n",
      "Epoch 2 Loss: 0.5809\n",
      "Epoch 3 Loss: 0.5064\n",
      "Epoch 4 Loss: 0.3803\n",
      "Epoch 5 Loss: 0.2272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.68      0.70      5081\n",
      "           1       0.54      0.59      0.56      3255\n",
      "\n",
      "    accuracy                           0.64      8336\n",
      "   macro avg       0.63      0.63      0.63      8336\n",
      "weighted avg       0.65      0.64      0.64      8336\n",
      "\n",
      "Accuracy: 0.6419145873320538\n",
      "Skipping ROUGE score: 'reference_summary' column not found.\n",
      "Execution Time: 184.46 seconds\n",
      "\n",
      "=== Running Extractive Summarization on IMDB Dataset ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ct/bhg1rsxd2ml7nqj_0l8bn9980000gn/T/ipykernel_19259/2734600125.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.5147\n",
      "Epoch 2 Loss: 0.4874\n",
      "Epoch 3 Loss: 0.4543\n",
      "Epoch 4 Loss: 0.4074\n",
      "Epoch 5 Loss: 0.3538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85      2021\n",
      "           1       0.36      0.13      0.19       584\n",
      "\n",
      "    accuracy                           0.75      2605\n",
      "   macro avg       0.57      0.53      0.52      2605\n",
      "weighted avg       0.69      0.75      0.70      2605\n",
      "\n",
      "Accuracy: 0.7531669865642995\n",
      "Skipping ROUGE score: 'reference_summary' column not found.\n",
      "Execution Time: 60.23 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run models\n",
    "preds_bbc, pred_texts_bbc = run_pipeline(\"BBC\", bbc_processed_df)\n",
    "preds_imdb, pred_texts_imdb = run_pipeline(\"IMDB\", imdb_processed_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e29d8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample Predicted Summaries ===\n",
      "\n",
      "--- Article ID: 51 ---\n",
      "Predicted Summary:\n",
      "j robinson sale shark capt cueto sale shark tait newcastle j noon newcastle j lewsey wasp c hodgson sale shark dawson wasp g rowntree leicester thompson northampton j white leicester grewcock bath b kay leicester l moody leicester hazell gloucester j worsley wasp initially bmw say would produce mini model year vast cowley factory outskirt oxford target quickly reach raise time time martin mubanga claim observer officer play key role consign u camp cuba follow arrest zambia complaint make body board deputy british jew commission racial equality\n",
      "\n",
      "--- Article ID: 21 ---\n",
      "Predicted Summary:\n",
      "every rural school africa would access library student oxford harvard currently project operate area main electricity take charge score pat sanderson kai horstman mathew tait rob thirlby fiji rally force tense finale nominee say make film reason something say annual figure mark best year since also well ahead 2.2 record reportedly meet executive new line cinema week discuss film slash series star initially miss number show tour injure knee show illinois last march\n",
      "\n",
      "--- Article ID: 105 ---\n",
      "Predicted Summary:\n",
      "research reveal two work day lose staff shopping via work computer jamaica storm personal best 7.13 second claim woman sprint excellent try left wing teddy morgan seal win encounter cardiff arm park talk dominate bob deans try rule scottish referee john dallas know christmas say sell well los angeles new york go get low cost structure willmean source thing overseas newspaper quote qantas chief executive geoff dixon say say 1.5 million people subsidised employment scheme fact look real job let play number different role interesting ploy add new dimension call duty endeavour even sacrifice narrative flow somewhat impress thai culture get thing far quick west continue cinema often book print two week even film roar success hold print go another cinema new processor set ignite fresh battle intel cell consortium processor sits centre digital product assume title lord kinnock also become chairman british council promote uk reputation art science education possibility tag uncooperative parent lord falconer say tagging may go far let debate nationally million browse net via broadband mp murder sentence concern murder sentence reduce automatically simply guilty plea say new mp report comment humorous game good go get way could limit hour spend play write charles macintyre england tobacco company deny illegally conspire promote smoking defraud public backstage say lot people say due maybe maybe accolade least digital european nation greece position accord digital life index contrast say popularity vehicle traditional saloon car would fade mission look robot program respect personal space human infrastructure development lag demand however improve health rate lamentable lack exercise drug abuse excessive drinking\n",
      "\n",
      "--- Article ID: 203 ---\n",
      "Predicted Summary:\n",
      "party say plan could save average pensioner every year cut winter death yes apple laptop sony walkman classic gadget child author judy blume give honourary medal use ceremony speak censorship housewife lift channel rating debut u television hit desperate housewife help lift channel january audience share compare last year cent also appear rap protege game song\n",
      "\n",
      "--- Article ID: 94 ---\n",
      "Predicted Summary:\n",
      "important one class critical division charge think carry action make u network impervious attack disruption virus worm hack attack become commonplace\n",
      "\n",
      "=== Sample Predicted Summaries ===\n",
      "\n",
      "--- Article ID: 355 ---\n",
      "Predicted Summary:\n",
      "story drive movie must say story suck big time world manage slip plot hole past critic good story would give high vote impossible still able live always fan scary movie preview really fool scary scene show preview special divide three distinct act film location bergdorf goodman department store successful first special streisand company decide film location first act second special\n",
      "\n",
      "--- Article ID: 183 ---\n",
      "Predicted Summary:\n",
      "furthermore acting seem little superficial emotional argument family less convince sub par suspense scene see preview movie see best part strong understanding plot movie worth see theater additional nomination edward dmytryk best director producer adrian scott best picture john paxton best writing adapt screenplay evidence positive recognition movie justifiably receive\n",
      "\n",
      "--- Article ID: 719 ---\n",
      "Predicted Summary:\n",
      "even describe bad movie ever see nice guy call movie another big budget make someone like think much even scary revolt great movie never reach big screen come thing trick movie fan guess big producer make whatever want get big producer hot chick allthough horrible actress ton horror movie clich cook week\n",
      "\n",
      "--- Article ID: 92 ---\n",
      "Predicted Summary:\n",
      "jealousy racism manipulation underlying message love geoffrey sax try pull shakespeare othello bring modern day context however actor convince enough pull extra body help put everything perspective however john othello play eamonn walker reacted lot film cause fall keeley hawes dessie brabant eventually end dessie death ben jago play christopher eccleston see main character film give enough evidence dessie cheat othello michael cass play richard coyle\n",
      "\n",
      "--- Article ID: 768 ---\n",
      "Predicted Summary:\n",
      "name fast whole family enjoy plot extremely interesting ultimate come back previous nancy draw movie nancy draw actor seem match movie much like alex rider stormbreaker\n"
     ]
    }
   ],
   "source": [
    "def display_predicted_summaries(df, preds, texts, num_samples=5):\n",
    "    from collections import defaultdict\n",
    "    import random\n",
    "\n",
    "    pred_by_article = defaultdict(list)\n",
    "    for text, pred, row in zip(texts, preds, df.itertuples()):\n",
    "        if pred == 1:\n",
    "            pred_by_article[row.article_id].append(text)\n",
    "\n",
    "    sampled_ids = random.sample(list(pred_by_article.keys()), min(num_samples, len(pred_by_article)))\n",
    "\n",
    "    print(\"\\n=== Sample Predicted Summaries ===\")\n",
    "    for aid in sampled_ids:\n",
    "        print(f\"\\n--- Article ID: {aid} ---\")\n",
    "        print(\"Predicted Summary:\")\n",
    "        print(\" \".join(pred_by_article[aid]))\n",
    "\n",
    "# Show 5 predicted summaries from BBC test set\n",
    "display_predicted_summaries(bbc_processed_df, preds_bbc, pred_texts_bbc)\n",
    "\n",
    "# Optionally do the same for IMDB\n",
    "display_predicted_summaries(imdb_processed_df, preds_imdb, pred_texts_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4a857a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BBC Dataset Sample Summaries ===\n",
      "\n",
      "--- Article ID: 1755 ---\n",
      "Predicted Summary:\n",
      "mr kennedy tour come labour leader tony blair conservative leader michael howard step campaign ahead next general election widely expect hold may mr kennedy say british public felt let labour issue iraq fee conservative ask critical question labour say lib dem vote could let tory tory say lib dems would mean high tax soft crime law power europe say people highly sceptical labour conservative promise tax\n",
      "\n",
      "Reference Summary:\n",
      "The Liberal Democrats say in the northern cities, the race is between them and Labour, while in southern seats - particularly the south west - it is between them and the Tories.Mr Kennedy said the British public felt let down by Labour on issues from Iraq to top-up fees and the Conservatives were not \"asking the critical questions\".Mr Kennedy's tour comes as he, Labour leader Tony Blair and Conservative leader Michael Howard all step up campaigning ahead of the next General Election, widely expected to be held on 5 May.On Tuesday Mr Kennedy will visit Leicester South, where Lib Dem MP Parmjit Singh Gill overturned a big Labour majority to win the seat in last year's by-election.Asked whether it was realistic to assume the Liberal Democrats could win the general election, he said: \"There's no limit to the ambitions we have as a party.Speaking to the BBC's Westminster Hour on Sunday, Mr Kennedy said the upcoming general election - widely tipped for 5 May - would be much more unpredictable than any others in \"recent experience\".And he said people were \"highly sceptical\" about Labour and Conservative promises on tax.\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Article ID: 312 ---\n",
      "Predicted Summary:\n",
      "know christmas set confirm number one chart sunday book analyst commission chart prank group mop create first christmas single use whole formula song call gon na christmas mop v santa band aid remake\n",
      "\n",
      "Reference Summary:\n",
      "\"Everybody says that Christmas number ones are formulaic, but Gonna Have a Number One this Christmas is the first song to crack the formula and combine all these elements into one ultimate Christmas track\" said Mr Roberts.Big festive hits over the years include Band Aid's Do They Know It's Christmas?, Slade's Merry Christmas Everybody, Wham's Last Christmas and Sir Cliff Richards' Mistletoe and Wine.The book's analysts commissioned chart prank group Moped to create the first Christmas single using the whole formula - the song is called Gonna Have a No 1 This Christmas by Moped Vs Santa.Band Aid 20's remake of Do They Know It's Christmas is set to be confirmed as number one in the charts on Sunday.\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Article ID: 71 ---\n",
      "Predicted Summary:\n",
      "darkness tragedy story dream land part movie also star british actor bob hoskins brenda blethyn darin mother\n",
      "\n",
      "Reference Summary:\n",
      "\"Bobby Darin was one of the greatest entertainers the world has ever known, and yet, because he died young, he's been kind of forgotten,\" said Spacey at the premiere.Spacey, 45, wrote, directed and starred in the film, inspired by the life of 1950s croooner Bobby Darin.\"This is my tribute to someone I think was a remarkable talent,\" said Spacey, who, as Darin, sings all 18 songs on the film soundtrack.\"I knew absolutely nothing about Bobby Darin before this film, but now I'm a huge fan,\" said Bosworth, who attended the premiere with British boyfriend Orlando Bloom.Hollywood stars Kevin Spacey and Kate Bosworth attended the British premiere of new film, Beyond the Sea, in London's Leicester Square on Thursday.Spacey, a double Oscar-winner, has long been fascinated by the story of singer Bobby Darin.\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Article ID: 2012 ---\n",
      "Predicted Summary:\n",
      "alex bell whose trial old bailey end friday know mr computer device steven dowd nickname curiously tim cost u industry lot money billion dollar say say computer software britain believe pirate cost revenue software company supplier distributor\n",
      "\n",
      "Reference Summary:\n",
      "US Customs claimed Mr Griffiths was one of DOD's leaders but his lawyer, Antony Townsden, told the BBC News website it was a laughable suggestion and added: \"He was living on welfare and had such an old computer that he couldn't even download software.He said 29% of computer software in Britain was believed to have been pirated and this cost Â£1bn in revenue for software companies, their suppliers and distributors.Mr Boyd said: \"It was truly global in scope.A spokesman for the Business Software Alliance said: \"DOD members claim they did not profit at all.He said DOD and other warez groups were fostering a \"culture of piracy\" on the internet.A spokesman for US Immigration, Customs and Enforcement, Dean Boyd, said DOD did not appear to be motivated by money.Mr Boyd said the destruction of DOD was a great coup but he added: \"I'm not going to sit here and say we have sorted the problem.Mr Townsden said if he had committed any crimes he should be prosecuted in Australia, not the US.But the authorities in both Britain and the United States considered it software piracy and took a dim view of networks such as DOD, one of a number of so-called warez organisations operating on the internet.Their motivation was the kudos which surrounded being able to crack sophisticated software.But Mr Boyd pointed out that once the software had been distributed on the internet it fell into the hands of organised criminals who were able to mass produce pirated software at zero cost.US Attorney Paul McNulty said at the time: \"John Sankus and his techno-gang operated in the faceless world of the internet and thought they would never be caught.\"Internet piracy of computer software remains a gigantic problem.\"Alex Bell, whose trial at the Old Bailey ended on Friday, was known as Mr 2940 - after a computer device - while his co-defendant Steven Dowd's nickname, curiously, was Tim.\"It cost US industries a lot of money, billions of dollars,\" he said.Two men who were part of a huge network of internet software pirates, known as Drink Or Die, have been convicted at the Old Bailey.He claimed the Australian government's decision to accept the extradition request was typical of their current \"acquiescent\" attitude to the US.At least 60 people were arrested worldwide - 45 of them in the US.\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Article ID: 762 ---\n",
      "Predicted Summary:\n",
      "elsewhere bba add underlying mortgage lending rise november compare october â£4.29m cml say loan new property purchase fell low total see since february rightmove say estate agent set enter third property book year ago seasonal lift house market swathe figure provide evidence slowdown uk property market cml figure show gross lending fell november number people buy new home fell\n",
      "\n",
      "Reference Summary:\n",
      "The CML said that loans for new property purchases fell 25% year-on-year to 85,000 - the lowest total seen since February 2003.CML figures showed gross lending fell by 4% in November as the number of people buying new homes fell.A swathe of figures have provided further evidence of a slowdown in the UK property market.The Council of Mortgage Lenders (CML), British Bankers Association (BBA) and Building Societies Association (BSA) all said mortgage lending was slowing.Data from the CML showed lending fell to just over Â£25bn in November, from Â£25.5bn a year earlier.\"What is apparent is a picture of a slowing market, but one that should remain stable as we return to more normal volumes of lending over 2005 as a whole,\" CML director general Michael Coogan said.Rightmove said estate agents were set to enter 2005 with a third more properties on their books than a year ago.A host of mortgage lenders and economists have predicted that property prices will either fall or stagnate in 2005.\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "=== IMDB Dataset Sample Summaries ===\n",
      "\n",
      "--- Article ID: 1740 ---\n",
      "Predicted Summary:\n",
      "best movie ever movie break rib force laughter well worth intend summary excellent movie go see chance think either love hate quality real cult movie\n",
      "\n",
      "Reference Summary:\n",
      "best movie ever this movie broke my ribs just by the force of laughter but it was well worth it don intend to do summary of this excellent movie just go see it if you have the chance think you will either love it or hate it that the qualities of real cult movie \n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Article ID: 1711 ---\n",
      "Predicted Summary:\n",
      "try explain mood inside gore violence want watch woman rap throat get slash woman get rap throw bush excruciate authenticity would sit home rather watch police report kuttram\n",
      "\n",
      "Reference Summary:\n",
      "On the way back from IMC San Jose California all five mind you three of us hardcore Kamal fans of us had reached unanimous verdict VV was solid crap. Thanks to the movie we were going to have pretty screwed up Monday Not to mention we swore to stay off the theatres for the next year won blame Kamal here because he sort of dropped hint in recent interview.\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Article ID: 947 ---\n",
      "Predicted Summary:\n",
      "tear laugh one occasion two lead character twirl around crazy love fest even superhero thing go believable thin story work really funny thus worthy cinema time broken heart\n",
      "\n",
      "Reference Summary:\n",
      "A guy desperate for action attempts to hit on gorgeous girl in bus. She refuses him but when he runs after someone who tries to steal her purse they get together anyway. relation that is slightly tainted by the fact that she is jealous and neurotic superhero.\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Article ID: 815 ---\n",
      "Predicted Summary:\n",
      "film long weird forgettable big surprise come end suddenly blue director rino di silvestro try make u believe movie base true fact\n",
      "\n",
      "Reference Summary:\n",
      "The film is too long too weird and too forgettable The biggest surprise comes at the end when suddenly and out of the blue director Rino Di Silvestro tries to make us believe that his movie was based on true facts.\n",
      "\n",
      "============================================================\n",
      "\n",
      "--- Article ID: 3927 ---\n",
      "Predicted Summary:\n",
      "become cult movie chinese college student though havnt watch broadcast channel uk full arty giddy pretentions plot mediocre unreal spirit want convey independent artist resist commercisliation music industry maintain purity artistic soul wouldnt sell dirty money really giddy superficial diologue mainly pathetic acting poor sceenplay full art pretention fantasy movie kid\n",
      "\n",
      "Reference Summary:\n",
      "this became cult movie in chinese college students though havnt watched it until it was broadcasted in channel UK full of arty giddy pretentions the plot is mediocre and unreal the spirit it wants to convey is how independent artists resist the commercisliation of music industry and maintain their purity of an artistic soul.\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(42)  # for reproducibility\n",
    "\n",
    "# --- BBC ---\n",
    "\n",
    "# Recreate test split for BBC\n",
    "_, test_df_bbc = train_test_split(bbc_processed_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build predicted summaries dict for BBC\n",
    "pred_by_article_bbc = defaultdict(list)\n",
    "for pred, text, row in zip(preds_bbc, pred_texts_bbc, test_df_bbc.itertuples()):\n",
    "    if pred == 1:\n",
    "        pred_by_article_bbc[row.article_id].append(text)\n",
    "\n",
    "predicted_summaries_bbc = {aid: ' '.join(sents) for aid, sents in pred_by_article_bbc.items()}\n",
    "\n",
    "# Filter and sample article_ids for BBC\n",
    "filtered_df_bbc = bbc_processed_df[bbc_processed_df['label'] == 1]\n",
    "candidate_article_ids_bbc = filtered_df_bbc['article_id'].unique()\n",
    "candidate_article_ids_bbc = [aid for aid in candidate_article_ids_bbc if aid in predicted_summaries_bbc]\n",
    "sampled_article_ids_bbc = random.sample(list(candidate_article_ids_bbc), 5)\n",
    "\n",
    "# Ensure article_id column in bbc_df\n",
    "if 'article_id' not in bbc_df.columns:\n",
    "    bbc_df = bbc_df.reset_index().rename(columns={'index': 'article_id'})\n",
    "\n",
    "print(\"\\n=== BBC Dataset Sample Summaries ===\\n\")\n",
    "for aid in sampled_article_ids_bbc:\n",
    "    pred_sum = predicted_summaries_bbc.get(aid, \"[No predicted summary]\")\n",
    "    ref_sum_row = bbc_df.loc[bbc_df['article_id'] == aid, 'Summary']\n",
    "    ref_sum = ref_sum_row.values[0] if len(ref_sum_row) > 0 else \"[No original summary]\"\n",
    "    \n",
    "    print(f\"--- Article ID: {aid} ---\")\n",
    "    print(\"Predicted Summary:\")\n",
    "    print(pred_sum)\n",
    "    print(\"\\nReference Summary:\")\n",
    "    print(ref_sum)\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# --- IMDB ---\n",
    "\n",
    "# Recreate test split for IMDB\n",
    "_, test_df_imdb = train_test_split(imdb_processed_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build predicted summaries dict for IMDB\n",
    "pred_by_article_imdb = defaultdict(list)\n",
    "for pred, text, row in zip(preds_imdb, pred_texts_imdb, test_df_imdb.itertuples()):\n",
    "    if pred == 1:\n",
    "        pred_by_article_imdb[row.article_id].append(text)\n",
    "\n",
    "predicted_summaries_imdb = {aid: ' '.join(sents) for aid, sents in pred_by_article_imdb.items()}\n",
    "\n",
    "# Filter and sample article_ids for IMDB\n",
    "filtered_df_imdb = imdb_processed_df[imdb_processed_df['label'] == 1]\n",
    "candidate_article_ids_imdb = filtered_df_imdb['article_id'].unique()\n",
    "candidate_article_ids_imdb = [aid for aid in candidate_article_ids_imdb if aid in predicted_summaries_imdb]\n",
    "sampled_article_ids_imdb = random.sample(list(candidate_article_ids_imdb), 5)\n",
    "\n",
    "# Ensure article_id column in imdb_df\n",
    "if 'article_id' not in imdb_df.columns:\n",
    "    imdb_df = imdb_df.reset_index().rename(columns={'index': 'article_id'})\n",
    "\n",
    "print(\"\\n=== IMDB Dataset Sample Summaries ===\\n\")\n",
    "for aid in sampled_article_ids_imdb:\n",
    "    pred_sum = predicted_summaries_imdb.get(aid, \"[No predicted summary]\")\n",
    "    ref_sum_row = imdb_df.loc[imdb_df['article_id'] == aid, 'Summary']\n",
    "    ref_sum = ref_sum_row.values[0] if len(ref_sum_row) > 0 else \"[No original summary]\"\n",
    "    \n",
    "    print(f\"--- Article ID: {aid} ---\")\n",
    "    print(\"Predicted Summary:\")\n",
    "    print(pred_sum)\n",
    "    print(\"\\nReference Summary:\")\n",
    "    print(ref_sum)\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d1d017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
