{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cec8ef5",
   "metadata": {},
   "source": [
    "Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "157bad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n = 2000\n",
    "valid_n = 500\n",
    "test_n = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd0c94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/mohamedkenya/.cache/kagglehub/datasets/pariza/bbc-news-summary/versions/2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"pariza/bbc-news-summary\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2696a69",
   "metadata": {},
   "source": [
    "BBC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e15bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f8d9aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_path = os.path.join(path, \"BBC News Summary/News Articles\")\n",
    "summaries_path = os.path.join(path, \"BBC News Summary/Summaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b40a7757",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for category in os.listdir(articles_path):\n",
    "    article_dir = os.path.join(articles_path, category)\n",
    "    summary_dir = os.path.join(summaries_path, category)\n",
    "\n",
    "    if os.path.isdir(article_dir) and os.path.isdir(summary_dir):\n",
    "        for filename in os.listdir(article_dir):\n",
    "            article_file = os.path.join(article_dir, filename)\n",
    "            summary_file = os.path.join(summary_dir, filename)\n",
    "\n",
    "            if os.path.exists(summary_file):\n",
    "                with open(article_file, \"r\", encoding=\"ISO-8859-1\") as f:\n",
    "                    article_text = f.read().strip()\n",
    "                with open(summary_file, \"r\", encoding=\"ISO-8859-1\") as f:\n",
    "                    summary_text = f.read().strip()\n",
    "\n",
    "                data.append(\n",
    "                    {\n",
    "                        # 'Category': category,\n",
    "                        \"Article\": article_text,\n",
    "                        \"Summary\": summary_text,\n",
    "                    }\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "976b1f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_df = pd.DataFrame(data)\n",
    "\n",
    "bbc_df.to_csv(\"../data/bbc/bbc_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e739f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_df = pd.read_csv(\"../data/bbc/bbc_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5040cab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Musicians to tackle US red tape\\n\\nMusicians' ...</td>\n",
       "      <td>Nigel McCune from the Musicians' Union said Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U2's desire to be number one\\n\\nU2, who have w...</td>\n",
       "      <td>But they still want more.They have to want to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rocker Doherty in on-stage fight\\n\\nRock singe...</td>\n",
       "      <td>Babyshambles, which he formed after his acrimo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Snicket tops US box office chart\\n\\nThe film a...</td>\n",
       "      <td>A Series of Unfortunate Events also stars Scot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ocean's Twelve raids box office\\n\\nOcean's Twe...</td>\n",
       "      <td>Ocean's Twelve, the crime caper sequel starrin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  \\\n",
       "0  Musicians to tackle US red tape\\n\\nMusicians' ...   \n",
       "1  U2's desire to be number one\\n\\nU2, who have w...   \n",
       "2  Rocker Doherty in on-stage fight\\n\\nRock singe...   \n",
       "3  Snicket tops US box office chart\\n\\nThe film a...   \n",
       "4  Ocean's Twelve raids box office\\n\\nOcean's Twe...   \n",
       "\n",
       "                                             Summary  \n",
       "0  Nigel McCune from the Musicians' Union said Br...  \n",
       "1  But they still want more.They have to want to ...  \n",
       "2  Babyshambles, which he formed after his acrimo...  \n",
       "3  A Series of Unfortunate Events also stars Scot...  \n",
       "4  Ocean's Twelve, the crime caper sequel starrin...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52dfda6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Article    0\n",
       "Summary    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b32f3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2225 entries, 0 to 2224\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Article  2225 non-null   object\n",
      " 1   Summary  2225 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 34.9+ KB\n"
     ]
    }
   ],
   "source": [
    "bbc_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da0395e",
   "metadata": {},
   "source": [
    "Summarized IMDB Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7940f52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/mohamedkenya/.cache/kagglehub/datasets/robber19/summarized-imdb-reviews/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "file_path = \"summary_reviews.csv\"\n",
    "\n",
    "path = kagglehub.dataset_download(\n",
    "    \"robber19/summarized-imdb-reviews\",\n",
    ")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3826ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct full file path\n",
    "file_path = os.path.join(path, \"summary_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "832b6331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51a7ca31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production The filming tech...</td>\n",
       "      <td>A wonderful little production The filming tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was wonderful way to spend time...</td>\n",
       "      <td>I thought it was proof that Woody Allen is sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there a family where little boy Jake...</td>\n",
       "      <td>Basically there a family where little boy Jake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei Love in the Time of Money is vis...</td>\n",
       "      <td>Petter Mattei Love in the Time of Money is vis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  \\\n",
       "0  One of the other reviewers has mentioned that ...   \n",
       "1  A wonderful little production The filming tech...   \n",
       "2  I thought this was wonderful way to spend time...   \n",
       "3  Basically there a family where little boy Jake...   \n",
       "4  Petter Mattei Love in the Time of Money is vis...   \n",
       "\n",
       "                                             Summary  \n",
       "0  One of the other reviewers has mentioned that ...  \n",
       "1  A wonderful little production The filming tech...  \n",
       "2  I thought it was proof that Woody Allen is sti...  \n",
       "3  Basically there a family where little boy Jake...  \n",
       "4  Petter Mattei Love in the Time of Money is vis...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean and rename columns\n",
    "df = df.rename(columns={\"review\": \"Article\", \"summary_review\": \"Summary\"})\n",
    "df = df[[\"Article\", \"Summary\"]]  # Keep only the desired columns\n",
    "\n",
    "# Optional: reset index if needed\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Show a preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4972c675",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"../data/imdb/imdb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1f763f",
   "metadata": {},
   "source": [
    "CNN Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848d9a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import kagglehub\n",
    "# from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# train_n = 2000\n",
    "# valid_n = 500\n",
    "# test_n = 500\n",
    "\n",
    "# # === BBC Dataset Download and Processing ===\n",
    "# path = kagglehub.dataset_download(\"pariza/bbc-news-summary\")\n",
    "# print(\"Path to dataset files:\", path)\n",
    "\n",
    "# articles_path = os.path.join(path, \"BBC News Summary/News Articles\")\n",
    "# summaries_path = os.path.join(path, \"BBC News Summary/Summaries\")\n",
    "# data = []\n",
    "\n",
    "# for category in os.listdir(articles_path):\n",
    "#     article_dir = os.path.join(articles_path, category)\n",
    "#     summary_dir = os.path.join(summaries_path, category)\n",
    "\n",
    "#     if os.path.isdir(article_dir) and os.path.isdir(summary_dir):\n",
    "#         for filename in os.listdir(article_dir):\n",
    "#             article_file = os.path.join(article_dir, filename)\n",
    "#             summary_file = os.path.join(summary_dir, filename)\n",
    "\n",
    "#             if os.path.exists(summary_file):\n",
    "#                 with open(article_file, \"r\", encoding=\"ISO-8859-1\") as f:\n",
    "#                     article_text = f.read().strip()\n",
    "#                 with open(summary_file, \"r\", encoding=\"ISO-8859-1\") as f:\n",
    "#                     summary_text = f.read().strip()\n",
    "\n",
    "#                 data.append({\n",
    "#                     \"Article\": article_text,\n",
    "#                     \"Summary\": summary_text,\n",
    "#                 })\n",
    "\n",
    "# # Save BBC Dataset\n",
    "# bbc_df = pd.DataFrame(data)\n",
    "# output_dir = \"../data/bbc\"\n",
    "# output_path = os.path.join(output_dir, \"bbc_dataset.csv\")\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# bbc_df.to_csv(output_path, index=False)\n",
    "# print(\"Dataset saved to:\", output_path)\n",
    "\n",
    "# # === CNN/DailyMail Dataset Loading ===\n",
    "# def load_and_sample(path, sample_size):\n",
    "#     df = kagglehub.load_dataset(KaggleDatasetAdapter.PANDAS, \"gowrishankarp/newspaper-text-summarization-cnn-dailymail\", path)\n",
    "#     return df.sample(n=sample_size, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# train_cnn_df = load_and_sample(\"cnn_dailymail/train.csv\", train_n)\n",
    "# valid_cnn_df = load_and_sample(\"cnn_dailymail/validation.csv\", valid_n)\n",
    "# test_cnn_df = load_and_sample(\"cnn_dailymail/test.csv\", test_n)\n",
    "\n",
    "# # === Clean and Save CNN/DailyMail Data ===\n",
    "# os.makedirs(\"../data/cnn\", exist_ok=True)\n",
    "\n",
    "# for name, df in zip([\"train\", \"valid\", \"test\"], [train_cnn_df, valid_cnn_df, test_cnn_df]):\n",
    "#     if \"id\" in df.columns:\n",
    "#         df.drop(columns=[\"id\"], inplace=True)\n",
    "#     df[\"Article\"] = df.pop(\"article\")\n",
    "#     df[\"Summary\"] = df.pop(\"highlights\")\n",
    "#     df.to_csv(f\"../data/cnn/cnn_dailymail_{name}.csv\", index=False)\n",
    "\n",
    "# print(\"All CNN/DailyMail datasets saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
